{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77639a59",
   "metadata": {},
   "source": [
    "# Generating a Full Text Searchable Database for *Notes & Queries*\n",
    "\n",
    "Whilst the PDF documents corresponding to each issue of *Notes and Queries* are quite large files, the searchable, OCR retrieved text documents are much smaller and can be easily added to a full-text searchable database.\n",
    "\n",
    "We can create a simple, file based SQLite database that will provide a full-text search facility over each issue of *Notes & Queries*.\n",
    "\n",
    "Recall that we previously downloaded the metadata for issues of *Notes & Queries* held by the Internet Archive to a CSV file.\n",
    "\n",
    "We can load that metadata in from the CSV file using the function we created and put into a simple Python package directory previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26e0236a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'sim_notes-and-queries_1849-11-03_1_1',\n",
       "  'date': '1849-11-03',\n",
       "  'title': 'Notes and Queries  1849-11-03: Vol 1 Iss 1',\n",
       "  'vol': '1',\n",
       "  'iss': '1',\n",
       "  'prev_id': 'sim_notes-and-queries_1849-1850_1_index',\n",
       "  'next_id': 'sim_notes-and-queries_1849-11-10_1_2',\n",
       "  'restricted': ''},\n",
       " {'id': 'sim_notes-and-queries_1849-11-10_1_2',\n",
       "  'date': '1849-11-10',\n",
       "  'title': 'Notes and Queries  1849-11-10: Vol 1 Iss 2',\n",
       "  'vol': '1',\n",
       "  'iss': '2',\n",
       "  'prev_id': 'sim_notes-and-queries_1849-11-03_1_1',\n",
       "  'next_id': 'sim_notes-and-queries_1849-11-17_1_3',\n",
       "  'restricted': ''},\n",
       " {'id': 'sim_notes-and-queries_1849-11-17_1_3',\n",
       "  'date': '1849-11-17',\n",
       "  'title': 'Notes and Queries  1849-11-17: Vol 1 Iss 3',\n",
       "  'vol': '1',\n",
       "  'iss': '3',\n",
       "  'prev_id': 'sim_notes-and-queries_1849-11-10_1_2',\n",
       "  'next_id': 'sim_notes-and-queries_1849-11-24_1_4',\n",
       "  'restricted': ''}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ia_utils.open_metadata_records import open_metadata_records\n",
    "\n",
    "data_records = open_metadata_records()\n",
    "data_records[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ff1d3e",
   "metadata": {},
   "source": [
    "We also saved the data to a simple local database, so we could alternatively retrieve the data from there.\n",
    "\n",
    "First open up a connection to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca63c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlite_utils import Database\n",
    "\n",
    "db_name = \"nq_demo.db\"\n",
    "db = Database(db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aec0c5",
   "metadata": {},
   "source": [
    "And then make a simple query onto it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce714d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>series</th>\n",
       "      <th>vol</th>\n",
       "      <th>iss</th>\n",
       "      <th>title</th>\n",
       "      <th>next_id</th>\n",
       "      <th>prev_id</th>\n",
       "      <th>is_index</th>\n",
       "      <th>restricted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>1849-11-03</td>\n",
       "      <td>1849-11-03T00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Notes and Queries  1849-11-03: Vol 1 Iss 1</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>sim_notes-and-queries_1849-1850_1_index</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>1849-11-10</td>\n",
       "      <td>1849-11-10T00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Notes and Queries  1849-11-10: Vol 1 Iss 2</td>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>1849-11-17</td>\n",
       "      <td>1849-11-17T00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Notes and Queries  1849-11-17: Vol 1 Iss 3</td>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id        date             datetime  \\\n",
       "0  sim_notes-and-queries_1849-11-03_1_1  1849-11-03  1849-11-03T00:00:00   \n",
       "1  sim_notes-and-queries_1849-11-10_1_2  1849-11-10  1849-11-10T00:00:00   \n",
       "2  sim_notes-and-queries_1849-11-17_1_3  1849-11-17  1849-11-17T00:00:00   \n",
       "\n",
       "  series vol iss                                       title  \\\n",
       "0   None   1   1  Notes and Queries  1849-11-03: Vol 1 Iss 1   \n",
       "1   None   1   2  Notes and Queries  1849-11-10: Vol 1 Iss 2   \n",
       "2   None   1   3  Notes and Queries  1849-11-17: Vol 1 Iss 3   \n",
       "\n",
       "                                next_id  \\\n",
       "0  sim_notes-and-queries_1849-11-10_1_2   \n",
       "1  sim_notes-and-queries_1849-11-17_1_3   \n",
       "2  sim_notes-and-queries_1849-11-24_1_4   \n",
       "\n",
       "                                   prev_id  is_index restricted  \n",
       "0  sim_notes-and-queries_1849-1850_1_index         0             \n",
       "1     sim_notes-and-queries_1849-11-03_1_1         0             \n",
       "2     sim_notes-and-queries_1849-11-10_1_2         0             "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_sql\n",
    "\n",
    "q = \"SELECT * FROM metadata;\"\n",
    "\n",
    "data_records_from_db = read_sql(q, db.conn)\n",
    "data_records_from_db.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb0f537",
   "metadata": {},
   "source": [
    "## Adding an `issues` Table to the Database\n",
    "\n",
    "We already have a metadata table in the database, but we can also add more tables to it.\n",
    "\n",
    "For at least the 19th century issues of *Notes & Queries*, a file is available for each issue that contains searchable text extracted from that issue. If we download those text files and add them to our own database, then we can create our own full text searchable database over the content of those issues.\n",
    "\n",
    "Let's create a simple table structure for the searchable text extracted from each issue of *Notes & Queries* containing the content and a unique identifier for each record.\n",
    "\n",
    "We can relate this table to the metadata table through a *foreign key*. What this means is that for each entry in the issues table, we also expect to find an entry in the metadata table under the same identifier value.\n",
    "\n",
    "We will also create a full text search table associated with the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a16617",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ia_utils/create_db_table_issues.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ia_utils/create_db_table_issues.py\n",
    "def create_db_table_issues(db, drop=True):\n",
    "    \"\"\"Create and issues database table and an associated full-text search table.\"\"\"\n",
    "    table_name = \"issues\"\n",
    "    # If required, drop any previously defined tables of the same name\n",
    "    if drop:\n",
    "        db[table_name].drop(ignore=True)\n",
    "        db[f\"{table_name}_fts\"].drop(ignore=True)\n",
    "    elif db[table_name].exists():\n",
    "        print(f\"Table {table_name} exists...\")\n",
    "        return\n",
    "\n",
    "    # Create the table structure for the simple issues table\n",
    "    db[table_name].create({\n",
    "            \"id\": str,\n",
    "            \"content\": str\n",
    "        }, pk=(\"id\"), foreign_keys=[ (\"id\", \"metadata\", \"id\"), # local-table-id, foreign-table, foreign-table-id)\n",
    "    ])\n",
    "    \n",
    "    # Enable full text search\n",
    "    # This creates an extra virtual table (issues_fts) to support the full text search\n",
    "    # A stemmer is applied to support the efficacy of the full-text searching\n",
    "    db[table_name].enable_fts([\"id\", \"content\"],\n",
    "                            create_triggers=True, tokenize=\"porter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1948092",
   "metadata": {},
   "source": [
    "Load that function in from the local package and call it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70e03a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ia_utils.create_db_table_issues import create_db_table_issues\n",
    "\n",
    "create_db_table_issues(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef1acb",
   "metadata": {},
   "source": [
    "To add the content data to the database, we need to download the searchable text associated with each record from the Internet Archive.\n",
    "\n",
    "Before we add the data in bulk, let's do a dummy run of the steps we need to follow.\n",
    "\n",
    "First, we need to download the full text file from the Internet Archive, given a record identifier. We'll use the first data record to provide us with the identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d0fc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'sim_notes-and-queries_1849-11-03_1_1',\n",
       " 'date': '1849-11-03',\n",
       " 'title': 'Notes and Queries  1849-11-03: Vol 1 Iss 1',\n",
       " 'vol': '1',\n",
       " 'iss': '1',\n",
       " 'prev_id': 'sim_notes-and-queries_1849-1850_1_index',\n",
       " 'next_id': 'sim_notes-and-queries_1849-11-10_1_2',\n",
       " 'restricted': ''}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_records[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e24651",
   "metadata": {},
   "source": [
    "The download step takes the identifier and requests the `OCR Search Text` file.\n",
    "\n",
    "We will download the Internet Archive files to the directory we specified previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e75e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create download dir file path, as before\n",
    "dirname = \"ia-downloads\" # This is a default\n",
    "p = Path(dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20453abb",
   "metadata": {},
   "source": [
    "And now download the text file for the sample record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7c45b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary packages\n",
    "from internetarchive import download\n",
    "\n",
    "download(data_records[0]['id'], destdir=p, silent = True,\n",
    "         formats=[\"OCR Search Text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3c44b5",
   "metadata": {},
   "source": [
    "Recall that the files are download into a directory with a name that corresponds to the record identifier.\n",
    "\n",
    "The data files are actually download as compressed archive files, as we can see if we review the download directory we saved our test download to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a242e1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sim_notes-and-queries_1849-11-03_1_1_hocr_searchtext.txt.gz',\n",
       " 'sim_notes-and-queries_1849-11-03_1_1_hocr_pageindex.json.gz',\n",
       " 'sim_notes-and-queries_1849-11-03_1_1_hocr_searchtext.txt',\n",
       " 'sim_notes-and-queries_1849-11-03_1_1_page_numbers.json',\n",
       " 'sim_notes-and-queries_1849-11-03_1_1_hocr_pageindex.json']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir( p / data_records[0]['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fbd642",
   "metadata": {},
   "source": [
    "We now need to uncompress the `.txt.gz` file to access the fully formed text file.\n",
    "\n",
    "The `gzip` package provides us with the utility we need to access the contents of the archive file.\n",
    "\n",
    "In fact, we don't need to actually uncompress the file into the directory, we can open it and extract its contents \"in memory\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "488b0262",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ia_utils/get_txt_from_file.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ia_utils/get_txt_from_file.py\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "\n",
    "# Create a simple function to make it even easier to extract the full text content\n",
    "def get_txt_from_file(id_val, dirname=\"ia-downloads\", typ=\"searchtext\"):\n",
    "    \"\"\"Retrieve text from downloaded text file.\"\"\"\n",
    "    if typ==\"searchtext\":\n",
    "        p_ = Path(dirname) / id_val / f'{id_val}_hocr_searchtext.txt.gz'\n",
    "        f = gzip.open(p_,'rb')\n",
    "        content = f.read().decode('utf-8')\n",
    "    elif typ==\"djvutxt\":\n",
    "        p_ = Path(dirname) / id_val / f'{id_val}_djvu.txt'\n",
    "        content = p_.read_text()\n",
    "    else:\n",
    "        content = \"\"\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af28752a",
   "metadata": {},
   "source": [
    "Let's see how it works, previewing the first 200 characters of the unarchived text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7db3edd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n \\n \\n \\nNOTES anp QUERIES:\\nA Medium of Enter-Communication\\nFOR\\nLITERARY MEN, ARTISTS, ANTIQUARIES, GENEALOGISTS, ETC.\\n‘* When found, make a note of.’—Carrain Corrie.\\nVOLUME FIRST.\\nNoveMBER, 1849—May, '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ia_utils.get_txt_from_file import get_txt_from_file\n",
    "\n",
    "get_txt_from_file(data_records[0]['id'])[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78ba65c",
   "metadata": {},
   "source": [
    "If we inspect the text in more detail, we see there are various things in it that we might want to simplify. For example, quotation marks appear in various guises, such as opening and closing quotes of different flavours. We *could* normalise these to a simpler form (for example, \"straight\" quotes `'` and `\"`), However, *if* opening and closing quotes are reliably recognised they do provide us with a simple text for matching text contained *within* the quotes. So for now, let's leave the originally detected quotes in place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fc981e",
   "metadata": {},
   "source": [
    "Having got a method in place, let's now download the contents of the non-index issues for 1849."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bca233f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>Notes and Queries  1849-11-03: Vol 1 Iss 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>Notes and Queries  1849-11-10: Vol 1 Iss 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>Notes and Queries  1849-11-17: Vol 1 Iss 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>Notes and Queries  1849-11-24: Vol 1 Iss 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sim_notes-and-queries_1849-12-01_1_5</td>\n",
       "      <td>Notes and Queries  1849-12-01: Vol 1 Iss 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sim_notes-and-queries_1849-12-08_1_6</td>\n",
       "      <td>Notes and Queries  1849-12-08: Vol 1 Iss 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sim_notes-and-queries_1849-12-15_1_7</td>\n",
       "      <td>Notes and Queries  1849-12-15: Vol 1 Iss 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sim_notes-and-queries_1849-12-22_1_8</td>\n",
       "      <td>Notes and Queries  1849-12-22: Vol 1 Iss 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sim_notes-and-queries_1849-12-29_1_9</td>\n",
       "      <td>Notes and Queries  1849-12-29: Vol 1 Iss 9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  sim_notes-and-queries_1849-11-03_1_1   \n",
       "1  sim_notes-and-queries_1849-11-10_1_2   \n",
       "2  sim_notes-and-queries_1849-11-17_1_3   \n",
       "3  sim_notes-and-queries_1849-11-24_1_4   \n",
       "4  sim_notes-and-queries_1849-12-01_1_5   \n",
       "5  sim_notes-and-queries_1849-12-08_1_6   \n",
       "6  sim_notes-and-queries_1849-12-15_1_7   \n",
       "7  sim_notes-and-queries_1849-12-22_1_8   \n",
       "8  sim_notes-and-queries_1849-12-29_1_9   \n",
       "\n",
       "                                        title  \n",
       "0  Notes and Queries  1849-11-03: Vol 1 Iss 1  \n",
       "1  Notes and Queries  1849-11-10: Vol 1 Iss 2  \n",
       "2  Notes and Queries  1849-11-17: Vol 1 Iss 3  \n",
       "3  Notes and Queries  1849-11-24: Vol 1 Iss 4  \n",
       "4  Notes and Queries  1849-12-01: Vol 1 Iss 5  \n",
       "5  Notes and Queries  1849-12-08: Vol 1 Iss 6  \n",
       "6  Notes and Queries  1849-12-15: Vol 1 Iss 7  \n",
       "7  Notes and Queries  1849-12-22: Vol 1 Iss 8  \n",
       "8  Notes and Queries  1849-12-29: Vol 1 Iss 9  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT id, title\n",
    "FROM metadata\n",
    "WHERE is_index = 0\n",
    "    AND strftime('%Y', datetime) = '1849'\n",
    "\"\"\"\n",
    "results = read_sql(q, db.conn)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090d6ab",
   "metadata": {},
   "source": [
    "The data is return from the `read_sql()` function as a *pandas* dataframe.\n",
    "\n",
    "This *pandas* package provides a very powerful set of tools for working with tabular data, including being able to iterate over he rows of the table and apply a function to each one.\n",
    "\n",
    "If we define a function to download the corresponding search text file from the Internet Archive and extract the text from the downloaded archive file, we can apply that function with a particular column value taken from each row of the dataframe and add the returned content to a new column in the same dataframe.\n",
    "\n",
    "Here's an example function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3168536",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ia_utils/download_and_extract_text.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ia_utils/download_and_extract_text.py\n",
    "from internetarchive import download\n",
    "from ia_utils.get_txt_from_file import get_txt_from_file\n",
    "\n",
    "def download_and_extract_text(id_val, p=\"ia-downloads\", typ=\"searchtext\", verbose=False):\n",
    "    \"\"\"Download search text from Internet Archive, extract the text and return it.\"\"\"\n",
    "    if verbose:\n",
    "        print(f\"Downloading {id_val} issue text\")\n",
    "    if typ==\"searchtext\":\n",
    "        download(id_val, destdir=p, silent = True,\n",
    "             formats=[\"OCR Search Text\"])\n",
    "    elif typ==\"djvutxt\":\n",
    "        download(id_val, destdir=p, silent = True,\n",
    "             formats=[\"DjVuTXT\"])\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "    text = get_txt_from_file(id_val, typ=typ)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b0e2fd",
   "metadata": {},
   "source": [
    "The Python *pandas* package natively provides an `apply()` function. However, the `tqdm` progress bar package also provides an \"apply with progress bar\" function, `.progress_apply()` if we enable the appropriate extensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9b4220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dowload the tqdm progrss bar tools\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#And enable the pandas extensions\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e7b664",
   "metadata": {},
   "source": [
    "Let's apply our `download_and_extract_text()` function to each row of our records table for 1849, keeping track of progress with a progress bar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82f37643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5434626a75f4444dbf088776685d3464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>Notes and Queries  1849-11-03: Vol 1 Iss 1</td>\n",
       "      <td>\\n \\n \\n \\nNOTES anp QUERIES:\\nA Medium of En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>Notes and Queries  1849-11-10: Vol 1 Iss 2</td>\n",
       "      <td>|\\n \\nA MEDIUM OF INTER-COMMUNICATION\\nFOR\\nLI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>Notes and Queries  1849-11-17: Vol 1 Iss 3</td>\n",
       "      <td>\\n \\n \\nceeeeeeeeee eee\\nA MEDIUM OF\\nLITERAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>Notes and Queries  1849-11-24: Vol 1 Iss 4</td>\n",
       "      <td>\\n \\n \\n \\n~ NOTES anp QUERIES:\\nA MEDIUM OF\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sim_notes-and-queries_1849-12-01_1_5</td>\n",
       "      <td>Notes and Queries  1849-12-01: Vol 1 Iss 5</td>\n",
       "      <td>\\n \\n \\nNOTES anp\\nQUERIES:\\nA MEDIUM OF INTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sim_notes-and-queries_1849-12-08_1_6</td>\n",
       "      <td>Notes and Queries  1849-12-08: Vol 1 Iss 6</td>\n",
       "      <td>\\n \\nOTES\\nAND QUERIES\\nA MEDIUM OF INTER-COM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sim_notes-and-queries_1849-12-15_1_7</td>\n",
       "      <td>Notes and Queries  1849-12-15: Vol 1 Iss 7</td>\n",
       "      <td>\\n \\n \\nNOTES\\nA MEDIUM OF\\nAND QUERIES\\nINTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sim_notes-and-queries_1849-12-22_1_8</td>\n",
       "      <td>Notes and Queries  1849-12-22: Vol 1 Iss 8</td>\n",
       "      <td>\\n \\nNOTES ann QUERIES\\nA MEDIUM OF\\nINTER-CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sim_notes-and-queries_1849-12-29_1_9</td>\n",
       "      <td>Notes and Queries  1849-12-29: Vol 1 Iss 9</td>\n",
       "      <td>\\nNOTE\\nA MEDIUM OF\\nAND QUERIES\\nINTER-COMMU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  sim_notes-and-queries_1849-11-03_1_1   \n",
       "1  sim_notes-and-queries_1849-11-10_1_2   \n",
       "2  sim_notes-and-queries_1849-11-17_1_3   \n",
       "3  sim_notes-and-queries_1849-11-24_1_4   \n",
       "4  sim_notes-and-queries_1849-12-01_1_5   \n",
       "5  sim_notes-and-queries_1849-12-08_1_6   \n",
       "6  sim_notes-and-queries_1849-12-15_1_7   \n",
       "7  sim_notes-and-queries_1849-12-22_1_8   \n",
       "8  sim_notes-and-queries_1849-12-29_1_9   \n",
       "\n",
       "                                        title  \\\n",
       "0  Notes and Queries  1849-11-03: Vol 1 Iss 1   \n",
       "1  Notes and Queries  1849-11-10: Vol 1 Iss 2   \n",
       "2  Notes and Queries  1849-11-17: Vol 1 Iss 3   \n",
       "3  Notes and Queries  1849-11-24: Vol 1 Iss 4   \n",
       "4  Notes and Queries  1849-12-01: Vol 1 Iss 5   \n",
       "5  Notes and Queries  1849-12-08: Vol 1 Iss 6   \n",
       "6  Notes and Queries  1849-12-15: Vol 1 Iss 7   \n",
       "7  Notes and Queries  1849-12-22: Vol 1 Iss 8   \n",
       "8  Notes and Queries  1849-12-29: Vol 1 Iss 9   \n",
       "\n",
       "                                             content  \n",
       "0   \\n \\n \\n \\nNOTES anp QUERIES:\\nA Medium of En...  \n",
       "1  |\\n \\nA MEDIUM OF INTER-COMMUNICATION\\nFOR\\nLI...  \n",
       "2   \\n \\n \\nceeeeeeeeee eee\\nA MEDIUM OF\\nLITERAR...  \n",
       "3   \\n \\n \\n \\n~ NOTES anp QUERIES:\\nA MEDIUM OF\\...  \n",
       "4   \\n \\n \\nNOTES anp\\nQUERIES:\\nA MEDIUM OF INTE...  \n",
       "5   \\n \\nOTES\\nAND QUERIES\\nA MEDIUM OF INTER-COM...  \n",
       "6   \\n \\n \\nNOTES\\nA MEDIUM OF\\nAND QUERIES\\nINTE...  \n",
       "7   \\n \\nNOTES ann QUERIES\\nA MEDIUM OF\\nINTER-CO...  \n",
       "8   \\nNOTE\\nA MEDIUM OF\\nAND QUERIES\\nINTER-COMMU...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ia_utils.download_and_extract_text import download_and_extract_text\n",
    "\n",
    "results['content'] = results[\"id\"].progress_apply(download_and_extract_text)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5cab45",
   "metadata": {},
   "source": [
    "We can now add that data table directly to our database using the *pandas* `.to_sql()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51b2fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the issue database table\n",
    "table_name = \"issues\"\n",
    "results[[\"id\", \"content\"]].to_sql(table_name, db.conn, index=False, if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dbabc8",
   "metadata": {},
   "source": [
    "*Note that this recipe does not represent a very efficient way of handling things: the pandas dataframe is held in memory, so as we add more rows, the memory requirements to store the data increase. A more efficient approach might be to create a function that retrieves each file, adds its contents to the database, and then perhaps even deletes the downloaded file, rather than adding the content to the in-memory dataframe.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29fb543",
   "metadata": {},
   "source": [
    "Let's see if we can query it, first at the basic table level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e6d96fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>\\n \\n \\nceeeeeeeeee eee\\nA MEDIUM OF\\nLITERAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>\\n \\n \\n \\n~ NOTES anp QUERIES:\\nA MEDIUM OF\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1849-12-15_1_7</td>\n",
       "      <td>\\n \\n \\nNOTES\\nA MEDIUM OF\\nAND QUERIES\\nINTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1849-12-29_1_9</td>\n",
       "      <td>\\nNOTE\\nA MEDIUM OF\\nAND QUERIES\\nINTER-COMMU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  sim_notes-and-queries_1849-11-17_1_3   \n",
       "1  sim_notes-and-queries_1849-11-24_1_4   \n",
       "2  sim_notes-and-queries_1849-12-15_1_7   \n",
       "3  sim_notes-and-queries_1849-12-29_1_9   \n",
       "\n",
       "                                             content  \n",
       "0   \\n \\n \\nceeeeeeeeee eee\\nA MEDIUM OF\\nLITERAR...  \n",
       "1   \\n \\n \\n \\n~ NOTES anp QUERIES:\\nA MEDIUM OF\\...  \n",
       "2   \\n \\n \\nNOTES\\nA MEDIUM OF\\nAND QUERIES\\nINTE...  \n",
       "3   \\nNOTE\\nA MEDIUM OF\\nAND QUERIES\\nINTER-COMMU...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT id, content\n",
    "FROM issues\n",
    "WHERE LOWER(content) LIKE \"%customs%\"\n",
    "\"\"\"\n",
    "read_sql(q, db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22adeee8",
   "metadata": {},
   "source": [
    "This is not overly helpful, perhaps. We can do better with the full text search, which will also allow us to return a snippet around the first, or highest ranked, location of any matched search terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0cbaeda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>...At length the __custom__ became general in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>...royal domains, leases of __customs__, &amp;c., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>...the Manners and __Customs__ of Ancient Gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1849-12-01_1_5</td>\n",
       "      <td>...Morning, as was his __Custom__, attended by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sim_notes-and-queries_1849-12-15_1_7</td>\n",
       "      <td>...So far as English usages and __customs__ ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sim_notes-and-queries_1849-12-22_1_8</td>\n",
       "      <td>...Sessions House and the __Custom__ House of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sim_notes-and-queries_1849-12-29_1_9</td>\n",
       "      <td>...elucidation of old world __customs__ and ob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  sim_notes-and-queries_1849-11-10_1_2   \n",
       "1  sim_notes-and-queries_1849-11-17_1_3   \n",
       "2  sim_notes-and-queries_1849-11-24_1_4   \n",
       "3  sim_notes-and-queries_1849-12-01_1_5   \n",
       "4  sim_notes-and-queries_1849-12-15_1_7   \n",
       "5  sim_notes-and-queries_1849-12-22_1_8   \n",
       "6  sim_notes-and-queries_1849-12-29_1_9   \n",
       "\n",
       "                                                clip  \n",
       "0  ...At length the __custom__ became general in ...  \n",
       "1  ...royal domains, leases of __customs__, &c., ...  \n",
       "2  ...the Manners and __Customs__ of Ancient Gree...  \n",
       "3  ...Morning, as was his __Custom__, attended by...  \n",
       "4  ...So far as English usages and __customs__ ar...  \n",
       "5  ...Sessions House and the __Custom__ House of ...  \n",
       "6  ...elucidation of old world __customs__ and ob...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_term = \"customs\"\n",
    "\n",
    "q = f\"\"\"\n",
    "SELECT id, snippet(issues_fts, -1, \"__\", \"__\", \"...\", 10) as clip\n",
    "FROM issues_fts WHERE issues_fts MATCH {db.quote(search_term)} ;\n",
    "\"\"\"\n",
    "\n",
    "read_sql(q, db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5383ecab",
   "metadata": {},
   "source": [
    "This is okay as far as is goes: we can identify *issues* of *Notes and Queries* that contain a particular search term, retrieve the whole document, and even display a concordance for the first (or highest ranking) occurrence of the search term(s) to provide context for the response. But it's not ideal. For example, to display a concordance of each term in the full text document that matches our search term, we need to generate our own concordance, which may be difficulat where matches are inexact (for example if the match relies on stemming). There are also many pages in each issue of *Notes and Queries* and it would be useful if we could get the result at a better level of granularity.\n",
    "\n",
    "The `ouseful_sqlite_search_utils` package includes various functions for allowing us to tunnel into a text document to retrieve The tools aren't necessarily the *fastest* utilities to run, particularly on large databases, but they get their eventually.\n",
    "\n",
    "One particular utility will split a document into sentences and return each sentence on a separate row of a newly created virtual table. We can then search within these values for our search term, although we are limited to running *exact match* queries, rather than the more forgiving full text search queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d146a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'sim_notes-and-queries_1849-11-10_1_2',\n",
       "  'sentence': 'An examination of the structure of books of this period would confirm this view, and show that their apparent clumsiness is to be explained by the facility it was then the custom to afford for the interpolation or extraction of “sheets,” by a contrivance somewhat resembling that\\npapers in a cover, and known as the “ patent leaf-holder,”\\n'},\n",
       " {'id': 'sim_notes-and-queries_1849-11-10_1_2',\n",
       "  'sentence': 'At length the custom became general in Aden ; and it was not only drunk in the\\nnight by those who were desirous of being kept awake, but in the day for the sake of its other agreeable qualities.'},\n",
       " {'id': 'sim_notes-and-queries_1849-11-10_1_2',\n",
       "  'sentence': 'From hence the custom extended itself to many other towns of Arabia, particularly to Medina, and then to Grand Cairo in Egypt, where the dervises of Yemen, who lived in a district by themselves, drank coffee on the nights they intended to spend in\\n| devotion.'},\n",
       " {'id': 'sim_notes-and-queries_1849-11-10_1_2',\n",
       "  'sentence': 'In that year, Soliman Aga, ambassador from the Sultan Mahomet the Fourth, arrived, who, with his retinue, brought a considerable quantity of coffee with them, and made presents of it to per- sons both of the court and city, and is sup- posed to have established the custom of drinking it.'},\n",
       " {'id': 'sim_notes-and-queries_1849-11-10_1_2',\n",
       "  'sentence': 'How often\\nman stumble upon some elucidation of a doubtful |\\nphrase, or disputed passage ;—some illustration of an obsolete custom hitherto unnoticed ; — some biogra- phical aneedote or precise date hitherto unrecorded ;— some book, or some edition, hitherto unknown or im- perfectly described.'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ouseful_sqlite_search_utils import snippets\n",
    "\n",
    "snippets.register_snippets(db.conn)\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT * FROM\n",
    "    (SELECT id, sentence\n",
    "     FROM issues, get_sentences(1, NULL, issues.content)\n",
    "     WHERE issues.id = \"sim_notes-and-queries_1849-11-10_1_2\")\n",
    "WHERE sentence LIKE \"% custom %\"\n",
    "\"\"\"\n",
    "\n",
    "# Show the full result record in each case\n",
    "read_sql(q, db.conn).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746e904a",
   "metadata": {},
   "source": [
    "### Extracting Pages\n",
    "\n",
    "To make for more efficient granular searching, it would be useful if our content was stored in a more granular way.\n",
    "\n",
    "Ideally, we would extract items at the \"article\" level, but there is no simple way of chunking the document at this level. We could process it to extract items at the sentence or paragraph level and add those to their own table, but that might be *too* granular.\n",
    "\n",
    "However, by inspection of the files available for each issue, there appears to be another level of organisation that we can access: the *page* level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af20b944",
   "metadata": {},
   "source": [
    "*Page* metadata is provided in the the form of two files:\n",
    "\n",
    "- `OCR Page Index`: downloaded as a compressed `.gz` file the expanded file contains a list of lists. Each inner list contains four integers and each page has an associated inner list. The first and second integers in each inner list are the character count in the search text file representing the first and last characters on the corresponding page;\n",
    "- `Page Numbers JSON`: the pages numbers JSON file, which is downloaded as an uncompressed JSON file contains a JSON object with a `\"pages\"` attribute that returns a list of records; each record has four attributes: `\"leafNum\": int` (starting with index value 1), `\"ocr_value\": list` (a list of candidate OCR values), `\"pageNumber\": str` and `\"confidence\": float`. A top-level `\"confidence\"` attribute gives an indication of how likely it is that page numbers are available across the whole document.\n",
    "\n",
    "We also need the `OCR Search Text` file.\n",
    "\n",
    "Let's get a complete set of necessary files for a few sample records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caf575ea",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ia_utils/download_ia_records_by_format.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ia_utils/download_ia_records_by_format.py\n",
    "# Dowload the tqdm progress bar tools\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "from internetarchive import download\n",
    "\n",
    "def download_ia_records_by_format(records, path=\".\", formats=None):\n",
    "    \"\"\"Download records from Internet Archive given ID and desired format(s)\"\"\"\n",
    "    formats = formats if formats else [\"OCR Search Text\", \"OCR Page Index\", \"Page Numbers JSON\"]\n",
    "    \n",
    "    for record in tqdm(records):\n",
    "        _id = record['id']\n",
    "        download(_id, destdir=path,\n",
    "                 formats=formats,\n",
    "                 silent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0707ca5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30991d914bc4312b9f68ef380a4980b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ia_utils.download_ia_records_by_format import download_ia_records_by_format\n",
    "\n",
    "# Grab page counts and page structure files\n",
    "sample_records = data_records[:5]\n",
    "\n",
    "download_ia_records_by_format(sample_records, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166bbe36",
   "metadata": {},
   "source": [
    "We now need to figure out how to open and parse the page index and page numbers files, and check the lists are the correct lengths.\n",
    "\n",
    "The Python `zip` function  lets us \"zip\" together elements from different, parallel lists. We can also insert the same item, repeatedly, into each row using the `itertools.repeat()` function to generate as many repetitions of the same character as are required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecef7dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d4189",
   "metadata": {},
   "source": [
    "Example of using `itertools.repeat()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5c74a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1, 'x'), ('a', 2, 'y')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of list\n",
    "list(zip(itertools.repeat(\"a\"), [1, 2], [\"x\",\"y\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce06c741",
   "metadata": {},
   "source": [
    "We can now use this approach to create a zipped combination of the record ID values, page numbers and page character indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a143af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sim_notes-and-queries_1849-11-03_1_1',\n",
       "  {'leafNum': 1, 'ocr_value': [], 'pageNumber': '', 'confidence': 0},\n",
       "  [0, 301, 559, 14345]),\n",
       " ('sim_notes-and-queries_1849-11-03_1_1',\n",
       "  {'leafNum': 2, 'ocr_value': ['4', '3'], 'pageNumber': '', 'confidence': 0},\n",
       "  [301, 307, 14345, 15954]),\n",
       " ('sim_notes-and-queries_1849-11-03_1_1',\n",
       "  {'leafNum': 3, 'ocr_value': ['2'], 'pageNumber': '2', 'confidence': 100},\n",
       "  [307, 3212, 15954, 101879]),\n",
       " ('sim_notes-and-queries_1849-11-03_1_1',\n",
       "  {'leafNum': 4, 'ocr_value': ['3'], 'pageNumber': '3', 'confidence': 100},\n",
       "  [3212, 7431, 101879, 228974]),\n",
       " ('sim_notes-and-queries_1849-11-03_1_1',\n",
       "  {'leafNum': 5, 'ocr_value': [], 'pageNumber': '4', 'confidence': 100},\n",
       "  [7431, 12267, 228974, 370105])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "#for record in tqdm(sample_records):\n",
    "\n",
    "record = sample_records[0]\n",
    "\n",
    "id_val = record['id']\n",
    "p_ = Path(dirname) / id_val \n",
    "\n",
    "# Get the page numbers\n",
    "with open(p_ / f'{id_val}_page_numbers.json', 'r') as f:\n",
    "    page_numbers = json.load(f)\n",
    "\n",
    "# Get the page character indexes\n",
    "with gzip.open(p_ / f'{id_val}_hocr_pageindex.json.gz', 'rb') as g:\n",
    "    # The last element seems to be redundant\n",
    "    page_indexes = json.loads(g.read().decode('utf-8'))[:-1]\n",
    "\n",
    "# Optionally text the record counts are the same for page numbers and character indexes\n",
    "#assert len(page_indexes) == len(page_numbers['pages'])\n",
    "\n",
    "# Preview the result\n",
    "list(zip(itertools.repeat(id_val), page_numbers['pages'], page_indexes))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2254dcd1",
   "metadata": {},
   "source": [
    "We could add this page related data directly to the pages table, or we could create another simple database table to store it.\n",
    "\n",
    "Here's what a separate table might look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cba273c",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ia_utils/create_db_table_pages_metadata.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ia_utils/create_db_table_pages_metadata.py\n",
    "def create_db_table_pages_metadata(db, drop=True):\n",
    "    if drop:\n",
    "        db[\"pages_metadata\"].drop(ignore=True)\n",
    "    db[\"pages_metadata\"].create({\n",
    "        \"id\": str,\n",
    "        \"page_idx\": int, # This is just a count as we work through the pages \n",
    "        \"page_char_start\": int,\n",
    "        \"page_char_end\": int,\n",
    "        \"page_leaf_num\": int, \n",
    "        \"page_num\": str,\n",
    "        \"page_num_conf\": float # A confidence value relating to the page number detection\n",
    "    }, pk=(\"id\", \"page_idx\")) # compound foreign keys not currently available via sqlite_utils?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600b5aa0",
   "metadata": {},
   "source": [
    "Import that function from the local package and run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2e7ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ia_utils.create_db_table_pages_metadata import create_db_table_pages_metadata\n",
    "\n",
    "create_db_table_pages_metadata(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61e0f69",
   "metadata": {},
   "source": [
    "The following function \"zips\" together the contents of the page index and page numbers files. Each \"line item\" is a rather unwieldy mixmatch of elements, but we'll deal with those in a moment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11a2375a",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ia_utils/raw_pages_metadata.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ia_utils/raw_pages_metadata.py\n",
    "import itertools\n",
    "import json\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "\n",
    "def raw_pages_metadata(id_val, dirname=\"ia-downloads\"):\n",
    "    \"\"\"Get page metadata.\"\"\"\n",
    "\n",
    "    p_ = Path(dirname) / id_val\n",
    "\n",
    "    # Get the page numbers\n",
    "    with open(p_ / f'{id_val}_page_numbers.json', 'r') as f:\n",
    "        # We can ignore the last value\n",
    "        page_numbers = json.load(f)\n",
    "    \n",
    "    # Get the page character indexes\n",
    "    with gzip.open(p_ / f'{id_val}_hocr_pageindex.json.gz', 'rb') as g:\n",
    "        # The last element seems to be redundant\n",
    "        page_indexes = json.loads(g.read().decode('utf-8'))[:-1]\n",
    "\n",
    "    # Add the id and an index count\n",
    "    return zip(itertools.repeat(id_val), range(len(page_indexes)),\n",
    "               page_numbers['pages'], page_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94261676",
   "metadata": {},
   "source": [
    "For each line item in the zipped datastructure, we can parse out values into a more readable data object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "157aaf79",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ia_utils/parse_page_metadata.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ia_utils/parse_page_metadata.py\n",
    "\n",
    "def parse_page_metadata(item):\n",
    "    \"\"\"Parse out page attributes from the raw page metadata construct.\"\"\"\n",
    "    _id = item[0]\n",
    "    page_idx = item[1]\n",
    "    _page_nums = item[2]\n",
    "    ix = item[3]\n",
    "    obj = {'id': _id,\n",
    "           'page_idx': page_idx, # Maintain our own count, just in case; should be page_leaf_num-1\n",
    "           'page_char_start': ix[0],\n",
    "           'page_char_end': ix[1],\n",
    "           'page_leaf_num': _page_nums['leafNum'],\n",
    "           'page_num': _page_nums['pageNumber'],\n",
    "           'page_num_conf':_page_nums['confidence']\n",
    "          }\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f384372",
   "metadata": {},
   "source": [
    "Let's see how that looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2da96ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'sim_notes-and-queries_1849-11-03_1_1', 'page_idx': 0, 'page_char_start': 0, 'page_char_end': 301, 'page_leaf_num': 1, 'page_num': '', 'page_num_conf': 0}\n"
     ]
    }
   ],
   "source": [
    "from ia_utils.raw_pages_metadata import raw_pages_metadata\n",
    "from ia_utils.parse_page_metadata import parse_page_metadata\n",
    "\n",
    "sample_pages_metadata_item = raw_pages_metadata(id_val)\n",
    "\n",
    "for pmi in sample_pages_metadata_item:\n",
    "    print(parse_page_metadata(pmi))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b47ab7",
   "metadata": {},
   "source": [
    "We can now trivially add the page metadata to the `pages_metadata` database table. Let's try it with our sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "992152af",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ia_utils/add_page_metadata_to_db.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ia_utils/add_page_metadata_to_db.py\n",
    "from ia_utils.parse_page_metadata import parse_page_metadata\n",
    "from ia_utils.raw_pages_metadata import raw_pages_metadata\n",
    "\n",
    "def add_page_metadata_to_db(db, records, dirname=\"ia-downloads\", verbose=False):\n",
    "    \"\"\"Add page metadata to database.\"\"\"\n",
    "    \n",
    "    for record in records:\n",
    "        id_val = record[\"id\"]\n",
    "        if verbose:\n",
    "            print(id_val)\n",
    "            \n",
    "        records = [parse_page_metadata(pmi) for pmi in raw_pages_metadata(id_val, dirname)]\n",
    "    \n",
    "        # Add records to the database\n",
    "        db[\"pages_metadata\"].insert_all(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4942d23e",
   "metadata": {},
   "source": [
    "And run it with the page metadata records selected via a `id_val`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38991a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ia_utils.add_page_metadata_to_db import add_page_metadata_to_db\n",
    "\n",
    "# Clear the db table\n",
    "db[\"pages_metadata\"].delete_where()\n",
    "\n",
    "# Add the metadata to the table\n",
    "add_page_metadata_to_db(db, sample_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6b9722",
   "metadata": {},
   "source": [
    "Let's see how that looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "129bb281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>page_idx</th>\n",
       "      <th>page_char_start</th>\n",
       "      <th>page_char_end</th>\n",
       "      <th>page_leaf_num</th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_num_conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>1</td>\n",
       "      <td>301</td>\n",
       "      <td>307</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>3212</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>3</td>\n",
       "      <td>3212</td>\n",
       "      <td>7431</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>4</td>\n",
       "      <td>7431</td>\n",
       "      <td>12267</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  page_idx  page_char_start  \\\n",
       "0  sim_notes-and-queries_1849-11-03_1_1         0                0   \n",
       "1  sim_notes-and-queries_1849-11-03_1_1         1              301   \n",
       "2  sim_notes-and-queries_1849-11-03_1_1         2              307   \n",
       "3  sim_notes-and-queries_1849-11-03_1_1         3             3212   \n",
       "4  sim_notes-and-queries_1849-11-03_1_1         4             7431   \n",
       "\n",
       "   page_char_end  page_leaf_num page_num  page_num_conf  \n",
       "0            301              1                     0.0  \n",
       "1            307              2                     0.0  \n",
       "2           3212              3        2          100.0  \n",
       "3           7431              4        3          100.0  \n",
       "4          12267              5        4          100.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_sql\n",
    "\n",
    "q = \"SELECT * FROM pages_metadata LIMIT 5\"\n",
    "\n",
    "read_sql(q, db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd5aaf",
   "metadata": {},
   "source": [
    "Alternatively, we can view the results as a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a4164e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'sim_notes-and-queries_1849-11-03_1_1',\n",
       "  'page_idx': 0,\n",
       "  'page_char_start': 0,\n",
       "  'page_char_end': 301,\n",
       "  'page_leaf_num': 1,\n",
       "  'page_num': '',\n",
       "  'page_num_conf': 0.0},\n",
       " {'id': 'sim_notes-and-queries_1849-11-03_1_1',\n",
       "  'page_idx': 1,\n",
       "  'page_char_start': 301,\n",
       "  'page_char_end': 307,\n",
       "  'page_leaf_num': 2,\n",
       "  'page_num': '',\n",
       "  'page_num_conf': 0.0},\n",
       " {'id': 'sim_notes-and-queries_1849-11-03_1_1',\n",
       "  'page_idx': 2,\n",
       "  'page_char_start': 307,\n",
       "  'page_char_end': 3212,\n",
       "  'page_leaf_num': 3,\n",
       "  'page_num': '2',\n",
       "  'page_num_conf': 100.0}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_sql(q, db.conn).to_dict(orient=\"records\")[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c6b35",
   "metadata": {},
   "source": [
    "For each file containg the search text for a particular issue, we also need a routine to extract the page level content. Which is to say, we need to chunk the content based on character indices associated with the first and last characters on each page in the corresponding search text file. \n",
    "\n",
    "This essentially boils down to:\n",
    "\n",
    "- grabbing the page index values;\n",
    "- grabbing the page search text;\n",
    "- chunking the search text according to the page index values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7265ae6",
   "metadata": {},
   "source": [
    "We can apply a page chunker at the document level, paginating the content file, and adding things to the database.\n",
    "\n",
    "The following function will load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b0b68e1",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ia_utils/chunk_page_text.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ia_utils/chunk_page_text.py\n",
    "\n",
    "from pandas import read_sql\n",
    "from ia_utils.get_txt_from_file import get_txt_from_file\n",
    "\n",
    "def chunk_page_text(db, id_val):\n",
    "    \"\"\"Chunk text according to page_index values.\"\"\"\n",
    "    \n",
    "    q = f'SELECT * FROM pages_metadata WHERE id=\"{id_val}\"'\n",
    "    page_indexes = read_sql(q, db.conn).to_dict(orient=\"records\")\n",
    "    \n",
    "    text = get_txt_from_file(id_val)\n",
    "        \n",
    "    for ix in page_indexes:\n",
    "        ix[\"page_text\"] = text[ix[\"page_char_start\"]:ix[\"page_char_end\"]].strip()\n",
    "\n",
    "    return page_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021cdef6",
   "metadata": {},
   "source": [
    "Let's see if we've managed to pull out some page text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4cb5a4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'sim_notes-and-queries_1849-11-03_1_1',\n",
       "  'page_idx': 0,\n",
       "  'page_char_start': 0,\n",
       "  'page_char_end': 301,\n",
       "  'page_leaf_num': 1,\n",
       "  'page_num': '',\n",
       "  'page_num_conf': 0.0,\n",
       "  'page_text': 'NOTES anp QUERIES:\\nA Medium of Enter-Communication\\nFOR\\nLITERARY MEN, ARTISTS, ANTIQUARIES, GENEALOGISTS, ETC.\\n‘* When found, make a note of.’—Carrain Corrie.\\nVOLUME FIRST.\\nNoveMBER, 1849—May, 1850.\\nLONDON: GEORGE BELL, 186. FLEET STREET 1850.\\n[SOLD BY ALL BOOKSELLERS AND NEWSMEN. |'},\n",
       " {'id': 'sim_notes-and-queries_1849-11-03_1_1',\n",
       "  'page_idx': 1,\n",
       "  'page_char_start': 301,\n",
       "  'page_char_end': 307,\n",
       "  'page_leaf_num': 2,\n",
       "  'page_num': '',\n",
       "  'page_num_conf': 0.0,\n",
       "  'page_text': ''},\n",
       " {'id': 'sim_notes-and-queries_1849-11-03_1_1',\n",
       "  'page_idx': 2,\n",
       "  'page_char_start': 307,\n",
       "  'page_char_end': 3212,\n",
       "  'page_leaf_num': 3,\n",
       "  'page_num': '2',\n",
       "  'page_num_conf': 100.0,\n",
       "  'page_text': 'NOTES ann QUERIES:\\nA MEDIUM OF\\n——_——s\\nINTER-COMMUNICATION\\nFOR\\nLITERARY MEN, ARTISTS,\\nANTIQUARIES, GENEALOGISTS, ETC.\\n“When found, make a note of.” — Carrain Currie.\\nNOTES AND QUERIES.\\nTue nature and design of the present work have been so fully stated in the Prospectus, and are indeed so far explained by its very Title, that it is unnecessary to occupy any great portion of its first number with details on the subject. We are under no temptation to fill its columns with an account of what we hope future numbers will be. Indeed, we would rather give a specimen than a de- scription; and only regret that, from the wide range of subjects which it is intended to embrace, and the correspondence and contri- butions of various kinds which we are led to expect, even this can only be done gradually. A few words of introduction and explanation may, however, be allowed; and, indeed, ought to be prefixed, that we may be understood by those readers who have not seen our Pro- spectus.\\n“ WHEN FOUND, MAKE A NOTE OF,” is a most admirable rule; and if the excellent Captain had never uttered another word, he might have passed for a profound philosopher. It is a rule which should shine in gilt letters on the gingerbread of youth, and the specta- ele-case of age. Every man who reads with any view beyond mere pastime, knows the value of it. Every one, more or less, acts upon it. Every one regrets and suffers who\\n \\nSATURDAY, NOVEMBER 3. 1849.\\nPrice Threepence. Stamped Edition, 4 d.\\n \\nneglects it. There is some trouble in it, to be sure; but in what good thing is there not? and what trouble does it save! Nay, what mischief! Half the lies that are current in the world owe their origin to a misplaced confidence in memory, rather than to inten- tional falsehood. We have never known more than one man who could deliberately and con- scientiously say that his memory had never deceived him; and he (when he saw that he had excited the surprise of his hearers, espe- cially those who knew how many years he had spent in the management of important com- mercial affairs) used to. add, — because he had never trusted it; but had uniformly written down what he was anxious to remember.\\nBut, on the other hand, it cannot be denied that reading and writing men, of moderate industry, who act on this rule for any con- siderable length of time, will aceumulate a good deal of matter in various forms, shapes, and sizes—some more, some less legible and intelligible —some unposted in old pocket books — some on whole or half sheets, or mere seraps of paper, and backs of letters— some, lost sight of and forgotten, stuffing out old portfolios, or getting smoky edges in bundles tied up with faded tape. There are, we are quite sure, countless boxes and drawers, and pigeon-holes of such things, which want look- ing over, and would well repay the trouble.\\n \\n \\nFOURTH EDITION.'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ia_utils.chunk_page_text import chunk_page_text\n",
    "\n",
    "# Create a sample index ID\n",
    "sample_id_val = sample_records[0][\"id\"]\n",
    "\n",
    "# Get the chunked text back as part of the metadata record\n",
    "sample_pages = chunk_page_text(db, sample_id_val)\n",
    "\n",
    "sample_pages[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4444b608",
   "metadata": {},
   "source": [
    "### Modifying the `pages_metadata` Table in the Database\n",
    "\n",
    "Using the `chunk_page_text()` function, we can add page content to our pages metadata *in-memory*. But what if we want to add it to the database. The `pages_metadata` already exists, but does not include a `text` column. However, we can modify that table to include just such a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb1c2148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table pages_metadata (id, page_idx, page_char_start, page_char_end, page_leaf_num, page_num, page_num_conf, page_text)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[\"pages_metadata\"].add_column(\"page_text\", str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca4a8de",
   "metadata": {},
   "source": [
    "We can also enable a full text search facility over the table. Our interest is primarily in searching over the `page_text`, but if we include a couple of other columns, that can help us key into records in other tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2ecaa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table pages_metadata (id, page_idx, page_char_start, page_char_end, page_leaf_num, page_num, page_num_conf, page_text)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable full text search\n",
    "# This creates an extra virtual table to support the full text search\n",
    "db[\"pages_metadata_fts\"].drop(ignore=True)\n",
    "db[\"pages_metadata\"].enable_fts([\"id\", \"page_idx\", \"page_text\"], create_triggers=True, tokenize=\"porter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607de6a7",
   "metadata": {},
   "source": [
    "We can now update the records in the `pages_metadata` table so they include the `page_text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f3a8f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = f'SELECT DISTINCT(id) FROM pages_metadata;'\n",
    "id_vals = read_sql(q, db.conn).to_dict(orient=\"records\")\n",
    "\n",
    "for sample_id_val in id_vals:\n",
    "    updated_pages = chunk_page_text(db, sample_id_val[\"id\"])\n",
    "    db[\"pages_metadata\"].upsert_all(updated_pages, pk=(\"id\", \"page_idx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e76ee",
   "metadata": {},
   "source": [
    "We should now be able to search at the page level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32ef34ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>page_idx</th>\n",
       "      <th>page_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>5</td>\n",
       "      <td>22 NOTES\\n \\nAND QUERIES.\\nCatalogue — in whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>8</td>\n",
       "      <td>Nov. 10. 1849.)\\nNOTES AND QUERIES.\\n25\\n \\nne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>9</td>\n",
       "      <td>bring with him some coffee, which he believed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>12</td>\n",
       "      <td>Nov. 10. 1849.]\\nActing her passions on our st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>14</td>\n",
       "      <td>~—\\n \\n|\\n \\nNov. 10. 1849.]\\nNOTES AND QUERIE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>8</td>\n",
       "      <td>= 17. 1849.] }\\nreceive his representations an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>2</td>\n",
       "      <td>~vwe eS | FY\\nweNTe 6 FS-r—lCUcUOrlClC hLOOlhC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>6</td>\n",
       "      <td>NOTES AND QUERIES.\\n \\n \\n \\nNov. 24. 1849.]\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>15</td>\n",
       "      <td>NOTES AND QUERIES.\\nJust published, Part II., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sim_notes-and-queries_1849-12-01_1_5</td>\n",
       "      <td>5</td>\n",
       "      <td>NOTES AND QUERIES.\\n \\nmore than three Passeng...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  page_idx  \\\n",
       "0  sim_notes-and-queries_1849-11-10_1_2         5   \n",
       "1  sim_notes-and-queries_1849-11-10_1_2         8   \n",
       "2  sim_notes-and-queries_1849-11-10_1_2         9   \n",
       "3  sim_notes-and-queries_1849-11-10_1_2        12   \n",
       "4  sim_notes-and-queries_1849-11-10_1_2        14   \n",
       "5  sim_notes-and-queries_1849-11-17_1_3         8   \n",
       "6  sim_notes-and-queries_1849-11-24_1_4         2   \n",
       "7  sim_notes-and-queries_1849-11-24_1_4         6   \n",
       "8  sim_notes-and-queries_1849-11-24_1_4        15   \n",
       "9  sim_notes-and-queries_1849-12-01_1_5         5   \n",
       "\n",
       "                                           page_text  \n",
       "0  22 NOTES\\n \\nAND QUERIES.\\nCatalogue — in whic...  \n",
       "1  Nov. 10. 1849.)\\nNOTES AND QUERIES.\\n25\\n \\nne...  \n",
       "2  bring with him some coffee, which he believed ...  \n",
       "3  Nov. 10. 1849.]\\nActing her passions on our st...  \n",
       "4  ~—\\n \\n|\\n \\nNov. 10. 1849.]\\nNOTES AND QUERIE...  \n",
       "5  = 17. 1849.] }\\nreceive his representations an...  \n",
       "6  ~vwe eS | FY\\nweNTe 6 FS-r—lCUcUOrlClC hLOOlhC...  \n",
       "7  NOTES AND QUERIES.\\n \\n \\n \\nNov. 24. 1849.]\\n...  \n",
       "8  NOTES AND QUERIES.\\nJust published, Part II., ...  \n",
       "9  NOTES AND QUERIES.\\n \\nmore than three Passeng...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_term = \"customs\"\n",
    "\n",
    "q = f\"\"\"\n",
    "SELECT * FROM pages_metadata_fts\n",
    "WHERE pages_metadata_fts MATCH {db.quote(search_term)};\n",
    "\"\"\"\n",
    "\n",
    "read_sql(q, db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c01f20",
   "metadata": {},
   "source": [
    "We can then bring in additional columns from the original `pages_metadata` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5f5ba91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_leaf_num</th>\n",
       "      <th>id</th>\n",
       "      <th>page_idx</th>\n",
       "      <th>page_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>5</td>\n",
       "      <td>22 NOTES\\n \\nAND QUERIES.\\nCatalogue — in whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>8</td>\n",
       "      <td>Nov. 10. 1849.)\\nNOTES AND QUERIES.\\n25\\n \\nne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>9</td>\n",
       "      <td>bring with him some coffee, which he believed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>12</td>\n",
       "      <td>Nov. 10. 1849.]\\nActing her passions on our st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>14</td>\n",
       "      <td>~—\\n \\n|\\n \\nNov. 10. 1849.]\\nNOTES AND QUERIE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>8</td>\n",
       "      <td>= 17. 1849.] }\\nreceive his representations an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>2</td>\n",
       "      <td>~vwe eS | FY\\nweNTe 6 FS-r—lCUcUOrlClC hLOOlhC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>6</td>\n",
       "      <td>NOTES AND QUERIES.\\n \\n \\n \\nNov. 24. 1849.]\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>65</td>\n",
       "      <td>16</td>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>15</td>\n",
       "      <td>NOTES AND QUERIES.\\nJust published, Part II., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>71</td>\n",
       "      <td>6</td>\n",
       "      <td>sim_notes-and-queries_1849-12-01_1_5</td>\n",
       "      <td>5</td>\n",
       "      <td>NOTES AND QUERIES.\\n \\nmore than three Passeng...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  page_num  page_leaf_num                                    id  page_idx  \\\n",
       "0       23              6  sim_notes-and-queries_1849-11-10_1_2         5   \n",
       "1       26              9  sim_notes-and-queries_1849-11-10_1_2         8   \n",
       "2       27             10  sim_notes-and-queries_1849-11-10_1_2         9   \n",
       "3       30             13  sim_notes-and-queries_1849-11-10_1_2        12   \n",
       "4       32             15  sim_notes-and-queries_1849-11-10_1_2        14   \n",
       "5       42              9  sim_notes-and-queries_1849-11-17_1_3         8   \n",
       "6       52              3  sim_notes-and-queries_1849-11-24_1_4         2   \n",
       "7       56              7  sim_notes-and-queries_1849-11-24_1_4         6   \n",
       "8       65             16  sim_notes-and-queries_1849-11-24_1_4        15   \n",
       "9       71              6  sim_notes-and-queries_1849-12-01_1_5         5   \n",
       "\n",
       "                                           page_text  \n",
       "0  22 NOTES\\n \\nAND QUERIES.\\nCatalogue — in whic...  \n",
       "1  Nov. 10. 1849.)\\nNOTES AND QUERIES.\\n25\\n \\nne...  \n",
       "2  bring with him some coffee, which he believed ...  \n",
       "3  Nov. 10. 1849.]\\nActing her passions on our st...  \n",
       "4  ~—\\n \\n|\\n \\nNov. 10. 1849.]\\nNOTES AND QUERIE...  \n",
       "5  = 17. 1849.] }\\nreceive his representations an...  \n",
       "6  ~vwe eS | FY\\nweNTe 6 FS-r—lCUcUOrlClC hLOOlhC...  \n",
       "7  NOTES AND QUERIES.\\n \\n \\n \\nNov. 24. 1849.]\\n...  \n",
       "8  NOTES AND QUERIES.\\nJust published, Part II., ...  \n",
       "9  NOTES AND QUERIES.\\n \\nmore than three Passeng...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_term = \"customs\"\n",
    "\n",
    "q = f\"\"\"\n",
    "SELECT page_num, page_leaf_num, pages_metadata_fts.* FROM pages_metadata_fts, pages_metadata\n",
    "WHERE pages_metadata_fts MATCH {db.quote(search_term)} \n",
    "    AND pages_metadata.id = pages_metadata_fts.id\n",
    "    AND pages_metadata.page_idx = pages_metadata_fts.page_idx;\n",
    "\"\"\"\n",
    "\n",
    "read_sql(q, db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ffe2a6",
   "metadata": {},
   "source": [
    "### Automatically Populating the `pages` Table from the `issues` Table\n",
    "\n",
    "Rather than manually adding the page data to the `pages` table, we can automatically create the `pages` table from the content contained in the `issues` table and the page metadata in the `metadata` table.\n",
    "\n",
    "TO DO  - CREATE TABLE AS ;\n",
    "- maybe also as an extra demonstrate how to generate this automatically from a trigger\n",
    "- discuss various advantages and disadvantages of each approach; one is a step wise pipeline (create as) other is reactive and automatic ( trigger)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
