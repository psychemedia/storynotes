{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27ba201e",
   "metadata": {},
   "source": [
    "# Doc2Vec Searching of Lang Database\n",
    "\n",
    "In this recipe, I will demonstrate the use of the `gensim` package and a simple `doc2vec` model trained on stories from the Lang coloured fairy books to support semantic retrieval of fairy stories.\n",
    "\n",
    "The approach can be summarised as follows:\n",
    "\n",
    "- generate a vocabulary of terms representative of the search corpus;\n",
    "- generate a vector space where each dimension is a word in the vocabulary;\n",
    "- generate a vector for each document or search phrase;\n",
    "- retrieve documents based on similarity between document vector and search phrase vector.\n",
    "\n",
    "The following recipe is inspired by [How to make a search engine on Movies Description](https://github.com/ppontisso/Text-Search-Engine-using-Doc2Vec-and-TF-IDF/blob/master/notebook.ipynb).\n",
    "\n",
    "See also https://www.kaggle.com/hgilles06/a-doc2vec-search-engine-cord19-new-version for ideas on a possible graphical user interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0029a2c6",
   "metadata": {},
   "source": [
    "## Connecting to the Database\n",
    "\n",
    "We're going to work with our Lang fairy story database, so let's set up a connection to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e8d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlite_utils import Database\n",
    "\n",
    "db_name = \"demo.db\"\n",
    "\n",
    "db = Database(db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fad7275",
   "metadata": {},
   "source": [
    "Let's remind ourselves of the database structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c265fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE [books] (\n",
      "   [book] TEXT,\n",
      "   [title] TEXT,\n",
      "   [text] TEXT,\n",
      "   [last_para] TEXT,\n",
      "   [first_line] TEXT,\n",
      "   [provenance] TEXT,\n",
      "   [chapter_order] INTEGER,\n",
      "   PRIMARY KEY ([book], [title])\n",
      ");\n",
      "CREATE TABLE [books_metadata] (\n",
      "   [title] TEXT,\n",
      "   [year] INTEGER\n",
      ");\n",
      "CREATE VIRTUAL TABLE [books_fts] USING FTS5 (\n",
      "    [title], [text],\n",
      "    content=[books]\n",
      ");\n",
      "CREATE TABLE 'books_fts_data'(id INTEGER PRIMARY KEY, block BLOB);\n",
      "CREATE TABLE 'books_fts_idx'(segid, term, pgno, PRIMARY KEY(segid, term)) WITHOUT ROWID;\n",
      "CREATE TABLE 'books_fts_docsize'(id INTEGER PRIMARY KEY, sz BLOB);\n",
      "CREATE TABLE 'books_fts_config'(k PRIMARY KEY, v) WITHOUT ROWID;\n",
      "CREATE TRIGGER [books_ai] AFTER INSERT ON [books] BEGIN\n",
      "  INSERT INTO [books_fts] (rowid, [title], [text]) VALUES (new.rowid, new.[title], new.[text]);\n",
      "END;\n",
      "CREATE TRIGGER [books_ad] AFTER DELETE ON [books] BEGIN\n",
      "  INSERT INTO [books_fts] ([books_fts], rowid, [title], [text]) VALUES('delete', old.rowid, old.[title], old.[text]);\n",
      "END;\n",
      "CREATE TRIGGER [books_au] AFTER UPDATE ON [books] BEGIN\n",
      "  INSERT INTO [books_fts] ([books_fts], rowid, [title], [text]) VALUES('delete', old.rowid, old.[title], old.[text]);\n",
      "  INSERT INTO [books_fts] (rowid, [title], [text]) VALUES (new.rowid, new.[title], new.[text]);\n",
      "END;\n"
     ]
    }
   ],
   "source": [
    "print(db.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b58a3",
   "metadata": {},
   "source": [
    "Recall that we can perform a full text search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ffa3bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hansel And Grettel\n"
     ]
    }
   ],
   "source": [
    "#q = 'king \"three sons\" gold'\n",
    "q = 'hansel witch'\n",
    "_q = f'SELECT title FROM books_fts WHERE books_fts MATCH {db.quote(q)} ;'\n",
    "\n",
    "for row in db.query(_q):\n",
    "    print(row[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e490554",
   "metadata": {},
   "source": [
    "We can randomly sample a selection of rows with a query of the following form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4210c704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "King Lindorm\n",
      "Long, Broad, And Quickeye\n",
      "The Princess Bella-Flor\n",
      "The Hoodie-Crow.\n",
      "Prince Featherhead And The Princess Celandine\n"
     ]
    }
   ],
   "source": [
    "# Via https://gist.github.com/alecco/9976dab8fda8256ed403054ed0a65d7b\n",
    "\n",
    "_q_random_sample = \"\"\"\n",
    "SELECT * FROM books\n",
    "WHERE rowid IN (SELECT rowid FROM books\n",
    "                WHERE title NOT LIKE \"Preface\"\n",
    "                ORDER BY random() LIMIT {});\n",
    "\"\"\"\n",
    "\n",
    "for row in db.query(_q_random_sample.format(5)):\n",
    "    print(row[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b09a6cc",
   "metadata": {},
   "source": [
    "## Simple Model\n",
    "\n",
    "We could use an off-the-shelf model to process documents, or we can train our own model from our own documents so that the word vectors are aligned to our dataset. In a large corpus, we can train on a sample of documents if they are representative of the whole.\n",
    "\n",
    "If we train against the whole dataset, we can search into the dataset directly from the model. If train the model on a partial collection, then we can only compare search phrases and documents that we have generated vectors for.\n",
    "\n",
    "To create the model, it helps if we clean the documents, e.g. by decasing, and removing punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca7c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import strip_tags, strip_punctuation, strip_numeric, remove_stopwords\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Generate a cleaned, tokenised version of a text.\"\"\"\n",
    "    CUSTOM_FILTERS = [lambda x: x.lower(),\n",
    "                      strip_tags, strip_punctuation,\n",
    "                      strip_numeric, remove_stopwords]\n",
    "    \n",
    "    return preprocess_string(text, CUSTOM_FILTERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c636feb1",
   "metadata": {},
   "source": [
    "Apply the cleaning function to the text on the way in to creating the training corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "550b463f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['time', 'certain', 'country', 'lived', 'king'],\n",
       " 'The Blue Fairy Book::The Bronze Ring',\n",
       " 'The Bronze Ring')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_corpus = db.query(_q_random_sample.format(9999))\n",
    "\n",
    "sample_docs = [(clean_text(r['text']),\n",
    "               f\"{r['book']}::{r['title']}\", #create a unique tag\n",
    "               r['title'])\n",
    "               for r in sample_corpus]\n",
    "\n",
    "# For the first doc, preview the first 5 cleaned words and title\n",
    "sample_docs[0][0][:5], sample_docs[0][1], sample_docs[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "284e3617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gensim model needs named tuples\n",
    "# including at least a words and tags dimension\n",
    "# Naively we can just use a document index count as the tag\n",
    "from collections import namedtuple\n",
    "\n",
    "StoryDoc = namedtuple('StoryDoc',\n",
    "                      'words tags title')\n",
    "\n",
    "sample_docs_training = []\n",
    "\n",
    "for i, sample_doc in enumerate(sample_docs):\n",
    "    sample_docs_training.append(StoryDoc(sample_doc[0],\n",
    "                                         [sample_doc[1]], # This must be a list\n",
    "                                         sample_doc[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cf81b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# Define the parameters for building the model.\n",
    "# We can also pass a list of documents\n",
    "# via the first \"documents\" parameter\n",
    "# and the model will be trained against those.\n",
    "# Alternatively, create an empty model and train it later.\n",
    "model = Doc2Vec(\n",
    "                # dm: training algorithm;\n",
    "                # 1: distributed memory/PV-DM;\n",
    "                # 0: distributed bag of words (PV-DBOW)\n",
    "                dm=1,\n",
    "                # vector_size: size of feature vectors\n",
    "                vector_size=300,\n",
    "                # window: max dist between current & predicted word\n",
    "                window=10,\n",
    "                # hs: 1: hierarchical softmax;\n",
    "                # hs: 0 : negative sampling if negative\n",
    "                hs=0,\n",
    "                # min_count: ignore words w/ lower frequency\n",
    "                # There is a risk to setting this too high\n",
    "                # particularly if a search term is likely unique,\n",
    "                # as it might be with a name. On the other hand,\n",
    "                # for such situations, a simple search might be better?\n",
    "                min_count=1,\n",
    "                # sample: randomly downsample hi-frequency words\n",
    "                # useful range: (0, 1e-5)\n",
    "                sample=1e-5,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f8fb17",
   "metadata": {},
   "source": [
    "The model is built around a vocabulary extracted from the training document corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33e67b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model vocabulary\n",
    "model.build_vocab(sample_docs_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06be7767",
   "metadata": {},
   "source": [
    "We can now train the model (this may take some time for a large corpus):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6eb8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It would be useful if we could display a progress bar for this\n",
    "model.train(sample_docs_training,\n",
    "            total_examples=model.corpus_count,\n",
    "            epochs=100, start_alpha=0.01, end_alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be0c05",
   "metadata": {},
   "source": [
    "Rather than creating a model each time we want to use it, we can save the model and then load it as required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e210206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model\n",
    "model.save(\"lang_model.gensim\")\n",
    "\n",
    "# Load in a model\n",
    "model = Doc2Vec.load(\"lang_model.gensim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d047d40",
   "metadata": {},
   "source": [
    "To retrieve a document matching a search phrase, we need to encode the search phrase and then try to find a matching document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09d9bde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hansel',\n",
       " 'sister',\n",
       " 'cast',\n",
       " 'wicked',\n",
       " 'stepmother',\n",
       " 'went',\n",
       " 'forest',\n",
       " 'met',\n",
       " 'evil',\n",
       " 'witch']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_phrase = \"\"\"\n",
    "hansel and his sister were cast out by their wicked stepmother\n",
    "and went into forest and met an evil witch\n",
    "\"\"\"\n",
    "\n",
    "# Preprocess the search phrase\n",
    "tokens = clean_text(search_phrase)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9336bd13",
   "metadata": {},
   "source": [
    "Generate a vector for the tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c78ca74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the vector representation from the model\n",
    "search_vector = model.infer_vector(tokens, alpha=0.001, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c195e56",
   "metadata": {},
   "source": [
    "We can now search for related documents from the original training set based on how well their vectors match the vector generated for the search phrase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d1db972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The Blue Fairy Book::Hansel And Grettel', 0.728550136089325),\n",
       " ('The Yellow Fairy Book::The Witch', 0.5643637180328369),\n",
       " ('The Yellow Fairy Book::The White Duck', 0.5299764275550842),\n",
       " ('The Red Fairy Book::The Three Dwarfs', 0.5016872882843018),\n",
       " ('The Red Fairy Book::The Twelve Brothers', 0.4773011803627014),\n",
       " ('The Yellow Fairy Book::The Crow', 0.46543797850608826),\n",
       " ('The Yellow Fairy Book::The Dead Wife', 0.4470345079898834),\n",
       " ('The Red Fairy Book::Mother Holle', 0.4352571666240692),\n",
       " ('The Red Fairy Book::Brother And Sister', 0.43186280131340027),\n",
       " ('The Yellow Fairy Book::The Nixy', 0.4286130964756012)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the top 10 matches\n",
    "matches = model.dv.most_similar([search_vector], topn=10)\n",
    "# To rank every document from the training corpus\n",
    "# set: topn=model.docvecs.count\n",
    "\n",
    "# The response gives the original training document ids and match scores\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eae988",
   "metadata": {},
   "source": [
    "Let's try another one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7644fa89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The Blue Fairy Book::Cinderella, Or The Little Glass Slipper',\n",
       "  0.48652735352516174),\n",
       " ('The Brown Fairy Book::Which Was The Foolishest?', 0.4111166298389435),\n",
       " ('The Green Fairy Book::Spindle, Shuttle, And Needle', 0.3964698314666748),\n",
       " ('The Lilac Fairy Book::The Believing Husbands', 0.39020511507987976),\n",
       " ('The Lilac Fairy Book::The Brownie Of The Lake', 0.38550546765327454),\n",
       " ('The Brown Fairy Book::Habogi', 0.3834902048110962),\n",
       " ('The Blue Fairy Book::Little Red Riding Hood', 0.37533891201019287),\n",
       " ('The Lilac Fairy Book::The Hoodie-Crow.', 0.37399569153785706),\n",
       " ('The Violet Fairy Book::The Child Who Came From An Egg', 0.3730131685733795),\n",
       " ('The Violet Fairy Book::The Maiden With The Wooden Helmet',\n",
       "  0.3719061613082886)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_phrase = \"\"\"\n",
    "a poor orphan girl lives with her wicked stepmother and sisters\n",
    "but then her fairy godmother appears and she goes to a ball \n",
    "and leaves at midnight\n",
    "but loses her slipper then finally marries the prince\n",
    "\"\"\"\n",
    "\n",
    "# Preprocess the search phrase\n",
    "tokens = clean_text(search_phrase)\n",
    "search_vector = model.infer_vector(tokens, alpha=0.01, epochs = 50)\n",
    "model.dv.most_similar([search_vector], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a1e37c",
   "metadata": {},
   "source": [
    "Note that the result is stochastic (has a random element) in the way that the search vector is inferred: if you rerun the query, you will likely generate a different search vector. As a consequence, the search results returned are likely differ in their order and match scores each time the query is run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47e57b0",
   "metadata": {},
   "source": [
    "## Creating a Search Tool\n",
    "\n",
    "The next step is to register a custom SQLite function that will generate a vector for a search term and return matching records on that basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25d86a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vtfunc import TableFunction\n",
    "\n",
    "class SQLite_doc2Vec_Model_Search(TableFunction):\n",
    "    params = ['query', 'threshold']\n",
    "    columns = ['book', 'title', 'score']\n",
    "    name = 'doc2vec_model_search'\n",
    "    \n",
    "    model = Doc2Vec.load(\"lang_model.gensim\")\n",
    "    \n",
    "    def initialize(self, query=None, num=None, threshold=None):\n",
    "        tokens = clean_text(query)\n",
    "        search_vector = model.infer_vector(tokens, alpha=0.01, epochs = 50)\n",
    "        scores = model.dv.most_similar([search_vector],\n",
    "                                            topn=len(model.dv))\n",
    "        if threshold:\n",
    "            scores = [(t, s) for (t, s) in scores if s >= threshold ]\n",
    "\n",
    "        self._iter = iter(scores)\n",
    " \n",
    "    def iterate(self, idx):\n",
    "        (tag, score) = next(self._iter)\n",
    "        items = tag.split(\"::\")\n",
    "        return (items[0], items[1], score,)\n",
    "\n",
    "# And register the function\n",
    "SQLite_doc2Vec_Model_Search.register(db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee61edc",
   "metadata": {},
   "source": [
    "The query searches over the model and can take various forms:\n",
    "\n",
    "- `doc2vec_model_search(\"search phrase\")`\n",
    "- `doc2vec_model_search(\"search phrase\", MIN_SCORE)`\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5bc5a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The Blue Fairy Book', 'Cinderella, Or The Little Glass Slipper', 0.48834240436553955)\n"
     ]
    }
   ],
   "source": [
    "model_query = f\"\"\"\n",
    "SELECT *\n",
    "FROM doc2vec_model_search('''{search_phrase}''', 0.45 );\n",
    "\"\"\"\n",
    "\n",
    "for i in db.execute(model_query):\n",
    "    print(i)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdb3903",
   "metadata": {},
   "source": [
    "## Saving Model Vectors into the Database\n",
    "\n",
    "If we look at the object type of one of the model vectors, we see that it is a `numpy.ndarray`, which can be easily represented as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d24310a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.dv[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69316752",
   "metadata": {},
   "source": [
    "We can store this data in the SQLite database as a `BLOB`. To simplify the process of converting the array into and out of the appropriate format for storage in the database compared to its use as a gensim vector, we can register a custom handler for the `numpy.ndarray` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5409cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Via https://stackoverflow.com/a/18622264/454773\n",
    "# See also: https://github.com/joosephook/sqlite3-numpy\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "def adapt_array(arr):\n",
    "    \"\"\"\n",
    "    http://stackoverflow.com/a/31312102/190597 (SoulNibbler)\n",
    "    \"\"\"\n",
    "    out = io.BytesIO()\n",
    "    np.save(out, arr)\n",
    "    out.seek(0)\n",
    "    return sqlite3.Binary(out.read())\n",
    "\n",
    "def convert_array(text):\n",
    "    out = io.BytesIO(text)\n",
    "    out.seek(0)\n",
    "    return np.load(out)\n",
    "\n",
    "\n",
    "# Converts np.array to TEXT when inserting\n",
    "sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "\n",
    "# Converts TEXT to np.array when selecting\n",
    "sqlite3.register_converter(\"array\", convert_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a868b7e9",
   "metadata": {},
   "source": [
    "Now we need to reset the database to a connection that supports the custom handler we have just registered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eba4a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the database connection to used the parsed datatype\n",
    "db.conn = sqlite3.connect(db_name, detect_types=sqlite3.PARSE_DECLTYPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a9489",
   "metadata": {},
   "source": [
    "We can now create a table with a custom \"array\" datatype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d6e5dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x12d1fbf10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give ourselves a clean slate\n",
    "db[\"story_vectors\"].drop(ignore=True)\n",
    "\n",
    "\n",
    "# sqlite_utils doesn't appear to support custom types (yet?!)\n",
    "# The following errors on the \"array\" datatype\n",
    "\"\"\"\n",
    "db[\"story_vectors\"].create({\n",
    "    \"book\": str,\n",
    "    \"title\": str,\n",
    "    \"tag\": str, # a unique key derived from book and title\n",
    "    \"vector\": \"array\",\n",
    "}, pk=(\"book\", \"title\"),\n",
    "    #Â The following is not currently supported by sqlite_utils\n",
    "   #foreign_keys=[ ((\"book\", \"title\"), \"books\", (\"book\", \"title\"))] # local-table-id, foreign-table, foreign-table-id]\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# so we can create a table the old fashioned way...\n",
    "vector_table_create = \"\"\"\n",
    "CREATE TABLE story_vectors \n",
    "    (tag TEXT PRIMARY KEY, vector array, book TEXT, title TEXT );\n",
    "\"\"\"\n",
    "\n",
    "cur = db.conn.cursor()\n",
    "cur.execute(vector_table_create)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3d854e",
   "metadata": {},
   "source": [
    "We can generate a list of dictionaries, one per record used to train the model, that can then be added directly to the `story_vectors` database table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7b9c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrecords = []\n",
    "\n",
    "for tag in model.dv.index_to_key:\n",
    "    xrecords.append({'book': tag.split('::')[0],\n",
    "                     'title': tag.split('::')[1],\n",
    "                     'tag': tag, 'vector': model.dv[tag]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b0429",
   "metadata": {},
   "source": [
    "And add the records directly to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ec58e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table story_vectors (tag, vector, book, title)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[\"story_vectors\"].insert_all(xrecords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca13b86",
   "metadata": {},
   "source": [
    "Let's pull an example record back showing just the first few elements of the vector associated with the record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7adfe6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Blue Fairy Book::The Bronze Ring The Blue Fairy Book The Bronze Ring [-1.1545537  -1.5133394  -0.9199181   3.0243099   0.9392002   2.3881683\n",
      " -1.5769789  -0.30107376 -0.3657083   1.5464693 ]\n"
     ]
    }
   ],
   "source": [
    "_q = f'SELECT * FROM story_vectors LIMIT 1;'\n",
    "\n",
    "for row in db.query(_q):\n",
    "    print(row['tag'], row['book'], row['title'], row['vector'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3063ebcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>vector</th>\n",
       "      <th>book</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Blue Fairy Book::The Bronze Ring</td>\n",
       "      <td>[-1.1545537, -1.5133394, -0.9199181, 3.0243099...</td>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>The Bronze Ring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Blue Fairy Book::Prince Hyacinth And The D...</td>\n",
       "      <td>[-2.2750967, -0.05328803, -0.42831513, -0.4234...</td>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>Prince Hyacinth And The Dear Little Princess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Blue Fairy Book::East Of The Sun And West ...</td>\n",
       "      <td>[-0.11260367, 1.1501226, 0.4695935, 0.6856275,...</td>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>East Of The Sun And West Of The Moon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tag  \\\n",
       "0               The Blue Fairy Book::The Bronze Ring   \n",
       "1  The Blue Fairy Book::Prince Hyacinth And The D...   \n",
       "2  The Blue Fairy Book::East Of The Sun And West ...   \n",
       "\n",
       "                                              vector                 book  \\\n",
       "0  [-1.1545537, -1.5133394, -0.9199181, 3.0243099...  The Blue Fairy Book   \n",
       "1  [-2.2750967, -0.05328803, -0.42831513, -0.4234...  The Blue Fairy Book   \n",
       "2  [-0.11260367, 1.1501226, 0.4695935, 0.6856275,...  The Blue Fairy Book   \n",
       "\n",
       "                                          title  \n",
       "0                               The Bronze Ring  \n",
       "1  Prince Hyacinth And The Dear Little Princess  \n",
       "2          East Of The Sun And West Of The Moon  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "_q = f'SELECT * FROM story_vectors;'\n",
    "df = pd.read_sql(_q, db.conn)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6842b491",
   "metadata": {},
   "source": [
    "We can get the cosine similarity for each row relative to a search vector using the `sklearn.metrics.pairwise.cosine_similarity` applied to a dataframe of vectors we want to match against.\n",
    "\n",
    "The `cosine_similarity()` function will happily accept two `pandas` dataframes, such as an N x M matrix of vectors we want to score against, and a 1 x M search vector matrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb442684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>vector</th>\n",
       "      <th>book</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Blue Fairy Book::Cinderella, Or The Little...</td>\n",
       "      <td>[-0.7598129, 1.4367288, 0.19395736, 0.573754, ...</td>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>Cinderella, Or The Little Glass Slipper</td>\n",
       "      <td>0.486527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tag  \\\n",
       "6  The Blue Fairy Book::Cinderella, Or The Little...   \n",
       "\n",
       "                                              vector                 book  \\\n",
       "6  [-0.7598129, 1.4367288, 0.19395736, 0.573754, ...  The Blue Fairy Book   \n",
       "\n",
       "                                     title     score  \n",
       "6  Cinderella, Or The Little Glass Slipper  0.486527  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Grab the vectors and expand each on across columns\n",
    "match_vectors_df = df['vector'].apply(pd.Series)\n",
    "search_vector_df = pd.DataFrame(search_vector).T\n",
    "\n",
    "df['score'] = cosine_similarity(match_vectors_df,\n",
    "                                search_vector_df)\n",
    "\n",
    "df[df['score']>0.45].sort_values(\"score\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ab8a9b",
   "metadata": {},
   "source": [
    "So it's easy enough to create a custom function to search over the vectors table rather than the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79688968",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLite_doc2Vec_Table_Search(TableFunction):\n",
    "    params = ['query', 'threshold']\n",
    "    columns = ['book', 'title', 'score']\n",
    "    name = 'doc2vec_search'\n",
    "    \n",
    "    # If we move this into the body, we can update the database\n",
    "    # and respond to new rows added to story_vectors table\n",
    "    _q = f'SELECT book, title, vector FROM story_vectors;'\n",
    "    df = pd.read_sql(_q, db.conn)\n",
    "    match_vectors_df = df['vector'].apply(pd.Series)\n",
    "    \n",
    "    def initialize(self, query=None, threshold=None):\n",
    "        df = self.df\n",
    "        tokens = clean_text(query)\n",
    "        search_vector = model.infer_vector(tokens, alpha=0.01, epochs = 50)\n",
    "\n",
    "        search_vector_df = pd.DataFrame(search_vector).T\n",
    "\n",
    "        # Find cosine similarity\n",
    "        df['score'] = cosine_similarity(self.match_vectors_df,\n",
    "                                        search_vector_df)\n",
    "        \n",
    "        # Apply minimum threshold if set\n",
    "        _iterator = df[df['score']>=threshold] if threshold else df\n",
    "\n",
    "        self._iter = _iterator[self.columns].itertuples(index=False,\n",
    "                                                        name=None)\n",
    " \n",
    "    def iterate(self, idx):\n",
    "        row = next(self._iter)\n",
    "        return (row[0], row[1], row[2],)\n",
    "\n",
    "# And register the function\n",
    "SQLite_doc2Vec_Table_Search.register(db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca947234",
   "metadata": {},
   "source": [
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3041462a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>Cinderella, Or The Little Glass Slipper</td>\n",
       "      <td>0.522628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Red Fairy Book</td>\n",
       "      <td>The Six Sillies</td>\n",
       "      <td>0.410686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Brown Fairy Book</td>\n",
       "      <td>Habogi</td>\n",
       "      <td>0.403348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   book                                    title     score\n",
       "0   The Blue Fairy Book  Cinderella, Or The Little Glass Slipper  0.522628\n",
       "1    The Red Fairy Book                          The Six Sillies  0.410686\n",
       "2  The Brown Fairy Book                                   Habogi  0.403348"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_query = f\"\"\"\n",
    "SELECT *\n",
    "FROM doc2vec_search(\"{search_phrase}\")\n",
    "WHERE score>0.4 ORDER BY score DESC LIMIT 3;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(vector_query, db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f049000",
   "metadata": {},
   "source": [
    "Let's try another one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6da228b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Red Fairy Book</td>\n",
       "      <td>The Nettle Spinner</td>\n",
       "      <td>0.639598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Pink Fairy Book</td>\n",
       "      <td>The Merry Wives</td>\n",
       "      <td>0.449067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>Rumpelstiltzkin</td>\n",
       "      <td>0.444151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  book               title     score\n",
       "0   The Red Fairy Book  The Nettle Spinner  0.639598\n",
       "1  The Pink Fairy Book     The Merry Wives  0.449067\n",
       "2  The Blue Fairy Book     Rumpelstiltzkin  0.444151"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_phrase2 = \"\"\"\n",
    "A girl lives with her grandmother and a wicked lord comes along and tells her\n",
    "she can't get married unless she spins a funeral shroud and a wedding gown made from nettles.\n",
    "As she spins, he gets ill, but can't die until she finishes it.\n",
    "\"\"\"\n",
    "\n",
    "vector_query = f\"\"\"\n",
    "SELECT *\n",
    "FROM doc2vec_search(\"{search_phrase2}\")\n",
    "WHERE score>0.3 ORDER BY score DESC LIMIT 3;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(vector_query, db.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11ab1ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Yellow Fairy Book</td>\n",
       "      <td>The Yellow Fairy Book</td>\n",
       "      <td>0.624495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>Little Red Riding Hood</td>\n",
       "      <td>0.590124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Red Fairy Book</td>\n",
       "      <td>The Six Sillies</td>\n",
       "      <td>0.572264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>Why The Sea Is Salt</td>\n",
       "      <td>0.547218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Pink Fairy Book</td>\n",
       "      <td>I Know What I Have Learned</td>\n",
       "      <td>0.535688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Pink Fairy Book</td>\n",
       "      <td>The Merry Wives</td>\n",
       "      <td>0.531312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Red Fairy Book</td>\n",
       "      <td>The True History Of Little Golden Hood</td>\n",
       "      <td>0.529552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Pink Fairy Book</td>\n",
       "      <td>Peter Bull</td>\n",
       "      <td>0.528966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Pink Fairy Book</td>\n",
       "      <td>The House In The Wood</td>\n",
       "      <td>0.517915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Lilac Fairy Book</td>\n",
       "      <td>A Lost Paradise</td>\n",
       "      <td>0.516366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    book                                   title     score\n",
       "0  The Yellow Fairy Book                   The Yellow Fairy Book  0.624495\n",
       "1    The Blue Fairy Book                  Little Red Riding Hood  0.590124\n",
       "2     The Red Fairy Book                         The Six Sillies  0.572264\n",
       "3    The Blue Fairy Book                     Why The Sea Is Salt  0.547218\n",
       "4    The Pink Fairy Book              I Know What I Have Learned  0.535688\n",
       "5    The Pink Fairy Book                         The Merry Wives  0.531312\n",
       "6     The Red Fairy Book  The True History Of Little Golden Hood  0.529552\n",
       "7    The Pink Fairy Book                              Peter Bull  0.528966\n",
       "8    The Pink Fairy Book                   The House In The Wood  0.517915\n",
       "9   The Lilac Fairy Book                         A Lost Paradise  0.516366"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_phrase3 = \"\"\"\n",
    "A girl in kitchen makes soup for king gets married.\n",
    "\"\"\"\n",
    "\n",
    "vector_query = f\"\"\"\n",
    "SELECT *\n",
    "FROM doc2vec_search(\"{search_phrase3}\")\n",
    "WHERE score>0.3 ORDER BY score DESC LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(vector_query, db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4dab1a",
   "metadata": {},
   "source": [
    "## Add TF-IDF\n",
    "\n",
    "To improve the doc2vec performance, it might be worth exploring a model that has a stricter minimum frequency for words in the corpus, but that also mixes a TF-IDF (*term frequency, inverse document frequency*) component in the ranking score?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
