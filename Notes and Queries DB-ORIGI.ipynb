{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5790aab1",
   "metadata": {},
   "source": [
    "# Notes & Queries Database\n",
    "\n",
    "This chapter, and several following ones, will describe how to create various search context for 19th century issues of *Notes & Queries*. These include:\n",
    "\n",
    "- a monolithic PDF of index issues up to 1892;\n",
    "- a searchable database of index issues up to 1892;\n",
    "- a full text searchable database of non-index issues up to 1900.\n",
    "\n",
    "Original scans of the original publication, as well as automatically extracted search text, are available, for free, from the Internet Archive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca9ffc",
   "metadata": {},
   "source": [
    "## Working With Documents From the Internet Archive\n",
    "\n",
    "The Internet Archive – [`archive.org`](https://archive.org/) – is an incredible resource. Amongst other things, it is home to a large number of out-of-copyright digitised books scanned by the Google Book project as well as other book scanning initiatives.\n",
    "\n",
    "In this unbook, I will explore various ways in which can build tools around the Internet Archive and documents retrieved from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c89c48",
   "metadata": {},
   "source": [
    "## Searching the Internet Archive\n",
    "\n",
    "Many people will be familiar with the web interface to the [Internet Archive](https://archive.org) (and I suspect many more are not aware of the existence of the Internet Archive at all). This provides tools for discovering documents available in the archive, previewing the scanned versions of them, and even searching within them.\n",
    "\n",
    "At times, the search inside a book can be a bit hit and miss, in part depending on the quality of the scanned images and the ability of the OCR tools - where \"OCR\" stands for \"optical character recognition\" - to convert the pictures of text into actual text. Which is to say, *searchable* text.\n",
    "\n",
    "To work with the archive, we'll use the Python programming language. This lets us write instructions for our machine helpers to follow. One of the machine helpers comes in the form of the [`internetarchive` Python package](https://archive.org/services/docs/api/internetarchive/index.html), a collection of routines that can access the Internet Archive at the programming, rather than human user interface, level.\n",
    "\n",
    "*The human  level interface simply provides graphical tools that we can understand, such as menu items and toolbar buttons. Selecting or clicking these simply invokes machine level commands in a useable-for-us way. Writing program code lets us call those commands directly, in a textual way, rather than visually, by clicking menu items and buttons. Copying and pasting simple text instructions that can be used to perform a particular function is often quite straightforward. Modifying such commands may also be relatively straightforward. (For example, given a block of code that downloads a file from a web location using code of the form `download_file(\"https://example.com/this_file.pdf\")`, you could probably work out how to download a file from `http://another.example.com/myfile.pdf`.) Creating graphical user interfaces is hard. Graphical user interfaces also constrains users to using just the functions and features that the designers and developers of the user interface chose to support in the user interface, in just the way that the user interface allows. Being able to instruct a machine using code, even copied and pasted code, gives the end-use far more power over the machine.*\n",
    "\n",
    "Within any particular programming language, *packages* are often used to bundle together various tools and functions that can be used to support particular activities or tasks, or work with particular resources or resource types.\n",
    "\n",
    "One of the most useful tools within the Internet Archive package is the `search_items()` function, which lets us search the Internet Archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12942550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we haven't already installed the package into our computing environment,\n",
    "# we need to download it and install it.\n",
    "#%pip install internetarchive\n",
    "\n",
    "# Load in a function to search the archive\n",
    "from internetarchive import search_items\n",
    "\n",
    "# We are going to build up a list of search results\n",
    "items = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa3c6de",
   "metadata": {},
   "source": [
    "### Item Metadata\n",
    "\n",
    "At the data level, the Internet Archive has *metadata*, or \"data about data\" that provides key information or summary information about each data record. For example, works can be organised as part of different collections via `collection` elements such as `collection:\"pub_notes-and-queries\"`.\n",
    "\n",
    "For periodicals, there may also be a publication identifier associated with the periodical (for example, `sim_pubid:1250`) or metadata identifying which *volume* or *issue* a particular edition of a periodical may be.\n",
    "\n",
    "In the following bit of code, we search over the *Notes & Queries* collection, retrieving data about each item in the collection.\n",
    "\n",
    "This is quite a large collection, so to run a query that retrieves all the items in it may take a considerable amount of time. Instead, we can limit the search to issues published in a particular year, and further limit the query to only retrieve a certain number of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d4efbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 sim_notes-and-queries_1867-01-05_11_262 Notes and Queries  1867-01-05: Vol 11 Iss 262\n",
      "1 sim_notes-and-queries_1867-01-12_11_263 Notes and Queries  1867-01-12: Vol 11 Iss 263\n",
      "2 sim_notes-and-queries_1867-01-19_11_264 Notes and Queries  1867-01-19: Vol 11 Iss 264\n",
      "3 sim_notes-and-queries_1867-01-26_11_265 Notes and Queries  1867-01-26: Vol 11 Iss 265\n"
     ]
    }
   ],
   "source": [
    "# We can use a programming loop to search for items, iterate through the items\n",
    "# and retrieve a record for each one\n",
    "# The enumerate() command will loop trhough all the items, returnin a running count of items\n",
    "# returned, as well as each separate item\n",
    "# The count starts at 0...\n",
    "for count, item in enumerate(search_items('collection:\"pub_notes-and-queries\" AND year:1867').iter_as_items()):\n",
    "    # Display thecount, the item identifier and title\n",
    "    print(count, item.identifier, item.metadata['title'])\n",
    "\n",
    "    # If we see item with count value of at least 3, which is to say, the fourth item,\n",
    "    # (we start counting at zero, remember...)\n",
    "    if count >= 3:\n",
    "        # Then break out of this loop\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8663e4df",
   "metadata": {},
   "source": [
    "As well as the \"offical\" collection, some copies of *Notes and Queries* from other providers are also available in the Internet Archive. For example, there are some submissions from *Project Gutenberg*.\n",
    "\n",
    "The following retrieves an item obtained from the `gutenberg` collection, which is to say, *Project Gutenberg*, and previews its metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c113e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'identifier': 'notesandqueriesi13536gut',\n",
       " 'title': 'Notes and Queries, Index of Volume 1, November, 1849-May, 1850: A Medium of Inter-Communication for Literary Men, Artists, Antiquaries, Genealogists, Etc.',\n",
       " 'possible-copyright-status': 'NOT_IN_COPYRIGHT',\n",
       " 'copyright-region': 'US',\n",
       " 'mediatype': 'texts',\n",
       " 'collection': 'gutenberg',\n",
       " 'creator': 'Various',\n",
       " 'contributor': 'Project Gutenberg',\n",
       " 'description': 'Book from Project Gutenberg: Notes and Queries, Index of Volume 1, November, 1849-May, 1850: A Medium of Inter-Communication for Literary Men, Artists, Antiquaries, Genealogists, Etc.',\n",
       " 'language': 'eng',\n",
       " 'call_number': 'gutenberg etext# 13536',\n",
       " 'addeddate': '2006-12-07',\n",
       " 'publicdate': '2006-12-07',\n",
       " 'backup_location': 'ia903600_27'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from internetarchive import get_item\n",
    "\n",
    "# Retrieve an item from its unique identifier\n",
    "item = get_item('notesandqueriesi13536gut')\n",
    "\n",
    "# And display its metadata\n",
    "item.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafeee33",
   "metadata": {},
   "source": [
    "The items in the `pub_notes-and-queries` collection have much more metadata available, including `volume` and `issue` data, and the identifiers for the `previous` and `next` issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb8cb96",
   "metadata": {},
   "source": [
    "In some cases, the identifier values may be human readable, if you look closely enough. For example, *Notes and Queries* was published weekly, typically with two volumes per year, and an index for each. In the `pub_notes-and-queries` collections, the identifier for Volume 11, issue 262, published on January 5th, 1867, is `sim_notes-and-queries_1867-01-05_11_262`; and the identifier for the index of volume 12, published in throughout the second half of 1867, is `sim_notes-and-queries_1867_12_index`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57e6bab",
   "metadata": {},
   "source": [
    "### Available Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31416240",
   "metadata": {},
   "source": [
    "As well as the data record, certain other files may be associated with that item such as PDF scans, or files containing the raw scanned text of the document.\n",
    "\n",
    "We have already seen how we can retrieve an item given it's identifier, but let's see it in action again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dabbd1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Notes and Queries  1867: Vol 12 Index',\n",
       " 'sim_notes-and-queries_1867_12_index')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = get_item(\"sim_notes-and-queries_1867_12_index\")\n",
    "\n",
    "item.metadata['title'], item.identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6faa9be",
   "metadata": {},
   "source": [
    "We can make a call from this data item to return a list of the files associated with that item, and display their file formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69797f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item Tile\n",
      "JPEG 2000\n",
      "JPEG 2000\n",
      "Text PDF\n",
      "Archive BitTorrent\n",
      "chOCR\n",
      "DjVuTXT\n",
      "Djvu XML\n",
      "Metadata\n",
      "JSON\n",
      "hOCR\n",
      "OCR Page Index\n",
      "OCR Search Text\n",
      "Item Image\n",
      "Single Page Processed JP2 ZIP\n",
      "Metadata\n",
      "Metadata\n",
      "Page Numbers JSON\n",
      "JSON\n",
      "Scandata\n"
     ]
    }
   ],
   "source": [
    "for file_item in item.get_files():\n",
    "    print(file_item.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e65f799",
   "metadata": {},
   "source": [
    "For this item, then, we can get a PDF document, a file containing the search text, a record with information about page numbers, an XML version of the original scanned version, some image scans, and various other things containing who knows what!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9717f5f8",
   "metadata": {},
   "source": [
    "### A Complete List of *Notes & Queries* Issues\n",
    "\n",
    "To help us work with the *pub_notes-and-queries* collection, let's construct a local copy of the most important metadata associated with each item in the collection, specifically the item identifier, date and title, as well as the volume and issue. (*Notes and Queries* also has a higher level of organisation, a *Series*, which means thatvolume and issue numbers can actually recycle, so by itself, a particular `(volume, issue)` pair does not identify a unique item, but a `(series, volume, issue)` or `(year, volume, issue)` triple does.)\n",
    "\n",
    "For convenience, we might also collect the *previous* and *next* item identifiers, as well as a flag that tells us whether access is restricted or not. (For 19th century editions, there are no restrictions; but for more recent 20th century editions, access may be limited to library shelf access).\n",
    "\n",
    "The following cell contains a set of instructions bundled together to define a *function* under a unique function name. Functions provide us with a shorthand way of writing a set of instructions once, then calling on them repeatedly via their function name.\n",
    "\n",
    "In particular, the function takes in an item metadata record, tidies it up a little and returns just the fields we are interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "317fc7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def out_ia_metadata(item):\n",
    "    \"\"\"Retrieve a subset of item metadata and return it as a list.\"\"\"\n",
    "    # This is a nested function that looks up piece of metadata if it exists\n",
    "    # If it doesn't exist, we set it to ''\n",
    "    def _get(_item, field):\n",
    "        return _item[field] if field in _item else ''\n",
    "\n",
    "    #item = get_item(i.identifier)\n",
    "    identifier = item.metadata['identifier']\n",
    "    date =  item.metadata['date']\n",
    "    title = _get(item.metadata, 'title')\n",
    "    volume =_get(item.metadata, 'volume')\n",
    "    issue = _get(item.metadata, 'issue')\n",
    "    prev_ = _get(item.metadata, 'previous_item')\n",
    "    next_ = _get(item.metadata, 'next_item')\n",
    "    restricted = _get(item.metadata,'access-restricted-item')\n",
    "    \n",
    "    return [identifier, date, title, volume, issue, prev_, next_, restricted]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f1a635",
   "metadata": {},
   "source": [
    "Here's what the data retrieved from an item record by the `out_ia_metadata` function looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bef9ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sim_notes-and-queries_1867_12_index',\n",
       " '1867',\n",
       " 'Notes and Queries  1867: Vol 12 Index',\n",
       " '12',\n",
       " 'Index',\n",
       " 'sim_notes-and-queries_1867-06-29_11_287',\n",
       " 'sim_notes-and-queries_1867-07-06_12_288',\n",
       " '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get an item record form its identifier\n",
    "item = get_item(\"sim_notes-and-queries_1867_12_index\")\n",
    "\n",
    "# Display the key metadata\n",
    "out_ia_metadata(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50857f5",
   "metadata": {},
   "source": [
    "We can now build up a list of lists containing the key metadata for all editions of *Notes of Queries* in the `pub_notes-and-queries` collection.\n",
    "\n",
    "Our recipe will proceed in the following three steps:\n",
    "\n",
    "- search for all the items in the collection;\n",
    "- build up a list of records where item contains the key metadata, extracted from the full record using the `out_ia_metadata()` function;\n",
    "- open a file (*nandq_internet_archive.txt*), give it a column header line, and write the key metadata records to it, one record per line.\n",
    "\n",
    "The file will be written in \"CSV\" format (comma separarated variable), a simple text format for describing tabular data. CSV files can be read by spreadsheet applications, as well as other tools, and use comma separators to identify \"columns\" of information in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a61134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find records for all items in the collection\n",
    "items = search_items('collection:\"pub_notes-and-queries\"')\n",
    "\n",
    "# This piece of voodoo creates a list from from items in another list\n",
    "# Specifically, for each item in the items list, grab its essential metadata\n",
    "# and use that as an item in a new list.\n",
    "csv_items = [out_ia_metadata(i) for i in items]\n",
    "\n",
    "# We can now open a file\n",
    "with open('nandq_internet_archive.txt', 'w') as outfile:\n",
    "    # Create a \"CSV writer\" object that can write to the file \n",
    "    csv_write = csv.writer(outfile)\n",
    "    # Write a header row at the top of the file\n",
    "    csv_write.writerow(['id','date','title','vol','iss','prev_id', 'next_id','restricted'])\n",
    "    # Then write out list of essential metadata items out, one record per row\n",
    "    csv_write.writerows(csv_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d353c990",
   "metadata": {},
   "source": [
    "We can use a simple Linux command line tool (`head`) to show the top five lines of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "761eb6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,date,title,vol,iss,prev_id,next_id,restricted\r",
      "\r\n",
      "sim_notes-and-queries_1849-11-03_1_1,1849-11-03,Notes and Queries  1849-11-03: Vol 1 Iss 1,1,1,sim_notes-and-queries_1849-1850_1_index,sim_notes-and-queries_1849-11-10_1_2,\r",
      "\r\n",
      "sim_notes-and-queries_1849-11-10_1_2,1849-11-10,Notes and Queries  1849-11-10: Vol 1 Iss 2,1,2,sim_notes-and-queries_1849-11-03_1_1,sim_notes-and-queries_1849-11-17_1_3,\r",
      "\r\n",
      "sim_notes-and-queries_1849-11-17_1_3,1849-11-17,Notes and Queries  1849-11-17: Vol 1 Iss 3,1,3,sim_notes-and-queries_1849-11-10_1_2,sim_notes-and-queries_1849-11-24_1_4,\r",
      "\r\n",
      "sim_notes-and-queries_1849-11-24_1_4,1849-11-24,Notes and Queries  1849-11-24: Vol 1 Iss 4,1,4,sim_notes-and-queries_1849-11-17_1_3,sim_notes-and-queries_1849-12-01_1_5,\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 nandq_internet_archive.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd717db",
   "metadata": {},
   "source": [
    "So, with some idea of what's available to us, data wise, and file wise, what can we start to do with it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b854f3b",
   "metadata": {},
   "source": [
    "## Generating a Monolithic PDF Index for *Notes & Queries* Up To 1892"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42afa8e2",
   "metadata": {},
   "source": [
    "If we want to search for items in *Notes and Queries* \"manually\", one of the most effective ways is to look up items in the volume indexes. With two volumes a year, this means checking almost 100 separate documents if we want to look up 19th century references. (That's not quite true: from the 1890s, indexes were produced that started to to aggregate indices over several years.) \n",
    "\n",
    "So how might we go about producing a single index PDF for 19th c. editions of *Notes & Queries*? As a conjoined set of original index PDFs, this wouldn't provide us with unified index terms - a search on an index item would return separate entries for each volume index in which the term appeared – but it would mean we only needed to search one PDF document.\n",
    "\n",
    "We'll use the Python `csv` package to simplify saving and load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4e03047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b63a56",
   "metadata": {},
   "source": [
    "To begin with, we can load in our list of *Notes and Queries* record data downloaded from the Internet Archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d32706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file name we want to read data in from\n",
    "def open_metadata_records(fn='nandq_internet_archive.txt'):\n",
    "    \"\"\"Open and read metadata records file.\"\"\"\n",
    "\n",
    "    with open(fn, 'r') as f:\n",
    "        # We are going to load the data into a data structure known as a dictionary, or dict\n",
    "        # Each item in the dictionary contains several elements as `key:value` pairs\n",
    "        # The key matches the column name in the CSV data file,\n",
    "        # along with the corresponding value in a given item row\n",
    "\n",
    "        # Read the data in\n",
    "        csv_data = csv.DictReader(f)\n",
    "\n",
    "        # And convert it to a list of data records\n",
    "        data_records = list(csv_data)\n",
    "        \n",
    "    return data_records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7439843",
   "metadata": {},
   "source": [
    "Let's grab the metadata records from our saved file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d01f5aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'sim_notes-and-queries_1849-11-03_1_1',\n",
       " 'date': '1849-11-03',\n",
       " 'title': 'Notes and Queries  1849-11-03: Vol 1 Iss 1',\n",
       " 'vol': '1',\n",
       " 'iss': '1',\n",
       " 'prev_id': 'sim_notes-and-queries_1849-1850_1_index',\n",
       " 'next_id': 'sim_notes-and-queries_1849-11-10_1_2',\n",
       " 'restricted': ''}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_records = open_metadata_records()\n",
    "\n",
    "# Preview the first record (index count starts at 0)\n",
    "# The object returned is a dictionary / dict\n",
    "data_records[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16715d99",
   "metadata": {},
   "source": [
    "By inspection of the list of index entries, we note that at some point cumulative indexes over a set of years, as well as volume level indexes, were made available. Cumulative indexes include:\n",
    "\n",
    "- Notes and Queries 1892 - 1897: Vol 1-12 Index\n",
    "- Notes and Queries 1898 - 1903: Vol 1-12 Index\n",
    "- Notes and Queries 1904 - 1909: Vol 1-12 Index\n",
    "- Notes and Queries 1910 - 1915: Vol 1-12 Index\n",
    "\n",
    "In this first pass, we shall just ignore the cumulative indexes.\n",
    "\n",
    "At this point, it is not clear where we might reliably obtain the series information from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba87833",
   "metadata": {},
   "source": [
    "To make the data easier to work with, we can parse the date as a date thing (technical term!;-) using tools in the Python `dateparser` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d07a59a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateparser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a4db56",
   "metadata": {},
   "source": [
    "The parsed data provides ways of comparing dates, extracting month and year, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c2bdb44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/dateparser/date_parser.py:35: PytzUsageWarning: The localize method is no longer necessary, as this time zone supports the fold attribute (PEP 495). For more details on migrating to a PEP 495-compliant implementation, see https://pytz-deprecation-shim.readthedocs.io/en/latest/migration.html\n",
      "  date_obj = stz.localize(date_obj)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'sim_notes-and-queries_1850_2_index',\n",
       "  'date': '1850',\n",
       "  'title': 'Notes and Queries  1850: Vol 2 Index',\n",
       "  'vol': '2',\n",
       "  'iss': 'Index',\n",
       "  'prev_id': 'sim_notes-and-queries_1850-05-25_1_30',\n",
       "  'next_id': 'sim_notes-and-queries_1850-06-01_2_31',\n",
       "  'restricted': ''},\n",
       " {'id': 'sim_notes-and-queries_1851_3_index',\n",
       "  'date': '1851',\n",
       "  'title': 'Notes and Queries  1851: Vol 3 Index',\n",
       "  'vol': '3',\n",
       "  'iss': 'Index',\n",
       "  'prev_id': 'sim_notes-and-queries_1850-12-28_2_61',\n",
       "  'next_id': 'sim_notes-and-queries_1851-01-04_3_62',\n",
       "  'restricted': ''},\n",
       " {'id': 'sim_notes-and-queries_1851_4_index',\n",
       "  'date': '1851',\n",
       "  'title': 'Notes and Queries  1851: Vol 4 Index',\n",
       "  'vol': '4',\n",
       "  'iss': 'Index',\n",
       "  'prev_id': 'sim_notes-and-queries_1851-06-28_3_87',\n",
       "  'next_id': 'sim_notes-and-queries_1851-07-05_4_88',\n",
       "  'restricted': ''}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = []\n",
    "\n",
    "# Get index records up to 1892\n",
    "max_year = 1892\n",
    "\n",
    "for record in data_records:\n",
    "    # Only look at index records\n",
    "    if 'index' in record['id']:\n",
    "        # Need to handle a YYYY - YYYY exception\n",
    "        # If we detect it, ignore it\n",
    "        if len(record['date'].split()) > 1:\n",
    "               continue\n",
    "        \n",
    "        # Parse the year into a date object\n",
    "        # Then filter by year\n",
    "        if dateparser.parse(record['date'].split()[0]).year >= max_year:\n",
    "            break\n",
    "        indexes.append(record) \n",
    "\n",
    "# Preview the first three index records\n",
    "indexes[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322636c2",
   "metadata": {},
   "source": [
    "To generate the complete PDF index, we need to do several things:\n",
    "\n",
    "- iterate through the list of index records;\n",
    "- for each one, download the associated PDF to a directory;\n",
    "- merge all the downloaded files into a single PDF;\n",
    "- optionally, delete the original PDF files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aa81f9",
   "metadata": {},
   "source": [
    "### Working With PDF Files Downloaded from the Internet Archive\n",
    "\n",
    "We can download files from the Internet Archive using the `internetarchive.download()` function. This takes a list of items via a `formats` parameter for the files we want to download. For example, we might want to download the \"Text PDF\" (a PDF file with full text search), or a simple text file containing just the OCR captured text (`OCR Search Text`), or both.\n",
    "\n",
    "We can also specify the directory into which the files are downloaded.\n",
    "\n",
    "Let's import the packages that help simplify this task, and create a path to our desired download directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6f2e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "from internetarchive import download\n",
    "from pathlib import Path\n",
    "\n",
    "# The tqdm package provides a convenient progress bar\n",
    "# for tracking progress through looped actions\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d32fde",
   "metadata": {},
   "source": [
    "To keep our files organised, we'll create a directory into which we can download the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6397de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create download dir file path\n",
    "dirname = 'ia-downloads'\n",
    "\n",
    "p = Path(dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfeee1c",
   "metadata": {},
   "source": [
    "One of the ways we can work with the data is to process it using Python programming code.\n",
    "\n",
    "For example, we can iterate through the index records and download the required files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "id": "5383e088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199806de68f94c4b945b0272b55c6ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use tqdm for provide a progress bar\n",
    "for record in tqdm(indexes):\n",
    "    _id = record['id']\n",
    "    \n",
    "    # Download PDF - this may take time to retrieve / download\n",
    "    # This downloads to a direcotry with the same name as the record id\n",
    "    # The file name is akin to ${id}.pdf\n",
    "    download(_id, destdir=p, silent = True,\n",
    "             formats=[\"Text PDF\", \"OCR Search Text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7050f184",
   "metadata": {},
   "source": [
    "To create single monolithic PDF, we can use another fragment of code to iterate through the downloaded PDF files, adding each one to a single merged PDF file object. We can also create and insert a reference page between each of the original documents to provide provenance if the is no date on the index pages.\n",
    "\n",
    "Let's start by seeing how to create a simple PDF page. The `reportlab` Python package provides various tools for creating simple PDF documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb3daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade reportlab\n",
    "from reportlab.pdfgen.canvas import Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbeb602",
   "metadata": {},
   "source": [
    "For example, we can create a simple single page document that we can add index metadata to and then insert in between the pages of each index issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f766435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a page canvas\n",
    "test_pdf = \"test-page.pdf\"\n",
    "canvas = Canvas(test_pdf)\n",
    "\n",
    "# Write something on the page at a particular location\n",
    "# In this case, let's use the title from the first index record\n",
    "txt = indexes[0]['title']\n",
    "# Co-ordinate origin is bottom left of the page\n",
    "# Scale is points, where 72 points = 1 inch\n",
    "canvas.drawString(72, 10*72, txt)\n",
    "\n",
    "# Save the page\n",
    "canvas.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a9852c",
   "metadata": {},
   "source": [
    "Now we can preview the test page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89a677ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"500\"\n",
       "            src=\"test-page.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10b86f4c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(test_pdf, width=600, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497edbdb",
   "metadata": {},
   "source": [
    "A simple function lets us generate a simple page rendering a short text string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7e0acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pdf_page(txt, fn=\"test_pdf.pdf\"):\n",
    "    \"\"\"\"\"\"\n",
    "    canvas = Canvas(fn)\n",
    "\n",
    "    # Write something on the page at a partcular location\n",
    "    # Co-ordinate origin is bottom left of the page\n",
    "    # Scale is points, where 72 points = 1 inch\n",
    "    canvas.drawString(72, 10*72, txt)\n",
    "\n",
    "    # Save the page\n",
    "    canvas.save()\n",
    "    \n",
    "    return fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49bf40c",
   "metadata": {},
   "source": [
    "Let's now create our monolithic index with metadata page inserts.\n",
    "\n",
    "The `PyPDF2` package contains various tools for splitting and combining PDF documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a8cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileReader, PdfFileMerger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc0dd91",
   "metadata": {},
   "source": [
    "We can use it merge our separate index cover page and index issue documents, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f75ce4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd81922d6e047078670464aeb13f987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a merged PDF file creating object\n",
    "output = PdfFileMerger()\n",
    "\n",
    "# Generate a monolithic PDF index file by concatenating the pages\n",
    "# from each individual PDF index file\n",
    "# Use tqdm for provide a progress bar\n",
    "for record in tqdm(indexes):\n",
    "    # Generate some metadata:\n",
    "    txt = record['title']\n",
    "    metadata_pdf = make_pdf_page(txt)\n",
    "    # Add this to the output document\n",
    "    output.append(metadata_pdf)\n",
    "    # Delete the metadata file\n",
    "    Path(metadata_pdf).unlink()\n",
    "\n",
    "    # Get the record ID\n",
    "    _id = record['id']\n",
    "\n",
    "    # Locate the file and merge it into the monolithic PDF\n",
    "    output.append((p / _id / f'{_id}.pdf').as_posix())\n",
    "    \n",
    "# Write merged PDF file\n",
    "with open(\"notes_and_queries_big_index.pdf\", \"wb\") as output_stream:\n",
    "    output.write(output_stream)\n",
    "\n",
    "output = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05180cfd",
   "metadata": {},
   "source": [
    "The resulting PDF document is a large document that collects all the separate indexes in one place, although not as a single, *reconciled* index: if the same index terms exist in multiple index documents, there will be multiple occurrences of that term in the longer document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --SPLITHERE--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd2031d",
   "metadata": {},
   "source": [
    "## Generating a Full Text Searchable Database for *Notes & Queries*\n",
    "\n",
    "Whilst the PDF documents corresponding to each issue of *Notes and Queries* are quite large files, the searchable, OCR retrieved text documents are much smaller and can be easily added to a full-text searchable database.\n",
    "\n",
    "We can create a simple, file based SQLite database that will provide a full-text search facility over each issue of *Notes and Queries*.\n",
    "\n",
    "Let's start by creating the basic database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "ca63c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlite_utils import Database\n",
    "\n",
    "db_name = \"nq_demo.db\"\n",
    "\n",
    "# While developing the script, recreate database each time...\n",
    "db = Database(db_name, recreate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44264215",
   "metadata": {},
   "source": [
    "### Populating the Database With Record Metadata\n",
    "\n",
    "Let's start by creating a table in the database that can store our metadata data records, as loaded in from the  data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "1f777be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateparser\n",
    "import datetime\n",
    "\n",
    "def create_db_table_metadata(db, drop=True):\n",
    "    # If we want to remove the table completely, we can drop  it\n",
    "    if drop:\n",
    "        db[\"metadata\"].drop(ignore=True)\n",
    "    db[\"metadata\"].create({\n",
    "        \"id\": str,\n",
    "        \"date\": str,\n",
    "        \"datetime\": datetime.datetime, # Use an actual time representation\n",
    "        \"series\": str,\n",
    "        \"vol\": str,\n",
    "        \"iss\": str,\n",
    "        \"title\": str, \n",
    "        \"next_id\": str, \n",
    "        \"prev_id\": str,\n",
    "        \"is_index\": bool, # Is the record an index record\n",
    "        \"restricted\": str, # should really be boolean\n",
    "    }, pk=(\"id\"))\n",
    "    \n",
    "\n",
    "create_db_table_metadata(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f199d3c",
   "metadata": {},
   "source": [
    "We need to do a little tidying of the records, but then we can add them directly to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "2bc3ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_patched_metadata_records_to_db(db, data_records):\n",
    "    \"\"\"Add metadata records to database.\"\"\"\n",
    "    # Patch records to include a parsed datetime element\n",
    "    for record in tqdm(data_records):\n",
    "        # Parse the raw date into a date object\n",
    "        # Need to handle a YYYY - YYYY exception\n",
    "        # If we detect this form, use the last year for the record\n",
    "        if len(record['date'].split()[0]) > 1:\n",
    "            record['datetime'] = dateparser.parse(record['date'].split()[-1])\n",
    "        else:\n",
    "            record['datetime'] = dateparser.parse(record['date'])\n",
    "\n",
    "        record['is_index'] = 'index' in record['title'].lower() # We assign the result of a logical test\n",
    "\n",
    "    # Add records to the database\n",
    "    db[\"metadata\"].insert_all(data_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128720a8",
   "metadata": {},
   "source": [
    "Let's call that function and add our metadata data records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "8de825c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a03df509004067a3a2467abbd544bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5695 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "add_patched_metadata_records_to_db(db, data_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b65da66",
   "metadata": {},
   "source": [
    "We can then query the data, for example return the first rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "048dcf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>series</th>\n",
       "      <th>vol</th>\n",
       "      <th>iss</th>\n",
       "      <th>title</th>\n",
       "      <th>next_id</th>\n",
       "      <th>prev_id</th>\n",
       "      <th>is_index</th>\n",
       "      <th>restricted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>1849-11-03</td>\n",
       "      <td>1849-11-03T00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Notes and Queries  1849-11-03: Vol 1 Iss 1</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>sim_notes-and-queries_1849-1850_1_index</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>1849-11-10</td>\n",
       "      <td>1849-11-10T00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Notes and Queries  1849-11-10: Vol 1 Iss 2</td>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>1849-11-17</td>\n",
       "      <td>1849-11-17T00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Notes and Queries  1849-11-17: Vol 1 Iss 3</td>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>1849-11-24</td>\n",
       "      <td>1849-11-24T00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Notes and Queries  1849-11-24: Vol 1 Iss 4</td>\n",
       "      <td>sim_notes-and-queries_1849-12-01_1_5</td>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sim_notes-and-queries_1849-12-01_1_5</td>\n",
       "      <td>1849-12-01</td>\n",
       "      <td>1849-12-01T00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Notes and Queries  1849-12-01: Vol 1 Iss 5</td>\n",
       "      <td>sim_notes-and-queries_1849-12-08_1_6</td>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id        date             datetime  \\\n",
       "0  sim_notes-and-queries_1849-11-03_1_1  1849-11-03  1849-11-03T00:00:00   \n",
       "1  sim_notes-and-queries_1849-11-10_1_2  1849-11-10  1849-11-10T00:00:00   \n",
       "2  sim_notes-and-queries_1849-11-17_1_3  1849-11-17  1849-11-17T00:00:00   \n",
       "3  sim_notes-and-queries_1849-11-24_1_4  1849-11-24  1849-11-24T00:00:00   \n",
       "4  sim_notes-and-queries_1849-12-01_1_5  1849-12-01  1849-12-01T00:00:00   \n",
       "\n",
       "  series vol iss                                       title  \\\n",
       "0   None   1   1  Notes and Queries  1849-11-03: Vol 1 Iss 1   \n",
       "1   None   1   2  Notes and Queries  1849-11-10: Vol 1 Iss 2   \n",
       "2   None   1   3  Notes and Queries  1849-11-17: Vol 1 Iss 3   \n",
       "3   None   1   4  Notes and Queries  1849-11-24: Vol 1 Iss 4   \n",
       "4   None   1   5  Notes and Queries  1849-12-01: Vol 1 Iss 5   \n",
       "\n",
       "                                next_id  \\\n",
       "0  sim_notes-and-queries_1849-11-10_1_2   \n",
       "1  sim_notes-and-queries_1849-11-17_1_3   \n",
       "2  sim_notes-and-queries_1849-11-24_1_4   \n",
       "3  sim_notes-and-queries_1849-12-01_1_5   \n",
       "4  sim_notes-and-queries_1849-12-08_1_6   \n",
       "\n",
       "                                   prev_id  is_index restricted  \n",
       "0  sim_notes-and-queries_1849-1850_1_index         0             \n",
       "1     sim_notes-and-queries_1849-11-03_1_1         0             \n",
       "2     sim_notes-and-queries_1849-11-10_1_2         0             \n",
       "3     sim_notes-and-queries_1849-11-17_1_3         0             \n",
       "4     sim_notes-and-queries_1849-11-24_1_4         0             "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_sql\n",
    "\n",
    "q = \"SELECT * FROM metadata LIMIT 5\"\n",
    "\n",
    "read_sql(q, db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b780eb7",
   "metadata": {},
   "source": [
    "Or we could return the identifiers for index issues between 1875 and 1877: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2daaac0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1875_3_index</td>\n",
       "      <td>Notes and Queries  1875: Vol 3 Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1875_4_index</td>\n",
       "      <td>Notes and Queries  1875: Vol 4 Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1876_5_index</td>\n",
       "      <td>Notes and Queries  1876: Vol 5 Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1876_6_index</td>\n",
       "      <td>Notes and Queries  1876: Vol 6 Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sim_notes-and-queries_1877_7_index</td>\n",
       "      <td>Notes and Queries  1877: Vol 7 Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sim_notes-and-queries_1877_8_index</td>\n",
       "      <td>Notes and Queries  1877: Vol 8 Index</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id                                 title\n",
       "0  sim_notes-and-queries_1875_3_index  Notes and Queries  1875: Vol 3 Index\n",
       "1  sim_notes-and-queries_1875_4_index  Notes and Queries  1875: Vol 4 Index\n",
       "2  sim_notes-and-queries_1876_5_index  Notes and Queries  1876: Vol 5 Index\n",
       "3  sim_notes-and-queries_1876_6_index  Notes and Queries  1876: Vol 6 Index\n",
       "4  sim_notes-and-queries_1877_7_index  Notes and Queries  1877: Vol 7 Index\n",
       "5  sim_notes-and-queries_1877_8_index  Notes and Queries  1877: Vol 8 Index"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT id, title\n",
    "FROM metadata\n",
    "WHERE is_index = 1\n",
    "    -- Extract the year\n",
    "    AND strftime('%Y', datetime) >= '1875'\n",
    "    AND strftime('%Y', datetime) <= '1877'\n",
    "\"\"\"\n",
    "\n",
    "read_sql(q, db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb0f537",
   "metadata": {},
   "source": [
    "### Adding an `issues` Table to the Database\n",
    "\n",
    "Having popped the metadata in the database, let's now create a simple table structure for the searchable text extracted from each issue of *Notes & Queries*.\n",
    "\n",
    "We've already got the metadata stored, so we don't need to put that into the database again. Rather, we'll create a simpler table containing the content and a unique identifier for each record.\n",
    "\n",
    "We can relate this table to the metadata table through a *foreign key*. What this means is that for each entry in the issues table, we also expect to find an entry in the metadata table under the same identifier value.\n",
    "\n",
    "We will also create a full text search table associated with the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "70e03a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_table_issues(db, drop=True):\n",
    "    if drop:\n",
    "        db[\"issues\"].drop(ignore=True)\n",
    "        db[\"issues_fts\"].drop(ignore=True)\n",
    "\n",
    "    db[\"issues\"].create({\n",
    "        \"id\": str,\n",
    "        \"content\": str\n",
    "    }, pk=(\"id\"), foreign_keys=[ (\"id\", \"metadata\", \"id\") # local-table-id, foreign-table, foreign-table-id)\n",
    "    ])\n",
    "    \n",
    "    # Enable full text search\n",
    "    # This creates an extra virtual table (issues_fts) to support the full text search\n",
    "    # A stemmer is applied to support the efficacy of the full-text searching\n",
    "    db[\"issues\"].enable_fts([\"id\", \"content\"], create_triggers=True, tokenize=\"porter\")\n",
    "    \n",
    "create_db_table_issues(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef1acb",
   "metadata": {},
   "source": [
    "To add the content data to the database, we need to download the searchable text associated with each record from the Internet Archive.\n",
    "\n",
    "Before we add the data in bulk, let's do a dummy run of the steps we need to follow.\n",
    "\n",
    "First, we need to download the full text file from the Internet Archive, given a record identifier. We'll use the first data record to provide us with the identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "05d0fc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'sim_notes-and-queries_1849-11-03_1_1',\n",
       " 'date': '1849-11-03',\n",
       " 'title': 'Notes and Queries  1849-11-03: Vol 1 Iss 1',\n",
       " 'vol': '1',\n",
       " 'iss': '1',\n",
       " 'prev_id': 'sim_notes-and-queries_1849-1850_1_index',\n",
       " 'next_id': 'sim_notes-and-queries_1849-11-10_1_2',\n",
       " 'restricted': '',\n",
       " 'datetime': datetime.datetime(1849, 11, 3, 0, 0),\n",
       " 'is_index': False}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_records[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e24651",
   "metadata": {},
   "source": [
    "The download step takes the identifier and requests the `OCR Search Text` file, downloading it to the directory we specified previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff9b24f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download(data_records[0]['id'], destdir=p, silent = True,\n",
    "         formats=[\"OCR Search Text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3c44b5",
   "metadata": {},
   "source": [
    "The data files are actually download as compressed archive files, as we can see if we review the download directory we saved our test download to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a242e1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sim_notes-and-queries_1849-11-03_1_1_hocr_searchtext.txt.gz',\n",
       " 'sim_notes-and-queries_1849-11-03_1_1_hocr_pageindex.json.gz',\n",
       " 'sim_notes-and-queries_1849-11-03_1_1_hocr_searchtext.txt',\n",
       " 'sim_notes-and-queries_1849-11-03_1_1_page_numbers.json',\n",
       " 'sim_notes-and-queries_1849-11-03_1_1_hocr_pageindex.json']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir( p / data_records[0]['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fbd642",
   "metadata": {},
   "source": [
    "We now need to uncompress the `.txt.gz` file to access the fully formed text file.\n",
    "\n",
    "The `gzip` package provides us with the utility we need to access the contents of the archive file.\n",
    "\n",
    "In fact, we don't need to actually uncompress the file into the directory, we can open it and extract its contents \"in memory\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "488b0262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "# Create a simple function to make it even easier to extract the full text content\n",
    "def get_txt_from_file(id_val, dirname='ia-downloads', typ=\"searchtext\"):\n",
    "    \"\"\"Retrieve text from downloaded text file.\"\"\"\n",
    "    if typ==\"searchtext\":\n",
    "        p_ = Path(dirname) / id_val / f'{id_val}_hocr_searchtext.txt.gz'\n",
    "        f = gzip.open(p_,'rb')\n",
    "        content = f.read().decode('utf-8')\n",
    "    elif typ==\"djvutxt\":\n",
    "        p_ = Path(dirname) / id_val / f'{id_val}_djvu.txt'\n",
    "        content = p_.read_text()\n",
    "    else:\n",
    "        content = \"\"\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af28752a",
   "metadata": {},
   "source": [
    "Let's see how it works, previewing the first 200 characters of the unarchived text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7db3edd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n \\n \\n \\nNOTES anp QUERIES:\\nA Medium of Enter-Communication\\nFOR\\nLITERARY MEN, ARTISTS, ANTIQUARIES, GENEALOGISTS, ETC.\\n‘* When found, make a note of.’—Carrain Corrie.\\nVOLUME FIRST.\\nNoveMBER, 1849—May, '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_txt_from_file(data_records[0]['id'])[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78ba65c",
   "metadata": {},
   "source": [
    "If we inspect the text in more detail, we see there are various things in it that we might want to simplify. For example, quotation marks appear in various guises, such as opening and closing quotes of different flavours. We *could* normalise these to a simpler form (for example, \"straight\" quotes `'` and `\"`), However, *if* opening and closing quotes are reliably recognised they do provide us with a simple text for matching text contained *within* the quotes. So for now, let's leave the originally detected quotes in place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fc981e",
   "metadata": {},
   "source": [
    "Having got a method in place, let's now download the contents of the non-index issues for 1849."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bca233f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>Notes and Queries  1849-11-03: Vol 1 Iss 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>Notes and Queries  1849-11-10: Vol 1 Iss 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>Notes and Queries  1849-11-17: Vol 1 Iss 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>Notes and Queries  1849-11-24: Vol 1 Iss 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sim_notes-and-queries_1849-12-01_1_5</td>\n",
       "      <td>Notes and Queries  1849-12-01: Vol 1 Iss 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sim_notes-and-queries_1849-12-08_1_6</td>\n",
       "      <td>Notes and Queries  1849-12-08: Vol 1 Iss 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sim_notes-and-queries_1849-12-15_1_7</td>\n",
       "      <td>Notes and Queries  1849-12-15: Vol 1 Iss 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sim_notes-and-queries_1849-12-22_1_8</td>\n",
       "      <td>Notes and Queries  1849-12-22: Vol 1 Iss 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sim_notes-and-queries_1849-12-29_1_9</td>\n",
       "      <td>Notes and Queries  1849-12-29: Vol 1 Iss 9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  sim_notes-and-queries_1849-11-03_1_1   \n",
       "1  sim_notes-and-queries_1849-11-10_1_2   \n",
       "2  sim_notes-and-queries_1849-11-17_1_3   \n",
       "3  sim_notes-and-queries_1849-11-24_1_4   \n",
       "4  sim_notes-and-queries_1849-12-01_1_5   \n",
       "5  sim_notes-and-queries_1849-12-08_1_6   \n",
       "6  sim_notes-and-queries_1849-12-15_1_7   \n",
       "7  sim_notes-and-queries_1849-12-22_1_8   \n",
       "8  sim_notes-and-queries_1849-12-29_1_9   \n",
       "\n",
       "                                        title  \n",
       "0  Notes and Queries  1849-11-03: Vol 1 Iss 1  \n",
       "1  Notes and Queries  1849-11-10: Vol 1 Iss 2  \n",
       "2  Notes and Queries  1849-11-17: Vol 1 Iss 3  \n",
       "3  Notes and Queries  1849-11-24: Vol 1 Iss 4  \n",
       "4  Notes and Queries  1849-12-01: Vol 1 Iss 5  \n",
       "5  Notes and Queries  1849-12-08: Vol 1 Iss 6  \n",
       "6  Notes and Queries  1849-12-15: Vol 1 Iss 7  \n",
       "7  Notes and Queries  1849-12-22: Vol 1 Iss 8  \n",
       "8  Notes and Queries  1849-12-29: Vol 1 Iss 9  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT id, title\n",
    "FROM metadata\n",
    "WHERE is_index = 0\n",
    "    AND strftime('%Y', datetime) = '1849'\n",
    "\"\"\"\n",
    "results = read_sql(q, db.conn)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090d6ab",
   "metadata": {},
   "source": [
    "The data is return from the `read_sql()` function as a *pandas* dataframe.\n",
    "\n",
    "This *pandas* package provides a very powerful set of tools for working with tabular data, including being able to iterate over he rows of the table and apply a function to each one.\n",
    "\n",
    "If we define a function to download the corresponding search text file from the Internet Archive and extract the text from the downloaded archive file, we can apply that function with a particular column value taken from each row of the dataframe and add the returned content to a new column in the same dataframe.\n",
    "\n",
    "Here's an example function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b3168536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract_text(id_val, typ=\"searchtext\", verbose=False):\n",
    "    \"\"\"Download search text from Internet Archive, extract the text and return it.\"\"\"\n",
    "    if verbose:\n",
    "        print(f\"Downloading {id_val} issue text\")\n",
    "    if typ==\"searchtext\":\n",
    "        download(id_val, destdir=p, silent = True,\n",
    "             formats=[\"OCR Search Text\"])\n",
    "    elif typ==\"djvutxt\":\n",
    "        download(id_val, destdir=p, silent = True,\n",
    "             formats=[\"DjVuTXT\"])\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "    text = get_txt_from_file(id_val, typ=typ)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b0e2fd",
   "metadata": {},
   "source": [
    "The Python *pandas* package natively provides an `apply()` function. However, the `tqdm` progress bar package also provides an \"apply with progress bar\" function, `.progress_apply()` if we enable the appropriate extensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b9b4220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e7b664",
   "metadata": {},
   "source": [
    "Let's apply our `download_and_extract_text()` function to each row of our records table for 1849, keeping track of progress with a progress bar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "82f37643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cbdc88acd5474aa715e7422d0e59af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>Notes and Queries  1849-11-03: Vol 1 Iss 1</td>\n",
       "      <td>\\n \\n \\n \\nNOTES anp QUERIES:\\nA Medium of En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>Notes and Queries  1849-11-10: Vol 1 Iss 2</td>\n",
       "      <td>|\\n \\nA MEDIUM OF INTER-COMMUNICATION\\nFOR\\nLI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>Notes and Queries  1849-11-17: Vol 1 Iss 3</td>\n",
       "      <td>\\n \\n \\nceeeeeeeeee eee\\nA MEDIUM OF\\nLITERAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>Notes and Queries  1849-11-24: Vol 1 Iss 4</td>\n",
       "      <td>\\n \\n \\n \\n~ NOTES anp QUERIES:\\nA MEDIUM OF\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sim_notes-and-queries_1849-12-01_1_5</td>\n",
       "      <td>Notes and Queries  1849-12-01: Vol 1 Iss 5</td>\n",
       "      <td>\\n \\n \\nNOTES anp\\nQUERIES:\\nA MEDIUM OF INTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sim_notes-and-queries_1849-12-08_1_6</td>\n",
       "      <td>Notes and Queries  1849-12-08: Vol 1 Iss 6</td>\n",
       "      <td>\\n \\nOTES\\nAND QUERIES\\nA MEDIUM OF INTER-COM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sim_notes-and-queries_1849-12-15_1_7</td>\n",
       "      <td>Notes and Queries  1849-12-15: Vol 1 Iss 7</td>\n",
       "      <td>\\n \\n \\nNOTES\\nA MEDIUM OF\\nAND QUERIES\\nINTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sim_notes-and-queries_1849-12-22_1_8</td>\n",
       "      <td>Notes and Queries  1849-12-22: Vol 1 Iss 8</td>\n",
       "      <td>\\n \\nNOTES ann QUERIES\\nA MEDIUM OF\\nINTER-CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sim_notes-and-queries_1849-12-29_1_9</td>\n",
       "      <td>Notes and Queries  1849-12-29: Vol 1 Iss 9</td>\n",
       "      <td>\\nNOTE\\nA MEDIUM OF\\nAND QUERIES\\nINTER-COMMU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  sim_notes-and-queries_1849-11-03_1_1   \n",
       "1  sim_notes-and-queries_1849-11-10_1_2   \n",
       "2  sim_notes-and-queries_1849-11-17_1_3   \n",
       "3  sim_notes-and-queries_1849-11-24_1_4   \n",
       "4  sim_notes-and-queries_1849-12-01_1_5   \n",
       "5  sim_notes-and-queries_1849-12-08_1_6   \n",
       "6  sim_notes-and-queries_1849-12-15_1_7   \n",
       "7  sim_notes-and-queries_1849-12-22_1_8   \n",
       "8  sim_notes-and-queries_1849-12-29_1_9   \n",
       "\n",
       "                                        title  \\\n",
       "0  Notes and Queries  1849-11-03: Vol 1 Iss 1   \n",
       "1  Notes and Queries  1849-11-10: Vol 1 Iss 2   \n",
       "2  Notes and Queries  1849-11-17: Vol 1 Iss 3   \n",
       "3  Notes and Queries  1849-11-24: Vol 1 Iss 4   \n",
       "4  Notes and Queries  1849-12-01: Vol 1 Iss 5   \n",
       "5  Notes and Queries  1849-12-08: Vol 1 Iss 6   \n",
       "6  Notes and Queries  1849-12-15: Vol 1 Iss 7   \n",
       "7  Notes and Queries  1849-12-22: Vol 1 Iss 8   \n",
       "8  Notes and Queries  1849-12-29: Vol 1 Iss 9   \n",
       "\n",
       "                                             content  \n",
       "0   \\n \\n \\n \\nNOTES anp QUERIES:\\nA Medium of En...  \n",
       "1  |\\n \\nA MEDIUM OF INTER-COMMUNICATION\\nFOR\\nLI...  \n",
       "2   \\n \\n \\nceeeeeeeeee eee\\nA MEDIUM OF\\nLITERAR...  \n",
       "3   \\n \\n \\n \\n~ NOTES anp QUERIES:\\nA MEDIUM OF\\...  \n",
       "4   \\n \\n \\nNOTES anp\\nQUERIES:\\nA MEDIUM OF INTE...  \n",
       "5   \\n \\nOTES\\nAND QUERIES\\nA MEDIUM OF INTER-COM...  \n",
       "6   \\n \\n \\nNOTES\\nA MEDIUM OF\\nAND QUERIES\\nINTE...  \n",
       "7   \\n \\nNOTES ann QUERIES\\nA MEDIUM OF\\nINTER-CO...  \n",
       "8   \\nNOTE\\nA MEDIUM OF\\nAND QUERIES\\nINTER-COMMU...  "
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['content'] = results[\"id\"].progress_apply(download_and_extract_text)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5cab45",
   "metadata": {},
   "source": [
    "We can now add that data table directly to our database using the *pandas* `.to_sql()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "51b2fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the issue database table\n",
    "table_name = \"issues\"\n",
    "results[[\"id\", \"content\"]].to_sql(table_name, db.conn, index=False, if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dbabc8",
   "metadata": {},
   "source": [
    "*Note that this recipe does not represent a very efficient way of handling things: the pandas dataframe is held in memory, so as we add more rows, the memory requirements to store the data increase. A more efficient approach might be to create a function that retrieves each file, adds its contents to the database, and then perhaps even deletes the downloaded file, rather than adding the content to the in-memory dataframe.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29fb543",
   "metadata": {},
   "source": [
    "Let's see if we can query it, first at the basic table level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "9e6d96fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>\\n \\n \\nceeeeeeeeee eee\\nA MEDIUM OF\\nLITERAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>\\n \\n \\n \\n~ NOTES anp QUERIES:\\nA MEDIUM OF\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1849-12-15_1_7</td>\n",
       "      <td>\\n \\n \\nNOTES\\nA MEDIUM OF\\nAND QUERIES\\nINTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1849-12-29_1_9</td>\n",
       "      <td>\\nNOTE\\nA MEDIUM OF\\nAND QUERIES\\nINTER-COMMU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  sim_notes-and-queries_1849-11-17_1_3   \n",
       "1  sim_notes-and-queries_1849-11-24_1_4   \n",
       "2  sim_notes-and-queries_1849-12-15_1_7   \n",
       "3  sim_notes-and-queries_1849-12-29_1_9   \n",
       "\n",
       "                                             content  \n",
       "0   \\n \\n \\nceeeeeeeeee eee\\nA MEDIUM OF\\nLITERAR...  \n",
       "1   \\n \\n \\n \\n~ NOTES anp QUERIES:\\nA MEDIUM OF\\...  \n",
       "2   \\n \\n \\nNOTES\\nA MEDIUM OF\\nAND QUERIES\\nINTE...  \n",
       "3   \\nNOTE\\nA MEDIUM OF\\nAND QUERIES\\nINTER-COMMU...  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT id, content\n",
    "FROM issues\n",
    "WHERE LOWER(content) LIKE \"%customs%\"\n",
    "\"\"\"\n",
    "read_sql(q, db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22adeee8",
   "metadata": {},
   "source": [
    "This is not overly helpful, perhaps. We can do better with the full text search, which will also allow us to return a snippet around the first, or highest ranked, location of any matched search terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e0cbaeda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>...At length the __custom__ became general in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>...royal domains, leases of __customs__, &amp;c., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>...the Manners and __Customs__ of Ancient Gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1849-12-01_1_5</td>\n",
       "      <td>...Morning, as was his __Custom__, attended by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sim_notes-and-queries_1849-12-15_1_7</td>\n",
       "      <td>...So far as English usages and __customs__ ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sim_notes-and-queries_1849-12-22_1_8</td>\n",
       "      <td>...Sessions House and the __Custom__ House of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sim_notes-and-queries_1849-12-29_1_9</td>\n",
       "      <td>...elucidation of old world __customs__ and ob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  sim_notes-and-queries_1849-11-10_1_2   \n",
       "1  sim_notes-and-queries_1849-11-17_1_3   \n",
       "2  sim_notes-and-queries_1849-11-24_1_4   \n",
       "3  sim_notes-and-queries_1849-12-01_1_5   \n",
       "4  sim_notes-and-queries_1849-12-15_1_7   \n",
       "5  sim_notes-and-queries_1849-12-22_1_8   \n",
       "6  sim_notes-and-queries_1849-12-29_1_9   \n",
       "\n",
       "                                                clip  \n",
       "0  ...At length the __custom__ became general in ...  \n",
       "1  ...royal domains, leases of __customs__, &c., ...  \n",
       "2  ...the Manners and __Customs__ of Ancient Gree...  \n",
       "3  ...Morning, as was his __Custom__, attended by...  \n",
       "4  ...So far as English usages and __customs__ ar...  \n",
       "5  ...Sessions House and the __Custom__ House of ...  \n",
       "6  ...elucidation of old world __customs__ and ob...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_term = \"customs\"\n",
    "\n",
    "q = f\"\"\"\n",
    "SELECT id, snippet(issues_fts, -1, \"__\", \"__\", \"...\", 10) as clip\n",
    "FROM issues_fts WHERE issues_fts MATCH {db.quote(search_term)} ;\n",
    "\"\"\"\n",
    "\n",
    "read_sql(q, db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5383ecab",
   "metadata": {},
   "source": [
    "This is okay as far as is goes: we can identify *issues* of *Notes and Queries* that contain a particular search term, retrieve the whole document, and even display a concordance for the first (or highest ranking) occurrence of the search term(s) to provide context for the response. But it's not ideal. For example, to display a concordance of each term in the full text document that matches our search term, we need to generate our own concordance, which may be difficulat where matches are inexact (for example if the match relies on stemming). There are also many pages in each issue of *Notes and Queries* and it would be useful if we could get the result at a better level of granularity.\n",
    "\n",
    "The `ouseful_sqlite_search_utils` package includes various functions for allowing us to tunnel into a text document to retrieve The tools aren't necessarily the *fastest* utilities to run, particularly on large databases, but they get their eventually.\n",
    "\n",
    "One particular utility will split a document into sentences and return each sentence on a separate row of a newly created virtual table. We can then search within these values for our search term, although we are limited to running *exact match* queries, rather than the more forgiving full text search queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8d146a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'sim_notes-and-queries_1849-11-10_1_2',\n",
       "  'sentence': 'An examination of the structure of books of this period would confirm this view, and show that their apparent clumsiness is to be explained by the facility it was then the custom to afford for the interpolation or extraction of “sheets,” by a contrivance somewhat resembling that\\npapers in a cover, and known as the “ patent leaf-holder,”\\n'},\n",
       " {'id': 'sim_notes-and-queries_1849-11-10_1_2',\n",
       "  'sentence': 'At length the custom became general in Aden ; and it was not only drunk in the\\nnight by those who were desirous of being kept awake, but in the day for the sake of its other agreeable qualities.'},\n",
       " {'id': 'sim_notes-and-queries_1849-11-10_1_2',\n",
       "  'sentence': 'From hence the custom extended itself to many other towns of Arabia, particularly to Medina, and then to Grand Cairo in Egypt, where the dervises of Yemen, who lived in a district by themselves, drank coffee on the nights they intended to spend in\\n| devotion.'},\n",
       " {'id': 'sim_notes-and-queries_1849-11-10_1_2',\n",
       "  'sentence': 'In that year, Soliman Aga, ambassador from the Sultan Mahomet the Fourth, arrived, who, with his retinue, brought a considerable quantity of coffee with them, and made presents of it to per- sons both of the court and city, and is sup- posed to have established the custom of drinking it.'},\n",
       " {'id': 'sim_notes-and-queries_1849-11-10_1_2',\n",
       "  'sentence': 'How often\\nman stumble upon some elucidation of a doubtful |\\nphrase, or disputed passage ;—some illustration of an obsolete custom hitherto unnoticed ; — some biogra- phical aneedote or precise date hitherto unrecorded ;— some book, or some edition, hitherto unknown or im- perfectly described.'}]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ouseful_sqlite_search_utils import snippets\n",
    "\n",
    "snippets.register_snippets(db.conn)\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT * FROM\n",
    "    (SELECT id, sentence\n",
    "     FROM issues, get_sentences(1, NULL, issues.content)\n",
    "     WHERE issues.id = \"sim_notes-and-queries_1849-11-10_1_2\")\n",
    "WHERE sentence LIKE \"% custom %\"\n",
    "\"\"\"\n",
    "\n",
    "# Show the full result record in each case\n",
    "read_sql(q, db.conn).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746e904a",
   "metadata": {},
   "source": [
    "### Extracting Pages\n",
    "\n",
    "To make for more efficient granular searching, it would be useful if our content was stored in a more granular way.\n",
    "\n",
    "Ideally, we would extract items at the \"article\" level, but there is no simple way of chunking the document at this level. We could process it to extract items at the sentence or paragraph level and add those to their own table, but that might be *too* granular.\n",
    "\n",
    "However, by inspection of the files available for each issue, there appears to be another level of organisation that we can access: the *page* level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af20b944",
   "metadata": {},
   "source": [
    "*Page* metadata is provided in the the form of two files:\n",
    "\n",
    "- `OCR Page Index`: downloaded as a compressed `.gz` file the expanded file contains a list of lists. Each inner list contains four integers and each page has an associated inner list. The first and second integers in each inner list are the character count in the search text file representing the first and last characters on the corresponding page;\n",
    "- `Page Numbers JSON`: the pages numbers JSON file, which is downloaded as an uncompressed JSON file contains a JSON object with a `\"pages\"` attribute that returns a list of records; each record has four attributes: `\"leafNum\": int` (starting with index value 1), `\"ocr_value\": list` (a list of candidate OCR values), `\"pageNumber\": str` and `\"confidence\": float`. A top-level `\"confidence\"` attribute gives an indication of how likely it is that page numbers are available across the whole document.\n",
    "\n",
    "We also need the `OCR Search Text` file.\n",
    "\n",
    "Let's get a complete set of necessary files for a few sample records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "caf575ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ia_records_by_format(records, path=\".\", formats=None):\n",
    "    \"\"\"Download records from Internet Archive given ID and desired format(s)\"\"\"\n",
    "    formats = formats if formats else [\"OCR Search Text\", \"OCR Page Index\", \"Page Numbers JSON\"]\n",
    "    \n",
    "    for record in tqdm(records):\n",
    "        _id = record['id']\n",
    "        download(_id, destdir=path,\n",
    "                 formats=formats,\n",
    "                 silent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0707ca5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d75b11595644241a773d55f8dc62187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grab page counts and page structure files\n",
    "sample_records = data_records[:5]\n",
    "\n",
    "download_ia_records_by_format(sample_records, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166bbe36",
   "metadata": {},
   "source": [
    "We now need to figure out how to open and parse the page index and page numbers files, and check the lists are the correct lengths.\n",
    "\n",
    "The Python `zip` function  lets us \"zip\" together elements from different, parallel lists. We can also insert the same item, repeatedly, into each row using the `itertools.repeat()` function to generate as many repetitions of the same character as are required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ecef7dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d4189",
   "metadata": {},
   "source": [
    "Example of using `itertools.repeat()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f5c74a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1, 'x'), ('a', 2, 'y')]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of list\n",
    "list(zip(itertools.repeat(\"a\"), [1, 2], [\"x\",\"y\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce06c741",
   "metadata": {},
   "source": [
    "We can now use this approach to create a zipped combination of the record ID values, page numbers and page character indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1a143af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sim_notes-and-queries_1849-11-03_1_1',\n",
       "  {'leafNum': 1, 'ocr_value': [], 'pageNumber': '', 'confidence': 0},\n",
       "  [0, 301, 559, 14345]),\n",
       " ('sim_notes-and-queries_1849-11-03_1_1',\n",
       "  {'leafNum': 2, 'ocr_value': ['4', '3'], 'pageNumber': '', 'confidence': 0},\n",
       "  [301, 307, 14345, 15954]),\n",
       " ('sim_notes-and-queries_1849-11-03_1_1',\n",
       "  {'leafNum': 3, 'ocr_value': ['2'], 'pageNumber': '2', 'confidence': 100},\n",
       "  [307, 3212, 15954, 101879]),\n",
       " ('sim_notes-and-queries_1849-11-03_1_1',\n",
       "  {'leafNum': 4, 'ocr_value': ['3'], 'pageNumber': '3', 'confidence': 100},\n",
       "  [3212, 7431, 101879, 228974]),\n",
       " ('sim_notes-and-queries_1849-11-03_1_1',\n",
       "  {'leafNum': 5, 'ocr_value': [], 'pageNumber': '4', 'confidence': 100},\n",
       "  [7431, 12267, 228974, 370105])]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import itertools\n",
    "\n",
    "#for record in tqdm(sample_records):\n",
    "\n",
    "record = sample_records[0]\n",
    "\n",
    "id_val = record['id']\n",
    "p_ = Path(dirname) / id_val \n",
    "\n",
    "# Get the page numbers\n",
    "with open(p_ / f'{id_val}_page_numbers.json', 'r') as f:\n",
    "    page_numbers = json.load(f)\n",
    "\n",
    "# Get the page character indexes\n",
    "with gzip.open(p_ / f'{id_val}_hocr_pageindex.json.gz', 'rb') as g:\n",
    "    # The last element seems to be redundant\n",
    "    page_indexes = json.loads(g.read().decode('utf-8'))[:-1]\n",
    "\n",
    "# Optionally text the record counts are the same for page numbers and character indexes\n",
    "#assert len(page_indexes) == len(page_numbers['pages'])\n",
    "\n",
    "# Preview the result\n",
    "list(zip(itertools.repeat(id_val), page_numbers['pages'], page_indexes))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2254dcd1",
   "metadata": {},
   "source": [
    "We could add this page related data directly to the pages table, or we could create another simple database table to store it.\n",
    "\n",
    "Here's what a separate table might look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "b2e7ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_table_pages_metadata(db, drop=True):\n",
    "    if drop:\n",
    "        db[\"pages_metadata\"].drop(ignore=True)\n",
    "    db[\"pages_metadata\"].create({\n",
    "        \"id\": str,\n",
    "        \"page_idx\": int, # This is just a count as we work through the pages \n",
    "        \"page_char_start\": int,\n",
    "        \"page_char_end\": int,\n",
    "        \"page_leaf_num\": int, \n",
    "        \"page_num\": str,\n",
    "        \"page_num_conf\": float # A confidence value relating to the page number detection\n",
    "    }, pk=(\"id\", \"page_idx\")) # compound foreign keys not currently available via sqlite_utils?\n",
    "    \n",
    "create_db_table_pages_metadata(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61e0f69",
   "metadata": {},
   "source": [
    "The following function \"zips\" together the contents of the page index and page numbers files. Each \"line item\" is a rather unwieldy mixmatch of elements, but we'll deal with those in a moment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "11a2375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "\n",
    "def raw_pages_metadata(id_val):\n",
    "    \"\"\"Get page metadata.\"\"\"\n",
    "\n",
    "    p_ = Path(dirname) / id_val\n",
    "\n",
    "    # Get the page numbers\n",
    "    with open(p_ / f'{id_val}_page_numbers.json', 'r') as f:\n",
    "        # We can ignore the last value\n",
    "        page_numbers = json.load(f)\n",
    "    \n",
    "    # Get the page character indexes\n",
    "    with gzip.open(p_ / f'{id_val}_hocr_pageindex.json.gz', 'rb') as g:\n",
    "        # The last element seems to be redundant\n",
    "        page_indexes = json.loads(g.read().decode('utf-8'))[:-1]\n",
    "\n",
    "    # Add the id and an index count\n",
    "    return zip(itertools.repeat(id_val), range(len(page_indexes)),\n",
    "               page_numbers['pages'], page_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94261676",
   "metadata": {},
   "source": [
    "For each line item in the zipped datastructure, we can parse out values into a more readable data object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "157aaf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page_metadata(item):\n",
    "    \"\"\"Parse out page attributes from the raw page metadata construct.\"\"\"\n",
    "    _id = item[0]\n",
    "    page_idx = item[1]\n",
    "    _page_nums = item[2]\n",
    "    ix = item[3]\n",
    "    obj = {'id': _id,\n",
    "           'page_idx': page_idx, # Maintain our own count, just in case; should be page_leaf_num-1\n",
    "           'page_char_start': ix[0],\n",
    "           'page_char_end': ix[1],\n",
    "           'page_leaf_num': _page_nums['leafNum'],\n",
    "           'page_num': _page_nums['pageNumber'],\n",
    "           'page_num_conf':_page_nums['confidence']\n",
    "          }\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f384372",
   "metadata": {},
   "source": [
    "Let's see how that looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "2da96ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'sim_notes-and-queries_1849-11-03_1_1', 'page_idx': 0, 'page_char_start': 0, 'page_char_end': 301, 'page_leaf_num': 1, 'page_num': '', 'page_num_conf': 0}\n"
     ]
    }
   ],
   "source": [
    "sample_pages_metadata_item = raw_pages_metadata(id_val)\n",
    "\n",
    "for pmi in sample_pages_metadata_item:\n",
    "    print(parse_page_metadata(pmi))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b47ab7",
   "metadata": {},
   "source": [
    "We can now trivially add the page metadata to the `pages_metadata` database table. Let's try it with our sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "992152af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_page_metadata_to_db(db, records, verbose=False):\n",
    "    \"\"\"Add page metadata to database.\"\"\"\n",
    "    \n",
    "    for record in records:\n",
    "        id_val = record[\"id\"]\n",
    "        if verbose:\n",
    "            print(id_val)\n",
    "            \n",
    "        records = [parse_page_metadata(pmi) for pmi in raw_pages_metadata(id_val)]\n",
    "    \n",
    "        # Add records to the database\n",
    "        db[\"pages_metadata\"].insert_all(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4942d23e",
   "metadata": {},
   "source": [
    "And run it with the page metadata records selected via a `id_val`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "38991a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the db table\n",
    "db[\"pages_metadata\"].delete_where()\n",
    "\n",
    "# Add the metadata to the table\n",
    "add_page_metadata_to_db(db, sample_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6b9722",
   "metadata": {},
   "source": [
    "Let's see how that looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "129bb281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>page_idx</th>\n",
       "      <th>page_char_start</th>\n",
       "      <th>page_char_end</th>\n",
       "      <th>page_leaf_num</th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_num_conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>1</td>\n",
       "      <td>301</td>\n",
       "      <td>307</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>3212</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>3</td>\n",
       "      <td>3212</td>\n",
       "      <td>7431</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>4</td>\n",
       "      <td>7431</td>\n",
       "      <td>12267</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  page_idx  page_char_start  \\\n",
       "0  sim_notes-and-queries_1849-11-03_1_1         0                0   \n",
       "1  sim_notes-and-queries_1849-11-03_1_1         1              301   \n",
       "2  sim_notes-and-queries_1849-11-03_1_1         2              307   \n",
       "3  sim_notes-and-queries_1849-11-03_1_1         3             3212   \n",
       "4  sim_notes-and-queries_1849-11-03_1_1         4             7431   \n",
       "\n",
       "   page_char_end  page_leaf_num page_num  page_num_conf  \n",
       "0            301              1                     0.0  \n",
       "1            307              2                     0.0  \n",
       "2           3212              3        2          100.0  \n",
       "3           7431              4        3          100.0  \n",
       "4          12267              5        4          100.0  "
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_sql\n",
    "\n",
    "q = \"SELECT * FROM pages_metadata LIMIT 5\"\n",
    "\n",
    "read_sql(q, db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd5aaf",
   "metadata": {},
   "source": [
    "Alternatively, we can view the results as a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "5a4164e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'sim_notes-and-queries_1849-11-03_1_1',\n",
       "  'page_idx': 0,\n",
       "  'page_char_start': 0,\n",
       "  'page_char_end': 301,\n",
       "  'page_leaf_num': 1,\n",
       "  'page_num': '',\n",
       "  'page_num_conf': 0.0},\n",
       " {'id': 'sim_notes-and-queries_1849-11-03_1_1',\n",
       "  'page_idx': 1,\n",
       "  'page_char_start': 301,\n",
       "  'page_char_end': 307,\n",
       "  'page_leaf_num': 2,\n",
       "  'page_num': '',\n",
       "  'page_num_conf': 0.0},\n",
       " {'id': 'sim_notes-and-queries_1849-11-03_1_1',\n",
       "  'page_idx': 2,\n",
       "  'page_char_start': 307,\n",
       "  'page_char_end': 3212,\n",
       "  'page_leaf_num': 3,\n",
       "  'page_num': '2',\n",
       "  'page_num_conf': 100.0}]"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_sql(q, db.conn).to_dict(orient=\"records\")[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c6b35",
   "metadata": {},
   "source": [
    "For each file containg the search text for a particular issue, we also need a routine to extract the page level content. Which is to say, we need to chunk the content based on character indices associated with the first and last characters on each page in the corresponding search text file. \n",
    "\n",
    "This essentially boils down to:\n",
    "\n",
    "- grabbing the page index values;\n",
    "- grabbing the page search text;\n",
    "- chunking the search text according to the page index values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7265ae6",
   "metadata": {},
   "source": [
    "We can apply a page chunker at the document level, paginating the content file, and adding things to the database.\n",
    "\n",
    "The following function will load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "5b0b68e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_page_text(db, id_val):\n",
    "    \"\"\"Chunk text according to page_index values.\"\"\"\n",
    "    \n",
    "    q = f'SELECT * FROM pages_metadata WHERE id=\"{id_val}\"'\n",
    "    page_indexes = read_sql(q, db.conn).to_dict(orient=\"records\")\n",
    "    \n",
    "    text = get_txt_from_file(id_val)\n",
    "        \n",
    "    for ix in page_indexes:\n",
    "        ix[\"page_text\"] = text[ix[\"page_char_start\"]:ix[\"page_char_end\"]].strip()\n",
    "\n",
    "    return page_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021cdef6",
   "metadata": {},
   "source": [
    "Let's see if we've managed to pull out some page text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "4cb5a4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'sim_notes-and-queries_1849-11-03_1_1',\n",
       "  'page_idx': 0,\n",
       "  'page_char_start': 0,\n",
       "  'page_char_end': 301,\n",
       "  'page_leaf_num': 1,\n",
       "  'page_num': '',\n",
       "  'page_num_conf': 0.0,\n",
       "  'page_text': 'NOTES anp QUERIES:\\nA Medium of Enter-Communication\\nFOR\\nLITERARY MEN, ARTISTS, ANTIQUARIES, GENEALOGISTS, ETC.\\n‘* When found, make a note of.’—Carrain Corrie.\\nVOLUME FIRST.\\nNoveMBER, 1849—May, 1850.\\nLONDON: GEORGE BELL, 186. FLEET STREET 1850.\\n[SOLD BY ALL BOOKSELLERS AND NEWSMEN. |'},\n",
       " {'id': 'sim_notes-and-queries_1849-11-03_1_1',\n",
       "  'page_idx': 1,\n",
       "  'page_char_start': 301,\n",
       "  'page_char_end': 307,\n",
       "  'page_leaf_num': 2,\n",
       "  'page_num': '',\n",
       "  'page_num_conf': 0.0,\n",
       "  'page_text': ''},\n",
       " {'id': 'sim_notes-and-queries_1849-11-03_1_1',\n",
       "  'page_idx': 2,\n",
       "  'page_char_start': 307,\n",
       "  'page_char_end': 3212,\n",
       "  'page_leaf_num': 3,\n",
       "  'page_num': '2',\n",
       "  'page_num_conf': 100.0,\n",
       "  'page_text': 'NOTES ann QUERIES:\\nA MEDIUM OF\\n——_——s\\nINTER-COMMUNICATION\\nFOR\\nLITERARY MEN, ARTISTS,\\nANTIQUARIES, GENEALOGISTS, ETC.\\n“When found, make a note of.” — Carrain Currie.\\nNOTES AND QUERIES.\\nTue nature and design of the present work have been so fully stated in the Prospectus, and are indeed so far explained by its very Title, that it is unnecessary to occupy any great portion of its first number with details on the subject. We are under no temptation to fill its columns with an account of what we hope future numbers will be. Indeed, we would rather give a specimen than a de- scription; and only regret that, from the wide range of subjects which it is intended to embrace, and the correspondence and contri- butions of various kinds which we are led to expect, even this can only be done gradually. A few words of introduction and explanation may, however, be allowed; and, indeed, ought to be prefixed, that we may be understood by those readers who have not seen our Pro- spectus.\\n“ WHEN FOUND, MAKE A NOTE OF,” is a most admirable rule; and if the excellent Captain had never uttered another word, he might have passed for a profound philosopher. It is a rule which should shine in gilt letters on the gingerbread of youth, and the specta- ele-case of age. Every man who reads with any view beyond mere pastime, knows the value of it. Every one, more or less, acts upon it. Every one regrets and suffers who\\n \\nSATURDAY, NOVEMBER 3. 1849.\\nPrice Threepence. Stamped Edition, 4 d.\\n \\nneglects it. There is some trouble in it, to be sure; but in what good thing is there not? and what trouble does it save! Nay, what mischief! Half the lies that are current in the world owe their origin to a misplaced confidence in memory, rather than to inten- tional falsehood. We have never known more than one man who could deliberately and con- scientiously say that his memory had never deceived him; and he (when he saw that he had excited the surprise of his hearers, espe- cially those who knew how many years he had spent in the management of important com- mercial affairs) used to. add, — because he had never trusted it; but had uniformly written down what he was anxious to remember.\\nBut, on the other hand, it cannot be denied that reading and writing men, of moderate industry, who act on this rule for any con- siderable length of time, will aceumulate a good deal of matter in various forms, shapes, and sizes—some more, some less legible and intelligible —some unposted in old pocket books — some on whole or half sheets, or mere seraps of paper, and backs of letters— some, lost sight of and forgotten, stuffing out old portfolios, or getting smoky edges in bundles tied up with faded tape. There are, we are quite sure, countless boxes and drawers, and pigeon-holes of such things, which want look- ing over, and would well repay the trouble.\\n \\n \\nFOURTH EDITION.'}]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample index ID\n",
    "sample_id_val = sample_records[0][\"id\"]\n",
    "\n",
    "# Get the chunked text back as part of the metadata record\n",
    "sample_pages = chunk_page_text(db, sample_id_val)\n",
    "\n",
    "sample_pages[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4444b608",
   "metadata": {},
   "source": [
    "### Modifying the `pages_metadata` Table in the Database\n",
    "\n",
    "Using the `chunk_page_text()` function, we can add page content to our pages metadata *in-memory*. But what if we want to add it to the database. The `pages_metadata` already exists, but does not include a `text` column. However, we can modify that table to include just such a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "eb1c2148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table pages_metadata (id, page_idx, page_char_start, page_char_end, page_leaf_num, page_num, page_num_conf, page_text)>"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[\"pages_metadata\"].add_column(\"page_text\", str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca4a8de",
   "metadata": {},
   "source": [
    "We can also enable a full text search facility over the table. Our interest is primarily in searching over the `page_text`, bit if we include a couple of other columns that can help us key into records in other tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "f2ecaa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table pages_metadata (id, page_idx, page_char_start, page_char_end, page_leaf_num, page_num, page_num_conf, page_text)>"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable full text search\n",
    "# This creates an extra virtual table to support the full text search\n",
    "db[\"pages_metadata_fts\"].drop()\n",
    "db[\"pages_metadata\"].enable_fts([\"id\", \"page_idx\", \"page_text\"], create_triggers=True, tokenize=\"porter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607de6a7",
   "metadata": {},
   "source": [
    "We can now update the records in the `pages_metadata` table so they include the `page_text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "4f3a8f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = f'SELECT DISTINCT(id) FROM pages_metadata;'\n",
    "id_vals = read_sql(q, db.conn).to_dict(orient=\"records\")\n",
    "\n",
    "for sample_id_val in id_vals:\n",
    "    updated_pages = chunk_page_text(db, sample_id_val[\"id\"])\n",
    "    db[\"pages_metadata\"].upsert_all(updated_pages, pk=(\"id\", \"page_idx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e76ee",
   "metadata": {},
   "source": [
    "We should now be able to search at the page level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "32ef34ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>page_idx</th>\n",
       "      <th>page_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>5</td>\n",
       "      <td>22 NOTES\\n \\nAND QUERIES.\\nCatalogue — in whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>8</td>\n",
       "      <td>Nov. 10. 1849.)\\nNOTES AND QUERIES.\\n25\\n \\nne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>9</td>\n",
       "      <td>bring with him some coffee, which he believed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>12</td>\n",
       "      <td>Nov. 10. 1849.]\\nActing her passions on our st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>14</td>\n",
       "      <td>~—\\n \\n|\\n \\nNov. 10. 1849.]\\nNOTES AND QUERIE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>8</td>\n",
       "      <td>= 17. 1849.] }\\nreceive his representations an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>2</td>\n",
       "      <td>~vwe eS | FY\\nweNTe 6 FS-r—lCUcUOrlClC hLOOlhC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>6</td>\n",
       "      <td>NOTES AND QUERIES.\\n \\n \\n \\nNov. 24. 1849.]\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>15</td>\n",
       "      <td>NOTES AND QUERIES.\\nJust published, Part II., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sim_notes-and-queries_1849-12-01_1_5</td>\n",
       "      <td>5</td>\n",
       "      <td>NOTES AND QUERIES.\\n \\nmore than three Passeng...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  page_idx  \\\n",
       "0  sim_notes-and-queries_1849-11-10_1_2         5   \n",
       "1  sim_notes-and-queries_1849-11-10_1_2         8   \n",
       "2  sim_notes-and-queries_1849-11-10_1_2         9   \n",
       "3  sim_notes-and-queries_1849-11-10_1_2        12   \n",
       "4  sim_notes-and-queries_1849-11-10_1_2        14   \n",
       "5  sim_notes-and-queries_1849-11-17_1_3         8   \n",
       "6  sim_notes-and-queries_1849-11-24_1_4         2   \n",
       "7  sim_notes-and-queries_1849-11-24_1_4         6   \n",
       "8  sim_notes-and-queries_1849-11-24_1_4        15   \n",
       "9  sim_notes-and-queries_1849-12-01_1_5         5   \n",
       "\n",
       "                                           page_text  \n",
       "0  22 NOTES\\n \\nAND QUERIES.\\nCatalogue — in whic...  \n",
       "1  Nov. 10. 1849.)\\nNOTES AND QUERIES.\\n25\\n \\nne...  \n",
       "2  bring with him some coffee, which he believed ...  \n",
       "3  Nov. 10. 1849.]\\nActing her passions on our st...  \n",
       "4  ~—\\n \\n|\\n \\nNov. 10. 1849.]\\nNOTES AND QUERIE...  \n",
       "5  = 17. 1849.] }\\nreceive his representations an...  \n",
       "6  ~vwe eS | FY\\nweNTe 6 FS-r—lCUcUOrlClC hLOOlhC...  \n",
       "7  NOTES AND QUERIES.\\n \\n \\n \\nNov. 24. 1849.]\\n...  \n",
       "8  NOTES AND QUERIES.\\nJust published, Part II., ...  \n",
       "9  NOTES AND QUERIES.\\n \\nmore than three Passeng...  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_term = \"customs\"\n",
    "\n",
    "q = f\"\"\"\n",
    "SELECT * FROM pages_metadata_fts\n",
    "WHERE pages_metadata_fts MATCH {db.quote(search_term)};\n",
    "\"\"\"\n",
    "\n",
    "read_sql(q, db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c01f20",
   "metadata": {},
   "source": [
    "We can then bring in additional columns from the original `pages_metadata` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "e5f5ba91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_leaf_num</th>\n",
       "      <th>id</th>\n",
       "      <th>page_idx</th>\n",
       "      <th>page_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>5</td>\n",
       "      <td>22 NOTES\\n \\nAND QUERIES.\\nCatalogue — in whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>8</td>\n",
       "      <td>Nov. 10. 1849.)\\nNOTES AND QUERIES.\\n25\\n \\nne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>9</td>\n",
       "      <td>bring with him some coffee, which he believed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>12</td>\n",
       "      <td>Nov. 10. 1849.]\\nActing her passions on our st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>14</td>\n",
       "      <td>~—\\n \\n|\\n \\nNov. 10. 1849.]\\nNOTES AND QUERIE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>8</td>\n",
       "      <td>= 17. 1849.] }\\nreceive his representations an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>2</td>\n",
       "      <td>~vwe eS | FY\\nweNTe 6 FS-r—lCUcUOrlClC hLOOlhC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>6</td>\n",
       "      <td>NOTES AND QUERIES.\\n \\n \\n \\nNov. 24. 1849.]\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>65</td>\n",
       "      <td>16</td>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>15</td>\n",
       "      <td>NOTES AND QUERIES.\\nJust published, Part II., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>71</td>\n",
       "      <td>6</td>\n",
       "      <td>sim_notes-and-queries_1849-12-01_1_5</td>\n",
       "      <td>5</td>\n",
       "      <td>NOTES AND QUERIES.\\n \\nmore than three Passeng...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  page_num  page_leaf_num                                    id  page_idx  \\\n",
       "0       23              6  sim_notes-and-queries_1849-11-10_1_2         5   \n",
       "1       26              9  sim_notes-and-queries_1849-11-10_1_2         8   \n",
       "2       27             10  sim_notes-and-queries_1849-11-10_1_2         9   \n",
       "3       30             13  sim_notes-and-queries_1849-11-10_1_2        12   \n",
       "4       32             15  sim_notes-and-queries_1849-11-10_1_2        14   \n",
       "5       42              9  sim_notes-and-queries_1849-11-17_1_3         8   \n",
       "6       52              3  sim_notes-and-queries_1849-11-24_1_4         2   \n",
       "7       56              7  sim_notes-and-queries_1849-11-24_1_4         6   \n",
       "8       65             16  sim_notes-and-queries_1849-11-24_1_4        15   \n",
       "9       71              6  sim_notes-and-queries_1849-12-01_1_5         5   \n",
       "\n",
       "                                           page_text  \n",
       "0  22 NOTES\\n \\nAND QUERIES.\\nCatalogue — in whic...  \n",
       "1  Nov. 10. 1849.)\\nNOTES AND QUERIES.\\n25\\n \\nne...  \n",
       "2  bring with him some coffee, which he believed ...  \n",
       "3  Nov. 10. 1849.]\\nActing her passions on our st...  \n",
       "4  ~—\\n \\n|\\n \\nNov. 10. 1849.]\\nNOTES AND QUERIE...  \n",
       "5  = 17. 1849.] }\\nreceive his representations an...  \n",
       "6  ~vwe eS | FY\\nweNTe 6 FS-r—lCUcUOrlClC hLOOlhC...  \n",
       "7  NOTES AND QUERIES.\\n \\n \\n \\nNov. 24. 1849.]\\n...  \n",
       "8  NOTES AND QUERIES.\\nJust published, Part II., ...  \n",
       "9  NOTES AND QUERIES.\\n \\nmore than three Passeng...  "
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_term = \"customs\"\n",
    "\n",
    "q = f\"\"\"\n",
    "SELECT page_num, page_leaf_num, pages_metadata_fts.* FROM pages_metadata_fts, pages_metadata\n",
    "WHERE pages_metadata_fts MATCH {db.quote(search_term)} \n",
    "    AND pages_metadata.id = pages_metadata_fts.id\n",
    "    AND pages_metadata.page_idx = pages_metadata_fts.page_idx;\n",
    "\"\"\"\n",
    "\n",
    "read_sql(q, db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ffe2a6",
   "metadata": {},
   "source": [
    "### Automatically Populating the `pages` Table from the `issues` Table\n",
    "\n",
    "Rather than manually adding the page data to the `pages` table, we can automatically create the `pages` table from the content contained in the `issues` table and the page metadata in the `metaday` table.\n",
    "\n",
    "TO DO  - CREATE TABLE AS ;\n",
    "- maybe also as an extra demonstrate how to generate this automatically from a trigger\n",
    "- discuss various advantages and disadvantages of each approach; one is a step wise pipeline (create as) other is reactive and automatic ( trigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --SPLITHERE--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ceece5",
   "metadata": {},
   "source": [
    "## Building a Complete Full Text Search Engine\n",
    "\n",
    "Having got various pieces in place, we're now in a position to attempt to create a comprehensive full text search engine over 19th century issue of *Notes & Queries*. As we use the database, thee may well be \"optimisations\" we can make, for example in trying to tidy up the content a little. But for now, let's just put the pieces we've already assembled together and see how it looks.\n",
    "\n",
    "Let's create a db from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "4c2cd1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aabcc79156b401e9a13766c1eb6318a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5695 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Table pages_metadata (id, page_idx, page_char_start, page_char_end, page_leaf_num, page_num, page_num_conf, page_text)>"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RECREATE_FULL_DB = False\n",
    "\n",
    "dirname = 'ia-downloads'\n",
    "p = Path(dirname)\n",
    "\n",
    "if RECREATE_FULL_DB:\n",
    "    db_full = Database(\"full_nq.db\", recreate=True)\n",
    "\n",
    "    create_db_table_metadata(db_full)\n",
    "    data_records = open_metadata_records()\n",
    "    add_patched_metadata_records_to_db(db_full, data_records)\n",
    "\n",
    "    create_db_table_issues(db_full)\n",
    "\n",
    "    create_db_table_pages_metadata(db_full)\n",
    "    db_full[\"pages_metadata\"].add_column(\"page_text\", str)\n",
    "    db_full[\"pages_metadata_fts\"].drop(ignore=True)\n",
    "    db_full[\"pages_metadata\"].enable_fts([\"id\", \"page_idx\", \"page_text\"], create_triggers=True, tokenize=\"porter\")\n",
    "else:\n",
    "    db_full = Database(\"full_nq.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "3f2667cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>is_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1849-11-03_1_1</td>\n",
       "      <td>Notes and Queries  1849-11-03: Vol 1 Iss 1</td>\n",
       "      <td>1849-11-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>Notes and Queries  1849-11-10: Vol 1 Iss 2</td>\n",
       "      <td>1849-11-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>Notes and Queries  1849-11-17: Vol 1 Iss 3</td>\n",
       "      <td>1849-11-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>Notes and Queries  1849-11-24: Vol 1 Iss 4</td>\n",
       "      <td>1849-11-24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sim_notes-and-queries_1849-12-01_1_5</td>\n",
       "      <td>Notes and Queries  1849-12-01: Vol 1 Iss 5</td>\n",
       "      <td>1849-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sim_notes-and-queries_1849-12-08_1_6</td>\n",
       "      <td>Notes and Queries  1849-12-08: Vol 1 Iss 6</td>\n",
       "      <td>1849-12-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sim_notes-and-queries_1849-12-15_1_7</td>\n",
       "      <td>Notes and Queries  1849-12-15: Vol 1 Iss 7</td>\n",
       "      <td>1849-12-15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sim_notes-and-queries_1849-12-22_1_8</td>\n",
       "      <td>Notes and Queries  1849-12-22: Vol 1 Iss 8</td>\n",
       "      <td>1849-12-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sim_notes-and-queries_1849-12-29_1_9</td>\n",
       "      <td>Notes and Queries  1849-12-29: Vol 1 Iss 9</td>\n",
       "      <td>1849-12-29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  sim_notes-and-queries_1849-11-03_1_1   \n",
       "1  sim_notes-and-queries_1849-11-10_1_2   \n",
       "2  sim_notes-and-queries_1849-11-17_1_3   \n",
       "3  sim_notes-and-queries_1849-11-24_1_4   \n",
       "4  sim_notes-and-queries_1849-12-01_1_5   \n",
       "5  sim_notes-and-queries_1849-12-08_1_6   \n",
       "6  sim_notes-and-queries_1849-12-15_1_7   \n",
       "7  sim_notes-and-queries_1849-12-22_1_8   \n",
       "8  sim_notes-and-queries_1849-12-29_1_9   \n",
       "\n",
       "                                        title        date  is_index  \n",
       "0  Notes and Queries  1849-11-03: Vol 1 Iss 1  1849-11-03         0  \n",
       "1  Notes and Queries  1849-11-10: Vol 1 Iss 2  1849-11-10         0  \n",
       "2  Notes and Queries  1849-11-17: Vol 1 Iss 3  1849-11-17         0  \n",
       "3  Notes and Queries  1849-11-24: Vol 1 Iss 4  1849-11-24         0  \n",
       "4  Notes and Queries  1849-12-01: Vol 1 Iss 5  1849-12-01         0  \n",
       "5  Notes and Queries  1849-12-08: Vol 1 Iss 6  1849-12-08         0  \n",
       "6  Notes and Queries  1849-12-15: Vol 1 Iss 7  1849-12-15         0  \n",
       "7  Notes and Queries  1849-12-22: Vol 1 Iss 8  1849-12-22         0  \n",
       "8  Notes and Queries  1849-12-29: Vol 1 Iss 9  1849-12-29         0  "
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the records for a particular year\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT id, title, date, is_index\n",
    "FROM metadata\n",
    "WHERE is_index = 0\n",
    "    AND strftime('%Y', datetime) = '{year}';\n",
    "\"\"\"\n",
    "\n",
    "results_19th_cent = read_sql(q.format(year=1849), db_full.conn)\n",
    "results_19th_cent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac965995",
   "metadata": {},
   "source": [
    "We now need to:\n",
    "    \n",
    "- iterate through the records;\n",
    "- download the issue;\n",
    "- carve it into various parts;\n",
    "- add the parts to the database.\n",
    "\n",
    "We have all the pieces we need, so let's do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "048cb462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028f4082119e4022ba53a66bead49fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d3608019684a10b4c76aa3fe61c68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb322186ed0e4f7d8fa8d06dd29d66e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546d1a9d66604fb8b1e72e6c37a728bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd010b66ce44c01b470eaedf15b59d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a8b25622aa471cbb661aec07d9f109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef3c9ac00f74e06b10188c44e2f5d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeea52afeda64c6cb81e41aa605f3518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa7d48805f748219415984ebcc52ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cadd16819d79408eb955a186d93f64ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685db8d36b4840d2988df562ed90504d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8daebf5be94aa48a5e902e5b1a9981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6cc164fa194bd0863803ad6456e394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858330a1758a4176ab3a612a51bbc3ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f5925802004fe8b25e7c383c4bb835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b045df5325854ed4b5d4539879ac1d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab60f1eb25544fe9963ec130eab9cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa248d2fe834b3ebdd0dc9b7adb7cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a2af2a3ea347b9936e57a129cd18ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8d88027f214c7fbcec069c87e1a334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247d6ffd7bc84f7e986684f1a72fea8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8d79482b6f4897a1e7bf2ef78b8e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a483629f6b1434f94a5e5de8116376c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ef4f407b274214a93b64328e638dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7e26bc5dcc4a9088f3b6adf0ee1f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe67c89dbe74e97b1e4844bc1a72e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c290ffee21dd478bacb529fdf2f931df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735e55583dee425e89c18cfd385b9f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899a50253a544ea7bf319becf2e7fde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d84c5eaec5f49b090bb545152b61d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb93be84df1c4694954aca3512838710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a624354086cf42bc93084767b78e4f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c00e2e7cad4d1a93adcc60ea3bb401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba9bb074d6747949c47ce9c8de502e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6551e133154b459383df37306d264390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eaacdcbfa1a45aba69544392c7553a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb5d3e8a17d49be800f715edfa9cc9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0111587a653649948803c520b2f8ba0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9dc382267b4b2089006dcebc730fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67765eb5325f49d68263bca85c73570d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03c39dc0f324979bdd3ed3f8326ca53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7247ad5f5e4dc6b19f5202002385bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c81db83899f4568a1175568c54455ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33e2cf2713d4f9c8a26f86c6cffbb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0875512e9de248f58f23a3ec13c63756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34e2870bde34902a1be55847dadff9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86e8abb51c54395a76e0202d61501a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e77b76f32f74f5cacface5b5db020ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d0db97d1c34875bd8a50537ee992cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9613ab81332d46e8b0105842f6a4fd94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817bbffe0f484581a3537db261c7a72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7251289eecdb4b34a29e8d534f5bedbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if RECREATE_FULL_DB:\n",
    "    for year in tqdm(range(1849, 1900)):\n",
    "        # Get issues by year\n",
    "        results_by_year = read_sql(q.format(year=str(year)), db_full.conn)\n",
    "\n",
    "        # Download issue content by year\n",
    "        results_by_year['content'] = results_by_year[\"id\"].apply(download_and_extract_text, verbose=False)\n",
    "\n",
    "        # Add issues content to database\n",
    "        results_by_year[[\"id\", \"content\"]].to_sql(\"issues\", db_full.conn, index=False, if_exists=\"append\")\n",
    "\n",
    "        # For each issue, we need to grab the metadata and store it in the database\n",
    "        download_ia_records_by_format(results_by_year.to_dict(orient=\"records\"), p)\n",
    "        add_page_metadata_to_db(db_full, results_by_year.to_dict(orient=\"records\"), verbose=False)\n",
    "\n",
    "        for record_id_val in results_by_year['id'].to_list():\n",
    "            updated_pages = chunk_page_text(db_full, record_id_val)\n",
    "            db_full[\"pages_metadata\"].upsert_all(updated_pages, pk=(\"id\", \"page_idx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "1f7f06a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNT(*)\n",
       "0     58406"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM pages_metadata;\n",
    "\"\"\"\n",
    "\n",
    "read_sql(q, db_full.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "a0c82d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNT(*)\n",
       "0      2565"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT COUNT(*) FROM issues;\n",
    "\"\"\"\n",
    "\n",
    "read_sql(q, db_full.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "12c349e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1851-09-20_4_99</td>\n",
       "      <td>...Minor Queries :— Mazer Wood __eaters__ —“ A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1851-09-20_4_99</td>\n",
       "      <td>...Mazer Wood and __Sin__-__eaters__ (Vol. iii...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1851-12-27_4_113</td>\n",
       "      <td>...on mazer-wood and __sin__-__eaters__, 211. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1851-12-27_4_113</td>\n",
       "      <td>...__Sin__-__eaters__, notices respecting, 211...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sim_notes-and-queries_1852-10-23_6_156</td>\n",
       "      <td>...Coffins - -\\nMinor Queries ANSwereD : — __S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sim_notes-and-queries_1852-10-23_6_156</td>\n",
       "      <td>...__Sin__-__eater__.— Can any of your readers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sim_notes-and-queries_1852-12-04_6_162</td>\n",
       "      <td>...furnish its quota The __Sin__-__eater__, by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sim_notes-and-queries_1852-12-04_6_162</td>\n",
       "      <td>...regoi — irst line, THE __SIN__-__EATER__. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sim_notes-and-queries_1852-12-25_6_165</td>\n",
       "      <td>...B. “CE. ) on the __sin__-__eater__, 541.\\nB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sim_notes-and-queries_1852-12-25_6_165</td>\n",
       "      <td>...Leeper ( Alex.) on the __sin__-__eater__, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sim_notes-and-queries_1852-12-25_6_165</td>\n",
       "      <td>...off, 288, — origin of __sin__-__eater__, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sim_notes-and-queries_1856-07-12_2_28</td>\n",
       "      <td>...MARRIOT THE GREAT __EATER__. (2™ §. ii. 6.)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sim_notes-and-queries_1856-12-27_2_52</td>\n",
       "      <td>...the great __eater__, 33. “ Rebukes for __Si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sim_notes-and-queries_1864-10-29_6_148</td>\n",
       "      <td>...John into __Sin__- jon, St. Clair into Sinc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sim_notes-and-queries_1865-05-20_7_177</td>\n",
       "      <td>...this crying __sin__ did drawe downe\\n__eate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sim_notes-and-queries_1867-11-02_12_305</td>\n",
       "      <td>...4s ; __sin__ rle volumes, 288 . 48.3; sing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sim_notes-and-queries_1870-11-12_6_150</td>\n",
       "      <td>...The origin of the __Sin__-__eater__ is need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sim_notes-and-queries_1876-12-23_6_156</td>\n",
       "      <td>...We are well rid of the __sin__-__eater__, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sim_notes-and-queries_1876-12-30_6_157</td>\n",
       "      <td>...364, 423\\nSicilian, 507\\n__Sin__-__eater__,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sim_notes-and-queries_1876-12-30_6_157</td>\n",
       "      <td>...and the Bible, 509 __Sin__-__eater__, 505 W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sim_notes-and-queries_1877-06-30_7_183</td>\n",
       "      <td>...local name, on the __Sin__-__eater__, 14 n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sim_notes-and-queries_1877-06-30_7_183</td>\n",
       "      <td>...66\\nShrove Tuesday, 120\\n__Sin__-__eater__,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sim_notes-and-queries_1879-07-26_12_291</td>\n",
       "      <td>...Writings of the opium-__eater__. In one of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sim_notes-and-queries_1882-01-28_5_109</td>\n",
       "      <td>...and Hastings.\\nEp. MarsHatt.\\n__Sin__ Curis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sim_notes-and-queries_1882-06-24_5_130</td>\n",
       "      <td>...on Franklin, 288\\n \\nMoon, __sin__ to point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sim_notes-and-queries_1883-01-13_7_159</td>\n",
       "      <td>...The superstition of the __Sin__-__Eater__ i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sim_notes-and-queries_1883-06-30_7_183</td>\n",
       "      <td>...for, 410, 448, 474 __Sin__-__eater__, 25, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sim_notes-and-queries_1883-09-29_8_196</td>\n",
       "      <td>...John Aubrey has three passages concerning _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sim_notes-and-queries_1883-12-29_8_209</td>\n",
       "      <td>...Swithin, 46 Scrofula, touching for, 113, 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sim_notes-and-queries_1885-02-21_11_269</td>\n",
       "      <td>...from Tennyson, The Lotos __Eaters__, stanza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sim_notes-and-queries_1889-12-28_8_209</td>\n",
       "      <td>...Good night! There goes another year! (__Eat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sim_notes-and-queries_1892-01-30_1_5</td>\n",
       "      <td>...prevailed, certain persons called “__sin__ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sim_notes-and-queries_1892-10-29_2_44</td>\n",
       "      <td>...it were not lead, that is, __sinful__, yet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>sim_notes-and-queries_1893-11-04_4_97</td>\n",
       "      <td>...LOTOS-__EATER__ in CAPRI. By Dr. ALAN WALTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sim_notes-and-queries_1895-10-12_8_198</td>\n",
       "      <td>...Charterhouse — ‘‘ Oyster of Veal” — __Sin__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>sim_notes-and-queries_1895-10-12_8_198</td>\n",
       "      <td>...Here the __sin__-__eater__ was supposed to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>sim_notes-and-queries_1895-10-26_8_200</td>\n",
       "      <td>...Moore, 331—Lan Stam\\nct — __Sin__-__eaters_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sim_notes-and-queries_1895-11-09_8_202</td>\n",
       "      <td>...Heene, Worthing :—‘ Though the __sin__-__ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>sim_notes-and-queries_1895-12-28_8_209</td>\n",
       "      <td>...and Burns, 205, 515 __Sin__-__eaters__, 288...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>sim_notes-and-queries_1895-12-28_8_209</td>\n",
       "      <td>...Westminster, anchorite at, 408 __Sin__-__ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>sim_notes-and-queries_1896-02-08_9_215</td>\n",
       "      <td>...REPLIES :—__Sin__-__Eater__, 109—Vatican Em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sim_notes-and-queries_1896-02-08_9_215</td>\n",
       "      <td>...Beylics,\\n__SIN__-__EATER__. (8™ §S. viii. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>sim_notes-and-queries_1896-02-08_9_215</td>\n",
       "      <td>...the myth of the __sin__-__eater__. The only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>sim_notes-and-queries_1896-02-29_9_218</td>\n",
       "      <td>...REPLIES :—__Sin__-__eater__, 169—Bream’s Bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>sim_notes-and-queries_1896-02-29_9_218</td>\n",
       "      <td>...Beplies,\\n__SIN__ - __EATER__, (8 §, viii, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>sim_notes-and-queries_1896-03-21_9_221</td>\n",
       "      <td>...Revels for Scotland—Milton—__Sin__-__eater_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>sim_notes-and-queries_1896-03-21_9_221</td>\n",
       "      <td>...w.c.B\\nSrn-__EaTER__ (8 §, viii, 288, 332 ;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>sim_notes-and-queries_1896-04-11_9_224</td>\n",
       "      <td>...s ‘ Richard III.,’ 295—__Sin__-__eater__—Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>sim_notes-and-queries_1896-06-27_9_235</td>\n",
       "      <td>...Mass, its etymology, 334 __Sin__-__eaters__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>sim_notes-and-queries_1896-06-27_9_235</td>\n",
       "      <td>...38\\nRose-galls, 93\\n__Sin__-__eaters__, 110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>sim_notes-and-queries_1896-06-27_9_235</td>\n",
       "      <td>...Gastayne, 232 Senses, the seven, 493 __Sin_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>sim_notes-and-queries_1896-06-27_9_235</td>\n",
       "      <td>...438 Rose-gall, 93 __Sin__-__eaters__, 109, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>sim_notes-and-queries_1896-06-27_9_235</td>\n",
       "      <td>...271 Penn (William), 243 __Sin__-__eaters__,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>sim_notes-and-queries_1896-06-27_9_235</td>\n",
       "      <td>...Trunion, 34 __Sin__-__eaters__, 110 Sterlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>sim_notes-and-queries_1896-06-27_9_235</td>\n",
       "      <td>...P.) on __sin__-__eaters__, 109, 236 Owen (M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>sim_notes-and-queries_1896-06-27_9_235</td>\n",
       "      <td>...M. ) on maypoles, 10 __Sin__-__eaters__, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>sim_notes-and-queries_1896-06-27_9_235</td>\n",
       "      <td>...1, ‘‘ Bare bodkin,” 362, | __Sin__-__eaters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>sim_notes-and-queries_1896-06-27_9_235</td>\n",
       "      <td>...W.) on __sin__-__eaters__, 169 Thomas (R.) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>sim_notes-and-queries_1897-08-28_12_296</td>\n",
       "      <td>...I am sorry that __Sin__ Hersert Maxwett wil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0     sim_notes-and-queries_1851-09-20_4_99   \n",
       "1     sim_notes-and-queries_1851-09-20_4_99   \n",
       "2    sim_notes-and-queries_1851-12-27_4_113   \n",
       "3    sim_notes-and-queries_1851-12-27_4_113   \n",
       "4    sim_notes-and-queries_1852-10-23_6_156   \n",
       "5    sim_notes-and-queries_1852-10-23_6_156   \n",
       "6    sim_notes-and-queries_1852-12-04_6_162   \n",
       "7    sim_notes-and-queries_1852-12-04_6_162   \n",
       "8    sim_notes-and-queries_1852-12-25_6_165   \n",
       "9    sim_notes-and-queries_1852-12-25_6_165   \n",
       "10   sim_notes-and-queries_1852-12-25_6_165   \n",
       "11    sim_notes-and-queries_1856-07-12_2_28   \n",
       "12    sim_notes-and-queries_1856-12-27_2_52   \n",
       "13   sim_notes-and-queries_1864-10-29_6_148   \n",
       "14   sim_notes-and-queries_1865-05-20_7_177   \n",
       "15  sim_notes-and-queries_1867-11-02_12_305   \n",
       "16   sim_notes-and-queries_1870-11-12_6_150   \n",
       "17   sim_notes-and-queries_1876-12-23_6_156   \n",
       "18   sim_notes-and-queries_1876-12-30_6_157   \n",
       "19   sim_notes-and-queries_1876-12-30_6_157   \n",
       "20   sim_notes-and-queries_1877-06-30_7_183   \n",
       "21   sim_notes-and-queries_1877-06-30_7_183   \n",
       "22  sim_notes-and-queries_1879-07-26_12_291   \n",
       "23   sim_notes-and-queries_1882-01-28_5_109   \n",
       "24   sim_notes-and-queries_1882-06-24_5_130   \n",
       "25   sim_notes-and-queries_1883-01-13_7_159   \n",
       "26   sim_notes-and-queries_1883-06-30_7_183   \n",
       "27   sim_notes-and-queries_1883-09-29_8_196   \n",
       "28   sim_notes-and-queries_1883-12-29_8_209   \n",
       "29  sim_notes-and-queries_1885-02-21_11_269   \n",
       "30   sim_notes-and-queries_1889-12-28_8_209   \n",
       "31     sim_notes-and-queries_1892-01-30_1_5   \n",
       "32    sim_notes-and-queries_1892-10-29_2_44   \n",
       "33    sim_notes-and-queries_1893-11-04_4_97   \n",
       "34   sim_notes-and-queries_1895-10-12_8_198   \n",
       "35   sim_notes-and-queries_1895-10-12_8_198   \n",
       "36   sim_notes-and-queries_1895-10-26_8_200   \n",
       "37   sim_notes-and-queries_1895-11-09_8_202   \n",
       "38   sim_notes-and-queries_1895-12-28_8_209   \n",
       "39   sim_notes-and-queries_1895-12-28_8_209   \n",
       "40   sim_notes-and-queries_1896-02-08_9_215   \n",
       "41   sim_notes-and-queries_1896-02-08_9_215   \n",
       "42   sim_notes-and-queries_1896-02-08_9_215   \n",
       "43   sim_notes-and-queries_1896-02-29_9_218   \n",
       "44   sim_notes-and-queries_1896-02-29_9_218   \n",
       "45   sim_notes-and-queries_1896-03-21_9_221   \n",
       "46   sim_notes-and-queries_1896-03-21_9_221   \n",
       "47   sim_notes-and-queries_1896-04-11_9_224   \n",
       "48   sim_notes-and-queries_1896-06-27_9_235   \n",
       "49   sim_notes-and-queries_1896-06-27_9_235   \n",
       "50   sim_notes-and-queries_1896-06-27_9_235   \n",
       "51   sim_notes-and-queries_1896-06-27_9_235   \n",
       "52   sim_notes-and-queries_1896-06-27_9_235   \n",
       "53   sim_notes-and-queries_1896-06-27_9_235   \n",
       "54   sim_notes-and-queries_1896-06-27_9_235   \n",
       "55   sim_notes-and-queries_1896-06-27_9_235   \n",
       "56   sim_notes-and-queries_1896-06-27_9_235   \n",
       "57   sim_notes-and-queries_1896-06-27_9_235   \n",
       "58  sim_notes-and-queries_1897-08-28_12_296   \n",
       "\n",
       "                                                 clip  \n",
       "0   ...Minor Queries :— Mazer Wood __eaters__ —“ A...  \n",
       "1   ...Mazer Wood and __Sin__-__eaters__ (Vol. iii...  \n",
       "2   ...on mazer-wood and __sin__-__eaters__, 211. ...  \n",
       "3   ...__Sin__-__eaters__, notices respecting, 211...  \n",
       "4   ...Coffins - -\\nMinor Queries ANSwereD : — __S...  \n",
       "5   ...__Sin__-__eater__.— Can any of your readers...  \n",
       "6   ...furnish its quota The __Sin__-__eater__, by...  \n",
       "7   ...regoi — irst line, THE __SIN__-__EATER__. I...  \n",
       "8   ...B. “CE. ) on the __sin__-__eater__, 541.\\nB...  \n",
       "9   ...Leeper ( Alex.) on the __sin__-__eater__, 5...  \n",
       "10  ...off, 288, — origin of __sin__-__eater__, 30...  \n",
       "11  ...MARRIOT THE GREAT __EATER__. (2™ §. ii. 6.)...  \n",
       "12  ...the great __eater__, 33. “ Rebukes for __Si...  \n",
       "13  ...John into __Sin__- jon, St. Clair into Sinc...  \n",
       "14  ...this crying __sin__ did drawe downe\\n__eate...  \n",
       "15  ...4s ; __sin__ rle volumes, 288 . 48.3; sing ...  \n",
       "16  ...The origin of the __Sin__-__eater__ is need...  \n",
       "17  ...We are well rid of the __sin__-__eater__, w...  \n",
       "18  ...364, 423\\nSicilian, 507\\n__Sin__-__eater__,...  \n",
       "19  ...and the Bible, 509 __Sin__-__eater__, 505 W...  \n",
       "20  ...local name, on the __Sin__-__eater__, 14 n ...  \n",
       "21  ...66\\nShrove Tuesday, 120\\n__Sin__-__eater__,...  \n",
       "22  ...Writings of the opium-__eater__. In one of ...  \n",
       "23  ...and Hastings.\\nEp. MarsHatt.\\n__Sin__ Curis...  \n",
       "24  ...on Franklin, 288\\n \\nMoon, __sin__ to point...  \n",
       "25  ...The superstition of the __Sin__-__Eater__ i...  \n",
       "26  ...for, 410, 448, 474 __Sin__-__eater__, 25, 3...  \n",
       "27  ...John Aubrey has three passages concerning _...  \n",
       "28  ...Swithin, 46 Scrofula, touching for, 113, 29...  \n",
       "29  ...from Tennyson, The Lotos __Eaters__, stanza...  \n",
       "30  ...Good night! There goes another year! (__Eat...  \n",
       "31  ...prevailed, certain persons called “__sin__ ...  \n",
       "32  ...it were not lead, that is, __sinful__, yet ...  \n",
       "33  ...LOTOS-__EATER__ in CAPRI. By Dr. ALAN WALTE...  \n",
       "34  ...Charterhouse — ‘‘ Oyster of Veal” — __Sin__...  \n",
       "35  ...Here the __sin__-__eater__ was supposed to ...  \n",
       "36  ...Moore, 331—Lan Stam\\nct — __Sin__-__eaters_...  \n",
       "37  ...Heene, Worthing :—‘ Though the __sin__-__ea...  \n",
       "38  ...and Burns, 205, 515 __Sin__-__eaters__, 288...  \n",
       "39  ...Westminster, anchorite at, 408 __Sin__-__ea...  \n",
       "40  ...REPLIES :—__Sin__-__Eater__, 109—Vatican Em...  \n",
       "41  ...Beylics,\\n__SIN__-__EATER__. (8™ §S. viii. ...  \n",
       "42  ...the myth of the __sin__-__eater__. The only...  \n",
       "43  ...REPLIES :—__Sin__-__eater__, 169—Bream’s Bu...  \n",
       "44  ...Beplies,\\n__SIN__ - __EATER__, (8 §, viii, ...  \n",
       "45  ...Revels for Scotland—Milton—__Sin__-__eater_...  \n",
       "46  ...w.c.B\\nSrn-__EaTER__ (8 §, viii, 288, 332 ;...  \n",
       "47  ...s ‘ Richard III.,’ 295—__Sin__-__eater__—Th...  \n",
       "48  ...Mass, its etymology, 334 __Sin__-__eaters__...  \n",
       "49  ...38\\nRose-galls, 93\\n__Sin__-__eaters__, 110...  \n",
       "50  ...Gastayne, 232 Senses, the seven, 493 __Sin_...  \n",
       "51  ...438 Rose-gall, 93 __Sin__-__eaters__, 109, ...  \n",
       "52  ...271 Penn (William), 243 __Sin__-__eaters__,...  \n",
       "53  ...Trunion, 34 __Sin__-__eaters__, 110 Sterlin...  \n",
       "54  ...P.) on __sin__-__eaters__, 109, 236 Owen (M...  \n",
       "55  ...M. ) on maypoles, 10 __Sin__-__eaters__, 11...  \n",
       "56  ...1, ‘‘ Bare bodkin,” 362, | __Sin__-__eaters...  \n",
       "57  ...W.) on __sin__-__eaters__, 169 Thomas (R.) ...  \n",
       "58  ...I am sorry that __Sin__ Hersert Maxwett wil...  "
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_term = \"sin eater\"\n",
    "\n",
    "#q = f\"\"\"\n",
    "#SELECT * FROM pages_metadata_fts\n",
    "#WHERE pages_metadata_fts MATCH {db.quote(search_term)};\n",
    "#\"\"\"\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT id, snippet(pages_metadata_fts, -1, \"__\", \"__\", \"...\", 10) as clip\n",
    "FROM pages_metadata_fts WHERE pages_metadata_fts MATCH {query} ;\n",
    "\"\"\"\n",
    "\n",
    "read_sql(q.format(query=db.quote(search_term)), db_full.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f7205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --SPLITHERE--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca11da0",
   "metadata": {},
   "source": [
    "## Creating a Database Table From Index Volumes\n",
    "\n",
    "Although putting textual content into a database allows us to create full text search tools over that content, a lot of work and effort went into creating the original indexes. So can we scrape the text data from the indexes and generate add the index data to a database `original_index` table to create a comprehensive searchable index?\n",
    "\n",
    "To start with, what columns might such a table need? Let's review an example index issue of *Notes & Queries*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f463f587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"500\"\n",
       "            src=\"ia-downloads/sim_notes-and-queries_1850_2_index/sim_notes-and-queries_1850_2_index.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10e53ee20>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_index_id = indexes[0][\"id\"]\n",
    "\n",
    "IFrame( (p / sample_index_id / f'{sample_index_id}.pdf').as_posix(), width=600, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc95841e",
   "metadata": {},
   "source": [
    "Let's also have a look at some of the raw search text for an index issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "id": "8a1cd232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE\n",
      "A.\n",
      "A.(A.) on solemnization of matrimony,\n",
      "4 bbé Strickland, 237 Abbey of St. W sndrille, bot, Richard, Aberde\n",
      "Aboriginal chambers near Tilbury, Achilles and the tortoise, 154. 185 346. dam of Bremen’s Julin, 282 443 lAdamson's Reign of Edward I1., 297. Admiration ! a note of, 86 dur, origin of, 71. 108. Earicus qui signa fundebat,”’ 297. A. (E. H.) on baptismal superstition, 197. on curfew, at Morpeth, 312. on Duresme and Dunelm, 206. Bneas Silvius, 423. Aérostation, works on, 199. 251. $17. 380. 469. érostation, squib on Lunardi, 469. A Frog he would,”’ &c. 45. 188 . (F. R.) on Dr. Magina, 109. on the Darby Ram,\n",
      "Normandy, 199. of Strata Florida, 493 1, hoods worn by doctors of divinity\n",
      "269. 2\n",
      "122.\n",
      "on Parse\n",
      "on Hoc\n",
      "on the Turkish Spy, 12. After” (the word in the Rubric, 424.\n",
      "498. ‘Agapemone, the, 17. 49. Agincourt, Sir Hilary charged at, 158. 190. Ague, cure for, 130\n",
      "spiders, a cure for, 259.\n",
      "A. (J. D.) on meaning of Wraxen, 366. A. (J. T.) on Captain John Stevens, 359. on Hogarth’s \n"
     ]
    }
   ],
   "source": [
    "simple_index_text = download_and_extract_text(sample_index_id)\n",
    "\n",
    "print(simple_index_text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "id": "8922ccf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE \n",
      "\n",
      "\n",
      "A. \n",
      "\n",
      "\n",
      "A.(A.) on solemnization of matrimony, \n",
      "\n",
      "\n",
      "4 \n",
      "bbé Strickland, 237 \n",
      "Abbey of St. W sndrille, \n",
      "bot, Richard, \n",
      "Aberde \n",
      "\n",
      "\n",
      "Aboriginal chambers near Tilbury, \n",
      "Achilles and the tortoise, 154. 185 346. \n",
      "dam of Bremen’s Julin, 282 443 \n",
      "lAdamson's Reign of Edward I1., 297. \n",
      "Admiration ! a note of, 86 \n",
      "dur, origin of, 71. 108. \n",
      "Earicus qui signa fundebat,”’ 297. \n",
      "A. (E. H.) on baptismal superstition, 197. \n",
      "on curfew, at Morpeth, 312. \n",
      "on Duresme and Dunelm, 206. \n",
      "Bneas Silvius, 423. \n",
      "Aérostation, works on, 199. 251. \n",
      "$17. 380. 469. \n",
      "érostation, squib on Lunardi, 469. \n",
      "A Frog he would,”’ &c. 45. 188 \n",
      ". (F. R.) on Dr. Magina, 109. \n",
      "on the Darby Ram, \n",
      "\n",
      "\n",
      "Normandy, 199. \n",
      "of Strata Florida, 493 \n",
      "1, hoods worn by doctors of divinity \n",
      "\n",
      "\n",
      "269. 2 \n",
      "\n",
      "\n",
      "122. \n",
      "\n",
      "on Parse \n",
      "\n",
      "on Hoc \n",
      "\n",
      "on the Turkish Spy, 12. \n",
      "After” (the word in the Rubric, 424. \n",
      "\n",
      "498. \n",
      "‘Agapemone, the, 17. 49. \n",
      "Agincourt, Sir Hilary charged at, 158. 190. \n",
      "Ague, cure for, 130 \n",
      "\n",
      "spiders, a cure for, 259. \n",
      "\n",
      "A. (J. D.) on meaning of Wraxen, \n"
     ]
    }
   ],
   "source": [
    "sample_index_text = download_and_extract_text(sample_index_id, typ=\"djvutxt\")\n",
    "\n",
    "print(sample_index_text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "id": "06be6a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sim_notes-and-queries_1850_2_index'"
      ]
     },
     "execution_count": 1002,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_index_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb605e7",
   "metadata": {},
   "source": [
    "Inspecting some of the documents shows that there is no guarantee that the search text correctly represents index items on a new line, although in certain documents it appears as if line breaks after each entry are provided (as in the original scanned image).\n",
    "\n",
    "There are also \"sub-elements\" on separate lines that relate to a major heading that we really need to \"fill down\" on, although there is may be no indication in the text (e.g. no series of dashes or a tab characters) to indicate the the subsidiary nature of a reference. (Note that there may be further clues in the original XML, for example, from the location of the text.) However, subsidiary entries do often appear to start with a lower case letter, so let's use that as a heuristic: *if the line starts with a lower case letter, it's a subsidiary entry*. More detailed inspection of the index search text also suggests that in some cases `-` separator characters may appear in the search text.\n",
    "\n",
    "To create a complete index, one possible approach is to:\n",
    "\n",
    "- normalise a single entry and all its subsidiary entries onto a single line;\n",
    "- parse a single entry and all its subsidiary entries into appropriate database records.\n",
    "\n",
    "Rather than consider the XML and all the additional processing that incurs, let's try to \"repair\" the document as best we can. Another thing we *could* try to exploit is the alphabetical order of entries, but let's leave that as an open question and only return to it if we find issues occurring that alphabetisation might help us address.\n",
    "\n",
    "So let's start by repairing the text and normalising the lines before considering how to parse the entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f00b5b",
   "metadata": {},
   "source": [
    "### Reinserting Line Breaks\n",
    "\n",
    "If we can identify where line breaks are likely to be missing, we should be able to reinsert them.\n",
    "\n",
    "By inspection of the raw search text, it seems that we have a page number (digits), space character, and then typically the next entry start by a capital letter (subsidiary lines seem to start with a lower case character). We can perform a regular expression substitution to match this pattern and replace the space after the final page number with an end-of-line character.\n",
    "\n",
    "Some lines also start with opening quotes of various flavours (`‘` or `“` for example), or incorrectly recognised quotes rendered as a `*` character. We can also insert line breaks in advance of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "id": "b7e62572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def repair_index_missing_line_breaks(text):\n",
    "    \"\"\"Attempt to repair missing line breaks.\"\"\"\n",
    "    # Add line break after page number\n",
    "    # allowing a single optional grace character at end for incorrect OCR\n",
    "    repaired_text  = re.sub(r\"([0-9].?\\s*\\.?)[\\s]+([\\(‘“\\\"'\\*A-Z])\", r'\\1\\n\\2', text)\n",
    "    \n",
    "    return repaired_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181bec9d",
   "metadata": {},
   "source": [
    "Let's see how that looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "id": "dca94c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE\n",
      "A.\n",
      "A.(A.) on solemnization of matrimony,\n",
      "4 bbé Strickland, 237\n",
      "Abbey of St. W sndrille, bot, Richard, Aberde\n",
      "Aboriginal chambers near Tilbury, Achilles and the tortoise, 154. 185 346. dam of Bremen’s Julin, 282 443 lAdamson's Reign of Edward I1., 297.\n",
      "Admiration ! a note of, 86 dur, origin of, 71. 108.\n",
      "Earicus qui signa fundebat,”’ 297.\n",
      "A. (E. H.) on baptismal superstition, 197. on curfew, at Morpeth, 312. on Duresme and Dunelm, 206.\n",
      "Bneas Silvius, 423.\n",
      "Aérostation, works on, 199. 251. $17. 380. 469. érostation, squib on Lunardi, 469.\n",
      "A Frog he would,”’ &c. 45. 188 .\n",
      "(F. R.) on Dr. Magina, 109. on the Darby Ram,\n",
      "Normandy, 199. of Strata Florida, 493 1, hoods worn by doctors of divinity\n",
      "269. 2\n",
      "122.\n",
      "on Parse\n",
      "on Hoc\n",
      "on the Turkish Spy, 12.\n",
      "After” (the word in the Rubric, 424.\n",
      "498.\n",
      "‘Agapemone, the, 17. 49.\n",
      "Agincourt, Sir Hilary charged at, 158. 190.\n",
      "Ague, cure for, 130\n",
      "spiders, a cure for, 259.\n",
      "A. (J. D.) on meaning of Wraxen, 366.\n",
      "A. (J. T.) on Captain John Stevens, 359. on Hogarth’s \n"
     ]
    }
   ],
   "source": [
    "repaired_sample_index = repair_index_missing_line_breaks( sample_index_text[:1000] )\n",
    "\n",
    "print(repaired_sample_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905e3fe6",
   "metadata": {},
   "source": [
    "### Removing Unwanted Line Breaks\n",
    "\n",
    "If what appear to be page numbers appear on the their own line, they should presumably appear as page numbers for the previous reference.\n",
    "\n",
    "In other cases, a subsidiary reference might incorrectly be place on one line, or a line might end on a comma. In such cases, we might assume the associated line breaks to be unwanted.\n",
    "\n",
    "So let's replace the line breaks in those locations with spaces, and then also replace any double spaces we might have introduced (or that were present withing the original scanned text) with a single space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "id": "af87571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_index_unwanted_line_breaks(text):\n",
    "    \"\"\"Attempt to repair extraneous line breaks.\"\"\"\n",
    "    # Fix unwanted line end before page number\n",
    "    repaired_text  = re.sub(r\"\\n([0-9].*)\", r' \\1', text)\n",
    "    # Fix unwanted line end before subsidiary entry (initial lower case character)\n",
    "    # Identify subsidiary split with a ::: separator\n",
    "    repaired_text  = re.sub(r\"\\n([a-z].*)\", r' ::: \\1', repaired_text)\n",
    "    # Fix unwanted line break after comma\n",
    "    #repaired_text  = re.sub(r\",\\s*\\n\", r', ZZ', repaired_text)\n",
    "    \n",
    "    # Remove duplicate spaces\n",
    "    repaired_text  = re.sub(r\"  \", r' ', repaired_text)\n",
    "    \n",
    "    return repaired_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49de6d1",
   "metadata": {},
   "source": [
    "How do things look now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "id": "add1b4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE\n",
      "A.\n",
      "A.(A.) on solemnization of matrimony, 4 bbé Strickland, 237\n",
      "Abbey of St. W sndrille, bot, Richard, Aberde\n",
      "Aboriginal chambers near Tilbury, Achilles and the tortoise, 154. 185 346. dam of Bremen’s Julin, 282 443 lAdamson's Reign of Edward I1., 297.\n",
      "Admiration ! a note of, 86 dur, origin of, 71. 108.\n",
      "Earicus qui signa fundebat,”’ 297.\n",
      "A. (E. H.) on baptismal superstition, 197. on curfew, at Morpeth, 312. on Duresme and Dunelm, 206.\n",
      "Bneas Silvius, 423.\n",
      "Aérostation, works on, 199. 251. $17. 380. 469. érostation, squib on Lunardi, 469.\n",
      "A Frog he would,”’ &c. 45. 188 .\n",
      "(F. R.) on Dr. Magina, 109. on the Darby Ram,\n",
      "Normandy, 199. of Strata Florida, 493 1, hoods worn by doctors of divinity 269. 2 122. ::: on Parse ::: on Hoc ::: on the Turkish Spy, 12.\n",
      "After” (the word in the Rubric, 424. 498.\n",
      "‘Agapemone, the, 17. 49.\n",
      "Agincourt, Sir Hilary charged at, 158. 190.\n",
      "Ague, cure for, 130 ::: spiders, a cure for, 259.\n",
      "A. (J. D.) on meaning of Wraxen, 366.\n",
      "A. (J. T.) on Captain John Stevens, 359. on Hogarth’s \n"
     ]
    }
   ],
   "source": [
    "repaired_sample_index = repair_index_missing_line_breaks( sample_index_text[:1000] )\n",
    "repaired_sample_index = repair_index_unwanted_line_breaks( repaired_sample_index )\n",
    "\n",
    "print(repaired_sample_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f34679",
   "metadata": {},
   "source": [
    "Inspecting the above, we see there are \"issues\" that we might be able to address, such as line entries that should be separated, based on a closer inspection of the XML returned from the scan that includes the position on the page.\n",
    "\n",
    "But at least we have something to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad894987",
   "metadata": {},
   "source": [
    "### Parsing Entries and Adding Them to a Database\n",
    "\n",
    "Let's now consider how we might structure our database entries.\n",
    "\n",
    "First, we have simple \"primary\" entries, such as *Agincourt, Sir Hilary charged at, 158. 190.*\n",
    "\n",
    "We might put this into a record of the form:\n",
    "\n",
    "```json\n",
    "[{\"source_id\": id_val, \"index_term\": \"Agincourt, Sir Hilary charged at\", \"page\": 158}\n",
    "{\"source_id\": id_val, \"index_term\": \"Agincourt, Sir Hilary charged at\", \"page\": 190}]\n",
    "```\n",
    "\n",
    "The page numbers are relative to a particular volume, so we also need to be able to capture information to identify what the page numbers are with reference to. The index document filenames take the form *Notes and Queries 1875: Vol 3 Index* so we can parse out the year and volume and add these to the record too.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "id": "e68e23cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse import parse\n",
    "\n",
    "def get_index_metadata_from_title(title):\n",
    "    \"\"\"Get year and volume from title.\"\"\"\n",
    "    metadata = parse(\"Notes and Queries {year}: Vol {vol} Index\", title)\n",
    "    if metadata:\n",
    "        metadata = {\"year\": metadata[\"year\"], \"vol\": metadata[\"vol\"]}\n",
    "    else:\n",
    "        metadata = {\"year\": None, \"vol\": None}\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a2562e",
   "metadata": {},
   "source": [
    "Here's how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "id": "39613aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': '1875', 'vol': '3'}"
      ]
     },
     "execution_count": 1125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_index_page_title = \"Notes and Queries 1875: Vol 3 Index\"\n",
    "\n",
    "get_index_metadata_from_title(sample_index_page_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffcd831",
   "metadata": {},
   "source": [
    "In the table, we might also provide a `type` column to distinguish between primary (`P`) and subsidiary (`S`) entries, along with subsidiary column which should be empty in simple cases.\n",
    "\n",
    "For a line entry such as *A. (E. H.) on baptismal superstition, 197. on curfew, at Morpeth, 312. on Duresme and Dunelm, 206.* we not the the first entry is actually a subsidiary entry, the `on` keyword identifying the subsidiarity to the main term `A. (E. H.)`.\n",
    "\n",
    "We might then desire to have partial records of the form:\n",
    "\n",
    "```json\n",
    "[{\"index_term\": \"A. (E. H.)\", \"typ\": \"S\", \"page\": 197, \"subsidiary\": \"on baptismal superstition\"},\n",
    "{\"index_term\": \"A. (E. H.)\", \"typ\": \"S\", \"page\": 312, \"subsidiary\": \"on curfew, at Morpeth\"},\n",
    "{\"index_term\": \"A. (E. H.)\", \"typ\": \"S\", \"page\": 206, \"subsidiary\": \"on Duresme and Dunelm,\"}\n",
    "]\n",
    "```\n",
    "\n",
    "Inspection of other records with subsidiary terms suggests that a comma may also be used as to denote initial subsidiarity, as or example illustrated here:\n",
    "\n",
    "`Berkeley (Bishop), adventures of Gau- dentio di Lucca, 247.successful experiments, 217.`\n",
    "\n",
    "In this case, the multiple items are based on the original term before the initial comma (this might be a hasty assumption if the key term itself includes a comma, but the we might hope for an \"on\" separator to clarify the position.\n",
    "\n",
    "*We also note in that example a possible repair we could make to the original text: removing the `word- split` hyphenation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "id": "2e97fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_remove_word_split_hyphenation(text):\n",
    "    \"\"\"Remove word split hyphenation.\"\"\"\n",
    "    cleaned_text = re.sub(r\"([a-z])[-—–][\\n]([a-z])\", r'\\1\\2', text)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bb0ed0",
   "metadata": {},
   "source": [
    "Let's do a quick test of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "id": "3e1099e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Berkeley (Bishop), adventures of Gaudentio di Lucca, 247.successful experiments, 217.'"
      ]
     },
     "execution_count": 1010,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eol_hyphenation = \"Berkeley (Bishop), adventures of Gau-\\ndentio di Lucca, 247.successful experiments, 217.\"\n",
    "\n",
    "clean_text_remove_word_split_hyphenation(test_eol_hyphenation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7b56b8",
   "metadata": {},
   "source": [
    "So let's start by suggesting the following database record structure as something to work towards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "id": "fa064a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table index_entries (source_id, year, vol, index_term, typ, subsidiary, page_num)>"
      ]
     },
     "execution_count": 1126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to remove the table completely, we can drop  it\n",
    "db[\"index_entries\"].drop(ignore=True)\n",
    "db[\"index_entries_fts\"].drop(ignore=True)\n",
    "\n",
    "db[\"index_entries\"].create({\n",
    "    \"source_id\": str, \n",
    "    \"year\": str,\n",
    "    \"vol\": str,\n",
    "    \"index_term\": str, \n",
    "    \"typ\": str,\n",
    "    \"subsidiary\": str,\n",
    "    \"page_num\": int\n",
    "})\n",
    "\n",
    "\n",
    "# Enable full text search\n",
    "# This creates an extra virtual table (books_fts) to support the full text search\n",
    "db[\"index_entries\"].enable_fts([\"source_id\", \"index_term\", \"subsidiary\", \"year\", \"vol\", \"page_num\"],\n",
    "                             create_triggers=True, tokenize=\"porter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87669346",
   "metadata": {},
   "source": [
    "We now need to consider various ways of parsing line items, including:\n",
    "    \n",
    "- extracting multiple page numbers for a single entry;\n",
    "- identifying entries that mask subsidiary terms.\n",
    "\n",
    "We have already adopted a convention of using `:::` to separate subsidiary items, so let's apply that a bit further to separate out \"on\" terms and comma separated terms. We might also have a catch all in case there are elements appearing after a page number that are perhaps rightly new entries but that we shall treat as subsidiaries.\n",
    "\n",
    "We could possibly also try to \"fudge\" page numbers that look like numbers-ish, for eexample, if there is a set of numbers that ends with an `s` or a `z`. where we might guess (possibly incorrectly) at a `5` or `2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "id": "e508b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _repair_index_subsidiary_separator_line(text):\n",
    "    \"\"\"Repair entries at line level.\"\"\"\n",
    "    \n",
    "    # Very risky number substitutions\n",
    "    # We want to access \\1 so we need the alternative syntax\n",
    "    repaired_text  = re.sub(r\"([0-9])[sS]\\.?\", r'\\g<1>5', text)\n",
    "    repaired_text  = re.sub(r\"([0-9])[zZ]\\.?\", r'\\g<1>2', repaired_text)\n",
    "    \n",
    "    # Subsidiary terms based on \"on\" - this may be overly aggressive to be starting with\n",
    "    repaired_text  = re.sub(r\"([^(on)]*)( on .*)\", r'\\1 ::: \\2', repaired_text)\n",
    "    # Subsidiary terms based on dashes at start of line\n",
    "    repaired_text  = re.sub(r'^[-—–]+', r' ::: ', repaired_text)\n",
    "    # Subsidiary terms based on multiple dashes within line (unlikely to be hyphen)\n",
    "    repaired_text  = re.sub(r'[-—–]{2,}', r' ::: ', repaired_text)\n",
    "    # Subsidiary terms based on dash after a number\n",
    "    repaired_text  = re.sub(r'([0-9\\.,]+\\s*)[-—–]+', r'\\1 :::', repaired_text)\n",
    "    \n",
    "    # Subsidiary terms based on page numbers\n",
    "    repaired_text  = re.sub(r\"([0-9]\\.) *([‘“\\\"'\\*A-Za-z])\", r'\\1 ::: \\2', repaired_text)\n",
    "    # Subsidiary terms based on \"on\" - this may be overly aggressive\n",
    "    #repaired_text  = re.sub(r\"^([^:]*)( on .*)\", r'\\1 ::: \\2', repaired_text)\n",
    "    # Or only apply after a number\n",
    "    #repaired_text  = re.sub(r\"([0-9]\\.)\\s*(on)\", r'\\1 ::: \\2', repaired_text)\n",
    "    if \"::: on\" in repaired_text:\n",
    "        # Also split at start\n",
    "        repaired_text = re.sub(r\"^([^(on)]*) (on)\", r\"\\1 ::: \\2\", repaired_text)\n",
    "    # Subsidiary terms based on \",\"\n",
    "    #elif \":::\" in repaired_text:\n",
    "    # If we have numbers separated by commas, replace the commas with a .\n",
    "    repaired_text = re.sub(r'(\\s+[0-9]+)\\s*,\\s*([0-9]+)',r'\\1. \\2', repaired_text)\n",
    "    # If we have a comma before a number, separate after the number\n",
    "    # Allow a grace character\n",
    "    re.sub(r\"^([^:,]*),\\s*([0-9][0-9\\.\\s]+[A-Za-z]?)[^\\n]\", r'\\1 \\2:::', repaired_text)\n",
    "    # If we have a comma appear before a separator, separate on it\n",
    "    repaired_text  = re.sub(r\"^([^:,]*),\\s*([^0-9]+)\", r'\\1 :::\\2', repaired_text)\n",
    "\n",
    "    # Provide a catch all to add separators after what look like page numbers\n",
    "    repaired_text  = re.sub(r\"([0-9]\\s*[^:].?)\\s*([A-Za-z].*)$\", r'\\1 ::: \\2', repaired_text)\n",
    "    \n",
    "    # Remove uncaught dashes at start and end of phrase\n",
    "    repaired_text = \":::\".join([p.strip(\"-—– \") for p in repaired_text.split(\":::\")])\n",
    "    \n",
    "    return repaired_text\n",
    "\n",
    "\n",
    "def repair_index_subsidiary_separator(text):\n",
    "    \"\"\"Attempt to identify where subsidiary splits occur.\"\"\"\n",
    "    # These are applied at the line level\n",
    "    repaired_lines = [_repair_index_subsidiary_separator_line(line.strip()) for line in text.split(\"\\n\") if line]\n",
    "    \n",
    "    # Patch back any overly aggressively split lines\n",
    "    return \"\\n\".join(repaired_lines).replace(\"\\n:::\", \":::\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694401f",
   "metadata": {},
   "source": [
    "Let's see how that works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "id": "8aae8b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE\n",
      "A.\n",
      "A.(A.):::on solemnization of matrimony, 4 b:::bé Strickland, 237\n",
      "Abbey of St. W sndrille:::bot, Richard, Aberde\n",
      "Aboriginal chambers near Tilbury:::Achilles and the tortoise, 154. 185 346.:::dam of Bremen’s Julin, 282 443:::lAdamson's Reign of Edward I1., 297.\n",
      "Admiration ! a note of:::86:::dur, origin of, 71. 108.\n",
      "Earicus qui signa fundebat:::”’ 297.\n",
      "A. (E. H.):::on baptismal superstition, 197.:::on curfew, at Morpeth, 312.:::on Duresme and Dunelm, 206.\n",
      "Bneas Silvius:::423.\n",
      "Aérostation:::works on, 199. 251. $17. 380. 469. érostation, squib:::on Lunardi, 469.\n",
      "A Frog he would:::”’ &c. 45. 188 .\n",
      "(F. R.):::on Dr. Magina, 109.:::on the Darby Ram,\n",
      "Normandy:::199.:::of Strata Florida, 493 1,:::hoods worn by doctors of divinity 269. 2 122.::::::on Parse:::on Hoc:::on the Turkish Spy, 12.\n",
      "After” (the word in the Rubric:::424. 498.\n",
      "‘Agapemone:::the, 17. 49.\n",
      "Agincourt:::Sir Hilary charged at, 158. 190.\n",
      "Ague:::cure for, 130:::spiders, a cure for, 259.\n",
      "A. (J. D.):::on meaning of Wraxen, 366.\n",
      "A. (J. T.):::on Captain John Stevens, 359.:::on Hogarth’s\n"
     ]
    }
   ],
   "source": [
    "repaired_sample_index2 = repaired_sample_index\n",
    "repaired_sample_index2 = repair_index_subsidiary_separator(repaired_sample_index2)\n",
    "\n",
    "print(repaired_sample_index2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaddd3c",
   "metadata": {},
   "source": [
    "And for the comma separator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "id": "b0db99f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Berkeley (Bishop):::adventures of Gau- dentio di Lucca, 247.:::successful experiments, 217.'"
      ]
     },
     "execution_count": 1129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_comma_subsidiary = \"Berkeley (Bishop), adventures of Gau- dentio di Lucca, 247.successful experiments, 217.\"\n",
    "\n",
    "repair_index_subsidiary_separator(text_comma_subsidiary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1396eeae",
   "metadata": {},
   "source": [
    "Having made an attempt at some subsidiary separators, we can now try to parse out the various components. At the start of the line we have the primary entry, then we may have one or more line numbers or one or more subsidiary phrases.\n",
    "\n",
    "Let's look at how to parse out page numbers. There may be one or more page numbers separated by spaces or by `.` characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "id": "ca70f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a rather crude approach that just grabs all the numbers we can find\n",
    "def extract_page_numbers_from_line(text):\n",
    "    \"\"\"Extract one or more page numbers from text.\"\"\"\n",
    "    # Try to nudge things towards finding numbers at the end of the phrase\n",
    "    end_of_text = re.sub(r'^[^0-9]*([0-9\\.,\\s]*$)', r'\\1', text)\n",
    "    start_of_text = text.replace(end_of_text, '')\n",
    "    # Then just bludgeon out all the possible page numbers\n",
    "    page_numbers = re.findall(r'\\d+', end_of_text)\n",
    "    return start_of_text, page_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2851234",
   "metadata": {},
   "source": [
    "Let's see how that works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "id": "ad479d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('adventures of Gau- dentio di Lucca, ', ['247']),\n",
       " ('successful experiments, ', ['217'])]"
      ]
     },
     "execution_count": 1131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a test example of subsidiary elements; there is no page number in the first part\n",
    "[extract_page_numbers_from_line(t) for t in repair_index_subsidiary_separator(text_comma_subsidiary).split(\":::\")[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9037e7",
   "metadata": {},
   "source": [
    "And if there are no numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "id": "05914123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('No numbers here', [])"
      ]
     },
     "execution_count": 1132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_page_numbers_from_line(\"No numbers here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "id": "a73bb67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_index_line(text):\n",
    "    \"\"\"Parse out elements of the index entry.\"\"\"\n",
    "    \n",
    "    # Split the entry in subsidiary parts and clean white space\n",
    "    parts = [p.strip() for p in text.split(\":::\")]\n",
    "\n",
    "    # Do we have one entry or many?\n",
    "    if len(parts) == 1:\n",
    "        # There are no subsidiary parts\n",
    "        # The first part is the main index entry\n",
    "        # from which we need to separate one or more page references\n",
    "        entry_text, page_numbers = extract_page_numbers_from_line(parts[0])\n",
    "        index_entries = [{\"index_term\": entry_text, \"typ\": \"P\",\n",
    "                         \"page_numbers\": page_numbers}]\n",
    "    else:\n",
    "        # There are subsidiary parts\n",
    "        # In this case, we get each subsidiary part and its page references\n",
    "        # Get the subsidiary parts\n",
    "        index_entries = []\n",
    "        for p in parts[1:]:\n",
    "            entry_text, page_numbers = extract_page_numbers(p)\n",
    "            subsidiary_entry = {\"index_term\": parts[0],\n",
    "                                \"subsidiary\": entry_text, \"typ\": \"S\",\n",
    "                                \"page_numbers\": page_numbers}\n",
    "            index_entries.append(subsidiary_entry)\n",
    "\n",
    "    return index_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "id": "8dd96268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index_term': '“ Noise\" derivations of ',\n",
       "  'typ': 'P',\n",
       "  'page_numbers': ['81', '106', '138', '218', '35']}]"
      ]
     },
     "execution_count": 1134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_index_line('“ Noise\" derivations of 81. 106. 138. 218. 35')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c4b260",
   "metadata": {},
   "source": [
    "So does that work?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "id": "ac2eca1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index_term': 'Aboriginal chambers near Tilbury',\n",
       "  'subsidiary': 'Achilles and the tortoise, ',\n",
       "  'typ': 'S',\n",
       "  'page_numbers': ['154', '185', '346']},\n",
       " {'index_term': 'Aboriginal chambers near Tilbury',\n",
       "  'subsidiary': 'dam of Bremen’s Julin, ',\n",
       "  'typ': 'S',\n",
       "  'page_numbers': ['282', '443']},\n",
       " {'index_term': 'Aboriginal chambers near Tilbury',\n",
       "  'subsidiary': \"lAdamson's Reign of Edward I\",\n",
       "  'typ': 'S',\n",
       "  'page_numbers': ['1', '297']}]"
      ]
     },
     "execution_count": 1135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_index_line(repaired_sample_index2.split(\"\\n\")[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb8ed49",
   "metadata": {},
   "source": [
    "In the above case, we have an error in that we have rolled one index entry as a subsidiary to an initial index entry because of a missing page number for the first entry.\n",
    "\n",
    "*In this case, alphabetic sorting checks across several index entries (and subsidiaries) might help us detect this error; for example, if a subsidiary term sorts between the index term and the next index term, we might guess that the subsidiary is actually a main index term.*\n",
    "\n",
    "Note that if we construct a full text search across the `index_term` and `subsidiary` columns, we are likely to get false positives but we shouldn't miss anything..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c18d13f",
   "metadata": {},
   "source": [
    "We can now try to create a complete set of records that we could upload to out database.\n",
    "\n",
    "To start with, we need the metadata, which means we need the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "id": "a38c9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_from_id(db, id_val):\n",
    "    \"\"\"get the title of the issue from the database.\"\"\"\n",
    "    q = f'SELECT title FROM metadata WHERE id=\"{id_val}\"'\n",
    "\n",
    "    return read_sql(q, db.conn)[\"title\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c48d6",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "id": "04dc3b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': ' 1850', 'vol': '2'}"
      ]
     },
     "execution_count": 1137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_base_data = get_index_metadata_from_title(get_title_from_id(db, sample_index_id))\n",
    "index_base_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a35718",
   "metadata": {},
   "source": [
    "Now we need to separate each line item into multiple items. The `pandas` dataframe can come to out aid here, with its ability to easily split out listed items in one cell onto multiple rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "id": "528b392f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_term</th>\n",
       "      <th>subsidiary</th>\n",
       "      <th>typ</th>\n",
       "      <th>page_numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aboriginal chambers near Tilbury</td>\n",
       "      <td>Achilles and the tortoise,</td>\n",
       "      <td>S</td>\n",
       "      <td>[154, 185, 346]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aboriginal chambers near Tilbury</td>\n",
       "      <td>dam of Bremen’s Julin,</td>\n",
       "      <td>S</td>\n",
       "      <td>[282, 443]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aboriginal chambers near Tilbury</td>\n",
       "      <td>lAdamson's Reign of Edward I</td>\n",
       "      <td>S</td>\n",
       "      <td>[1, 297]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         index_term                    subsidiary typ  \\\n",
       "0  Aboriginal chambers near Tilbury   Achilles and the tortoise,    S   \n",
       "1  Aboriginal chambers near Tilbury       dam of Bremen’s Julin,    S   \n",
       "2  Aboriginal chambers near Tilbury  lAdamson's Reign of Edward I   S   \n",
       "\n",
       "      page_numbers  \n",
       "0  [154, 185, 346]  \n",
       "1       [282, 443]  \n",
       "2         [1, 297]  "
      ]
     },
     "execution_count": 1138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "example_subsidiary_df = pd.DataFrame(parse_index_line(repaired_sample_index2.split(\"\\n\")[4]))\n",
    "example_subsidiary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300a9ac3",
   "metadata": {},
   "source": [
    "We can now \"explode\" that dataframe against the lists of page numbers to get one row per item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "id": "2cdea110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_term</th>\n",
       "      <th>subsidiary</th>\n",
       "      <th>typ</th>\n",
       "      <th>page_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aboriginal chambers near Tilbury</td>\n",
       "      <td>Achilles and the tortoise,</td>\n",
       "      <td>S</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aboriginal chambers near Tilbury</td>\n",
       "      <td>Achilles and the tortoise,</td>\n",
       "      <td>S</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aboriginal chambers near Tilbury</td>\n",
       "      <td>Achilles and the tortoise,</td>\n",
       "      <td>S</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aboriginal chambers near Tilbury</td>\n",
       "      <td>dam of Bremen’s Julin,</td>\n",
       "      <td>S</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aboriginal chambers near Tilbury</td>\n",
       "      <td>dam of Bremen’s Julin,</td>\n",
       "      <td>S</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aboriginal chambers near Tilbury</td>\n",
       "      <td>lAdamson's Reign of Edward I</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aboriginal chambers near Tilbury</td>\n",
       "      <td>lAdamson's Reign of Edward I</td>\n",
       "      <td>S</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         index_term                    subsidiary typ page_num\n",
       "0  Aboriginal chambers near Tilbury   Achilles and the tortoise,    S      154\n",
       "0  Aboriginal chambers near Tilbury   Achilles and the tortoise,    S      185\n",
       "0  Aboriginal chambers near Tilbury   Achilles and the tortoise,    S      346\n",
       "1  Aboriginal chambers near Tilbury       dam of Bremen’s Julin,    S      282\n",
       "1  Aboriginal chambers near Tilbury       dam of Bremen’s Julin,    S      443\n",
       "2  Aboriginal chambers near Tilbury  lAdamson's Reign of Edward I   S        1\n",
       "2  Aboriginal chambers near Tilbury  lAdamson's Reign of Edward I   S      297"
      ]
     },
     "execution_count": 1139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_subsidiary_df.explode('page_numbers').rename(columns={\"page_numbers\": \"page_num\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc59925",
   "metadata": {},
   "source": [
    "Let's see if we can now put all those pieces together. Essentially, for each index line, we need to generate the complete set of records we want to add to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "id": "ff1ab252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_index_records(id_val=None, text=None, metadata=None, retval=\"explode\"):\n",
    "    \"\"\"Generate a complete set of index records from original search text document.\"\"\"\n",
    "    if id_val is None and text is None:\n",
    "        return []\n",
    "\n",
    "    text = download_and_extract_text(id_val, typ=\"djvutxt\") if text is None else text\n",
    "\n",
    "    records = []\n",
    "    # Repair the text\n",
    "    repaired_text = repair_index_missing_line_breaks( text )\n",
    "    repaired_text = repair_index_unwanted_line_breaks( repaired_text )\n",
    "    repaired_text = repair_index_subsidiary_separator( repaired_text )\n",
    "\n",
    "    for line in repaired_text.split(\"\\n\"):\n",
    "        if line:\n",
    "            new_line = parse_index_line(line)\n",
    "            records.extend(new_line)\n",
    "    \n",
    "    if retval not in [\"df\", \"explode\"] or id_val is None:\n",
    "        # Return the list of dicts, without the metadata\n",
    "        return records\n",
    "\n",
    "    # WARNING - if we used provided text, the id_val and the text may actually be inconsistent\n",
    "    index_base_data = get_index_metadata_from_title(get_title_from_id(db, id_val))\n",
    "    # Generate a dataframe\n",
    "    records_df = pd.DataFrame(records)\n",
    "    \n",
    "    records_df[\"source_id\"] = id_val\n",
    "    records_df[\"year\"] = index_base_data[\"year\"]\n",
    "    records_df[\"vol\"] = index_base_data[\"vol\"]\n",
    "    \n",
    "    if retval==\"explode\":\n",
    "        return records_df.explode('page_numbers').rename(columns={\"page_numbers\": \"page_num\"})\n",
    "    elif retval==\"df\":\n",
    "        return records_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d16a9a4",
   "metadata": {},
   "source": [
    "And when we run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "id": "79607bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_term</th>\n",
       "      <th>typ</th>\n",
       "      <th>page_num</th>\n",
       "      <th>subsidiary</th>\n",
       "      <th>source_id</th>\n",
       "      <th>year</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>Chaucer’s Damascene,</td>\n",
       "      <td>S</td>\n",
       "      <td>442</td>\n",
       "      <td>portrait by Occleve,</td>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>Chaucer’s Damascene,</td>\n",
       "      <td>S</td>\n",
       "      <td>455</td>\n",
       "      <td>portrait by Occleve,</td>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>C. (H. B.)</td>\n",
       "      <td>S</td>\n",
       "      <td>77</td>\n",
       "      <td>on Duteh language,</td>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>C. (H. B.)</td>\n",
       "      <td>S</td>\n",
       "      <td>45</td>\n",
       "      <td>Tace Latin for a candle,</td>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>C. (H. B.)</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sanatory” and ‘* con</td>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>Jury</td>\n",
       "      <td>S</td>\n",
       "      <td>350</td>\n",
       "      <td>on Scotch</td>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>Jury</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>Jury</td>\n",
       "      <td>S</td>\n",
       "      <td>498</td>\n",
       "      <td>on Sir George Downing,</td>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>Jury</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Jury</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on “ Sir Hilary charged at Agincourt,”</td>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                index_term typ page_num  \\\n",
       "883   Chaucer’s Damascene,   S      442   \n",
       "883   Chaucer’s Damascene,   S      455   \n",
       "884             C. (H. B.)   S       77   \n",
       "885             C. (H. B.)   S       45   \n",
       "886             C. (H. B.)   S      NaN   \n",
       "...                    ...  ..      ...   \n",
       "1037                  Jury   S      350   \n",
       "1038                  Jury   S      NaN   \n",
       "1039                  Jury   S      498   \n",
       "1040                  Jury   S      NaN   \n",
       "1041                  Jury   S      NaN   \n",
       "\n",
       "                                  subsidiary  \\\n",
       "883                    portrait by Occleve,    \n",
       "883                    portrait by Occleve,    \n",
       "884                      on Duteh language,    \n",
       "885                Tace Latin for a candle,    \n",
       "886                     sanatory” and ‘* con   \n",
       "...                                      ...   \n",
       "1037                              on Scotch    \n",
       "1038                                           \n",
       "1039                 on Sir George Downing,    \n",
       "1040                                           \n",
       "1041  on “ Sir Hilary charged at Agincourt,”   \n",
       "\n",
       "                               source_id   year vol  \n",
       "883   sim_notes-and-queries_1850_2_index   1850   2  \n",
       "883   sim_notes-and-queries_1850_2_index   1850   2  \n",
       "884   sim_notes-and-queries_1850_2_index   1850   2  \n",
       "885   sim_notes-and-queries_1850_2_index   1850   2  \n",
       "886   sim_notes-and-queries_1850_2_index   1850   2  \n",
       "...                                  ...    ...  ..  \n",
       "1037  sim_notes-and-queries_1850_2_index   1850   2  \n",
       "1038  sim_notes-and-queries_1850_2_index   1850   2  \n",
       "1039  sim_notes-and-queries_1850_2_index   1850   2  \n",
       "1040  sim_notes-and-queries_1850_2_index   1850   2  \n",
       "1041  sim_notes-and-queries_1850_2_index   1850   2  \n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 1141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "construct_index_records(sample_index_id)[1000: 1200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221649b",
   "metadata": {},
   "source": [
    "It's far from ideal, but at least gives us something to work with. So let's add it to the database, and see how a search feels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "id": "0107ddcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table index_entries (source_id, year, vol, index_term, typ, subsidiary, page_num)>"
      ]
     },
     "execution_count": 1142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[\"index_entries\"].insert_all(construct_index_records(sample_index_id).to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839be04",
   "metadata": {},
   "source": [
    "Let's try a search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "id": "0b3e82c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>index_term</th>\n",
       "      <th>subsidiary</th>\n",
       "      <th>year</th>\n",
       "      <th>vol</th>\n",
       "      <th>page_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>Ague</td>\n",
       "      <td>cure for,</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>Ague</td>\n",
       "      <td>spiders, a cure for,</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>Wo.</td>\n",
       "      <td>on sympathetic cures,</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>D.</td>\n",
       "      <td>on cure for fits,</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>} Sunday</td>\n",
       "      <td>ts, cure f</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>H.</td>\n",
       "      <td>cure for warts,</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>H. (J. W.)</td>\n",
       "      <td>on cure for warts,</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>Junior</td>\n",
       "      <td>on spiders a cure for ague,</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>Spiders a cure for ague</td>\n",
       "      <td></td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>Sympathetic cures</td>\n",
       "      <td></td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>Thrush</td>\n",
       "      <td>cure for,</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sim_notes-and-queries_1850_2_index</td>\n",
       "      <td>Ww. (T. T )</td>\n",
       "      <td>on cure for warts,</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             source_id               index_term  \\\n",
       "0   sim_notes-and-queries_1850_2_index                     Ague   \n",
       "1   sim_notes-and-queries_1850_2_index                     Ague   \n",
       "2   sim_notes-and-queries_1850_2_index                      Wo.   \n",
       "3   sim_notes-and-queries_1850_2_index                       D.   \n",
       "4   sim_notes-and-queries_1850_2_index                 } Sunday   \n",
       "5   sim_notes-and-queries_1850_2_index                       H.   \n",
       "6   sim_notes-and-queries_1850_2_index               H. (J. W.)   \n",
       "7   sim_notes-and-queries_1850_2_index                   Junior   \n",
       "8   sim_notes-and-queries_1850_2_index  Spiders a cure for ague   \n",
       "9   sim_notes-and-queries_1850_2_index        Sympathetic cures   \n",
       "10  sim_notes-and-queries_1850_2_index                   Thrush   \n",
       "11  sim_notes-and-queries_1850_2_index              Ww. (T. T )   \n",
       "\n",
       "                      subsidiary   year vol  page_num  \n",
       "0                     cure for,    1850   2     130.0  \n",
       "1          spiders, a cure for,    1850   2     259.0  \n",
       "2         on sympathetic cures,    1850   2     130.0  \n",
       "3             on cure for fits,    1850   2       5.0  \n",
       "4                     ts, cure f   1850   2       NaN  \n",
       "5               cure for warts,    1850   2      68.0  \n",
       "6            on cure for warts,    1850   2     450.0  \n",
       "7   on spiders a cure for ague,    1850   2     299.0  \n",
       "8                                  1850   2     259.0  \n",
       "9                                  1850   2     150.0  \n",
       "10                    cure for,    1850   2     512.0  \n",
       "11           on cure for warts,    1850   2      68.0  "
      ]
     },
     "execution_count": 1143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_term = \"cure\"\n",
    "\n",
    "q = f\"\"\"\n",
    "SELECT * FROM index_entries_fts\n",
    "WHERE index_entries_fts MATCH {db.quote(search_term)};\n",
    "\"\"\"\n",
    "\n",
    "read_sql(q, db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d47af4a",
   "metadata": {},
   "source": [
    "Let's create a search index over all the index issues up to 1892."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "id": "71d82b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f326b1b1c42946e7890a320b9ebae231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "db[\"index_entries\"].delete_where()\n",
    "db[\"index_entries_fts\"].delete_where()\n",
    "\n",
    "# List of indexes already loaded: indexes\n",
    "\n",
    "for index_record in tqdm(indexes):\n",
    "    index_records = construct_index_records(index_record[\"id\"])\n",
    "    db[\"index_entries\"].insert_all( index_records.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf3388e",
   "metadata": {},
   "source": [
    "And how about a search..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "id": "87dd7b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>index_term</th>\n",
       "      <th>subsidiary</th>\n",
       "      <th>year</th>\n",
       "      <th>vol</th>\n",
       "      <th>page_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim_notes-and-queries_1869_4_index</td>\n",
       "      <td>Boggarts and Feorin</td>\n",
       "      <td></td>\n",
       "      <td>1869</td>\n",
       "      <td>4</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_notes-and-queries_1869_4_index</td>\n",
       "      <td>Boggarts and Feorin</td>\n",
       "      <td></td>\n",
       "      <td>1869</td>\n",
       "      <td>4</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim_notes-and-queries_1869_4_index</td>\n",
       "      <td>Higson (John)</td>\n",
       "      <td>on Boggarts and Feorin,</td>\n",
       "      <td>1869</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim_notes-and-queries_1870_5_index</td>\n",
       "      <td>Boggarts and Feorin</td>\n",
       "      <td></td>\n",
       "      <td>1870</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sim_notes-and-queries_1870_5_index</td>\n",
       "      <td>Boggarts and Feorin</td>\n",
       "      <td></td>\n",
       "      <td>1870</td>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sim_notes-and-queries_1870_5_index</td>\n",
       "      <td>Boggarts and Feorin</td>\n",
       "      <td></td>\n",
       "      <td>1870</td>\n",
       "      <td>5</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sim_notes-and-queries_1870_5_index</td>\n",
       "      <td>Boggarts and Feorin</td>\n",
       "      <td></td>\n",
       "      <td>1870</td>\n",
       "      <td>5</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sim_notes-and-queries_1870_5_index</td>\n",
       "      <td>Boggarts and Feorin</td>\n",
       "      <td></td>\n",
       "      <td>1870</td>\n",
       "      <td>5</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sim_notes-and-queries_1870_5_index</td>\n",
       "      <td>Boggarts and Feorin</td>\n",
       "      <td></td>\n",
       "      <td>1870</td>\n",
       "      <td>5</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sim_notes-and-queries_1870_5_index</td>\n",
       "      <td>Bowker (James)</td>\n",
       "      <td>on Boggarts, Feorin, &amp;c.</td>\n",
       "      <td>1870</td>\n",
       "      <td>5</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sim_notes-and-queries_1870_5_index</td>\n",
       "      <td>Boggarts</td>\n",
       "      <td>Feorin,</td>\n",
       "      <td>1870</td>\n",
       "      <td>5</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sim_notes-and-queries_1870_5_index</td>\n",
       "      <td>Davies (Wm.)</td>\n",
       "      <td>on Boggarts, Feorin, &amp;c.,</td>\n",
       "      <td>1870</td>\n",
       "      <td>5</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sim_notes-and-queries_1870_5_index</td>\n",
       "      <td>Hermentrude</td>\n",
       "      <td>on Boggarts,</td>\n",
       "      <td>1870</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sim_notes-and-queries_1870_5_index</td>\n",
       "      <td>Boggarts</td>\n",
       "      <td>Feorin, &amp;c.,</td>\n",
       "      <td>1870</td>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sim_notes-and-queries_1870_5_index</td>\n",
       "      <td>Riley (H. T.)</td>\n",
       "      <td>on Boggarts, Feorin, &amp;c.,</td>\n",
       "      <td>1870</td>\n",
       "      <td>5</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sim_notes-and-queries_1870_5_index</td>\n",
       "      <td>Smith (W. J. B.)</td>\n",
       "      <td>on Boggarts, Feorin, &amp;e.,</td>\n",
       "      <td>1870</td>\n",
       "      <td>5</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             source_id           index_term  \\\n",
       "0   sim_notes-and-queries_1869_4_index  Boggarts and Feorin   \n",
       "1   sim_notes-and-queries_1869_4_index  Boggarts and Feorin   \n",
       "2   sim_notes-and-queries_1869_4_index        Higson (John)   \n",
       "3   sim_notes-and-queries_1870_5_index  Boggarts and Feorin   \n",
       "4   sim_notes-and-queries_1870_5_index  Boggarts and Feorin   \n",
       "5   sim_notes-and-queries_1870_5_index  Boggarts and Feorin   \n",
       "6   sim_notes-and-queries_1870_5_index  Boggarts and Feorin   \n",
       "7   sim_notes-and-queries_1870_5_index  Boggarts and Feorin   \n",
       "8   sim_notes-and-queries_1870_5_index  Boggarts and Feorin   \n",
       "9   sim_notes-and-queries_1870_5_index       Bowker (James)   \n",
       "10  sim_notes-and-queries_1870_5_index             Boggarts   \n",
       "11  sim_notes-and-queries_1870_5_index         Davies (Wm.)   \n",
       "12  sim_notes-and-queries_1870_5_index          Hermentrude   \n",
       "13  sim_notes-and-queries_1870_5_index             Boggarts   \n",
       "14  sim_notes-and-queries_1870_5_index        Riley (H. T.)   \n",
       "15  sim_notes-and-queries_1870_5_index     Smith (W. J. B.)   \n",
       "\n",
       "                    subsidiary   year vol  page_num  \n",
       "0                                1869   4       508  \n",
       "1                                1869   4       508  \n",
       "2     on Boggarts and Feorin,    1869   4         5  \n",
       "3                                1870   5        23  \n",
       "4                                1870   5       156  \n",
       "5                                1870   5       216  \n",
       "6                                1870   5       287  \n",
       "7                                1870   5       365  \n",
       "8                                1870   5       517  \n",
       "9    on Boggarts, Feorin, &c.    1870   5       365  \n",
       "10                    Feorin,    1870   5       287  \n",
       "11  on Boggarts, Feorin, &c.,    1870   5       216  \n",
       "12               on Boggarts,    1870   5        23  \n",
       "13               Feorin, &c.,    1870   5       156  \n",
       "14  on Boggarts, Feorin, &c.,    1870   5       216  \n",
       "15  on Boggarts, Feorin, &e.,    1870   5       317  "
      ]
     },
     "execution_count": 1151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_term = \"boggart\"\n",
    "\n",
    "q = f\"\"\"\n",
    "SELECT * FROM index_entries_fts\n",
    "WHERE index_entries_fts MATCH {db.quote(search_term)};\n",
    "\"\"\"\n",
    "\n",
    "read_sql(q, db.conn)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fbef47",
   "metadata": {},
   "source": [
    "Isle of Wight Dilamgerbendi;\n",
    "but see also https://newwoodlesford.xyz/churches-and-chapels/rev-john-kershaw-craig/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf755846",
   "metadata": {},
   "source": [
    "## Indexes After 1891\n",
    "\n",
    "How about the indexes *after* 1891?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6cd67e",
   "metadata": {},
   "source": [
    "## Free Text Search Returning Corresponding Issue Metadata\n",
    "\n",
    "One thing it might be useful to to is return the volume, issue and page numbers associated with particular search responses.\n",
    "\n",
    "This requires finding the issue and character index of the search term, and then looking up the character index against the page metadata.\n",
    "\n",
    "TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c952695",
   "metadata": {},
   "source": [
    "## Fuzzy Searching and Partially Matched Content\n",
    "\n",
    "On of the problems with the OCR search text is that the OCR process is not completely reliable, which means that the search text might include a large number of typographical errors based on misidentifying scanned letters and words. When running an *exact match* search over the search text, we are thus likely to miss large numbers of search hits in a less than perfectly scanned document.\n",
    "\n",
    "One way round this is to use search tools that detect partially matching terms (for example, *sin-eater* and *bin eater* almost match, differing only in the first letter and the space versus hyphen characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9542a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlite_utils import Database\n",
    "\n",
    "db_name = \"nq_demo.db\"\n",
    "db = Database(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3daded3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_leaf_num</th>\n",
       "      <th>id</th>\n",
       "      <th>page_idx</th>\n",
       "      <th>page_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>5</td>\n",
       "      <td>22 NOTES\\n \\nAND QUERIES.\\nCatalogue — in whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>8</td>\n",
       "      <td>Nov. 10. 1849.)\\nNOTES AND QUERIES.\\n25\\n \\nne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>9</td>\n",
       "      <td>bring with him some coffee, which he believed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>12</td>\n",
       "      <td>Nov. 10. 1849.]\\nActing her passions on our st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>sim_notes-and-queries_1849-11-10_1_2</td>\n",
       "      <td>14</td>\n",
       "      <td>~—\\n \\n|\\n \\nNov. 10. 1849.]\\nNOTES AND QUERIE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>sim_notes-and-queries_1849-11-17_1_3</td>\n",
       "      <td>8</td>\n",
       "      <td>= 17. 1849.] }\\nreceive his representations an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>2</td>\n",
       "      <td>~vwe eS | FY\\nweNTe 6 FS-r—lCUcUOrlClC hLOOlhC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>6</td>\n",
       "      <td>NOTES AND QUERIES.\\n \\n \\n \\nNov. 24. 1849.]\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>65</td>\n",
       "      <td>16</td>\n",
       "      <td>sim_notes-and-queries_1849-11-24_1_4</td>\n",
       "      <td>15</td>\n",
       "      <td>NOTES AND QUERIES.\\nJust published, Part II., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>71</td>\n",
       "      <td>6</td>\n",
       "      <td>sim_notes-and-queries_1849-12-01_1_5</td>\n",
       "      <td>5</td>\n",
       "      <td>NOTES AND QUERIES.\\n \\nmore than three Passeng...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  page_num  page_leaf_num                                    id  page_idx  \\\n",
       "0       23              6  sim_notes-and-queries_1849-11-10_1_2         5   \n",
       "1       26              9  sim_notes-and-queries_1849-11-10_1_2         8   \n",
       "2       27             10  sim_notes-and-queries_1849-11-10_1_2         9   \n",
       "3       30             13  sim_notes-and-queries_1849-11-10_1_2        12   \n",
       "4       32             15  sim_notes-and-queries_1849-11-10_1_2        14   \n",
       "5       42              9  sim_notes-and-queries_1849-11-17_1_3         8   \n",
       "6       52              3  sim_notes-and-queries_1849-11-24_1_4         2   \n",
       "7       56              7  sim_notes-and-queries_1849-11-24_1_4         6   \n",
       "8       65             16  sim_notes-and-queries_1849-11-24_1_4        15   \n",
       "9       71              6  sim_notes-and-queries_1849-12-01_1_5         5   \n",
       "\n",
       "                                           page_text  \n",
       "0  22 NOTES\\n \\nAND QUERIES.\\nCatalogue — in whic...  \n",
       "1  Nov. 10. 1849.)\\nNOTES AND QUERIES.\\n25\\n \\nne...  \n",
       "2  bring with him some coffee, which he believed ...  \n",
       "3  Nov. 10. 1849.]\\nActing her passions on our st...  \n",
       "4  ~—\\n \\n|\\n \\nNov. 10. 1849.]\\nNOTES AND QUERIE...  \n",
       "5  = 17. 1849.] }\\nreceive his representations an...  \n",
       "6  ~vwe eS | FY\\nweNTe 6 FS-r—lCUcUOrlClC hLOOlhC...  \n",
       "7  NOTES AND QUERIES.\\n \\n \\n \\nNov. 24. 1849.]\\n...  \n",
       "8  NOTES AND QUERIES.\\nJust published, Part II., ...  \n",
       "9  NOTES AND QUERIES.\\n \\nmore than three Passeng...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_sql\n",
    "\n",
    "search_term = \"\"\n",
    "\n",
    "q = f\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "read_sql(q, db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239c7402",
   "metadata": {},
   "source": [
    "## Creating a Search Engine Over 19th Century Editions of *Notes & Queries*\n",
    "\n",
    "We now have all the ingredients in place to create a search engine over all editions of *Notes & Queries* from the 19th century."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c9994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa87a43b",
   "metadata": {},
   "source": [
    "## Paragraph Level Chunks Table\n",
    "\n",
    "The following demonstrates how we might generate a paragraph level table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106d6217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0467b3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b3fe13b",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f6138",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TO DO - these chunks can then be added to the database, along with page number data, so lets create a database table for that:\n",
    "\n",
    "PAGE_INDEX_TABLE = \"page_indexes4\"\n",
    "\n",
    "db[PAGE_INDEX_TABLE].create({\n",
    "    \"id\": str,\n",
    "    \"page_text\": str,\n",
    "    \"page_leaf_num\": int, \n",
    "    \"page_num\": str, # should really be int\n",
    "    \"page_num_conf\": float\n",
    "}, pk=(\"id\", \"page_leaf_num\"))\n",
    "\n",
    "# Enable full text search\n",
    "# This creates an extra virtual table (books_fts) to support the full text search\n",
    "db[PAGE_INDEX_TABLE].enable_fts([\"id\", \"page_leaf_num\", \"page_text\"], create_triggers=True, tokenize=\"porter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546b9b6f",
   "metadata": {},
   "source": [
    "We also need a recipe for iterating through the records,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c2f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in tqdm(indexes+indexes2):\n",
    "    id_val = record['id']\n",
    "    _texts = chunk_text(id_val) \n",
    "\n",
    "We should now be able to search at a page level:\n",
    "\n",
    "q3 = '\"sin eater\"'\n",
    "\n",
    "_q = f\"\"\"\n",
    "SELECT id, page_leaf_num\n",
    "FROM page_indexes4_fts WHERE page_indexes4_fts MATCH {db.quote(q3)} ;\n",
    "\"\"\"\n",
    "\n",
    "for row in db.query(_q):\n",
    "    print(row['id'], row[\"page_leaf_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8553fef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d61bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data_records:\n",
    "    # Only look at index records\n",
    "    if 'index' in c['id']:\n",
    "        # Need to handle a YYYY - YYYY exception\n",
    "        # If we detect it, ignore it\n",
    "        if len(c['date'].split()) > 1:\n",
    "               continue\n",
    "        \n",
    "        # Parse the year into a date object\n",
    "        # Then filter by year\n",
    "        if dateparser.parse(c['date'].split()[0]).year >= maxyear:\n",
    "            break\n",
    "        indexes.append(c) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a9b501",
   "metadata": {},
   "source": [
    "## OLD TEST BITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "445dc50a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
