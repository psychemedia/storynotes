{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae30ca3c",
   "metadata": {},
   "source": [
    "# A Full Text Searchable Database of Lang's Fairy Books\n",
    "\n",
    "In the late 19th and early 20th century, Andrew Lang published various collections of fairy tales, starting with *The Blue Fairy Book* and then progressing though various other colours to *The Olive Fairy Book*.\n",
    "\n",
    "This notebook represents a playful aside in trying to build various searchable contexts over the stories.\n",
    "\n",
    "To begin with, let's start by ingesting the stories into a database and building a full text search over them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89cd90e",
   "metadata": {},
   "source": [
    "## Obtain Source Texts\n",
    "\n",
    "We can download the raw text for each of Lang's coloured Fairy Books from the Sacred Texts website. The books are listed on a single index page:\n",
    "\n",
    "![](images/Sacred-Texts__Lang_Fairy_Books.png)\n",
    "\n",
    "Let's start by importing some packages that can help us download pages from the Sacred Texts website in an efficient and straightforward way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea58b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These packages make it easy to download web pages so that we can work with them\n",
    "import requests\n",
    "# \"Cacheing\" pages mans grabbing a local copy of the page so we only need to download it once\n",
    "import requests_cache\n",
    "from datetime import timedelta\n",
    "\n",
    "requests_cache.install_cache('web_cache', backend='sqlite', expire_after=timedelta(days=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5103c9eb",
   "metadata": {},
   "source": [
    "Given the index page URL, we can easily download the index page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "791c0704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<HTML>\\r\\n<HEAD>\\r\\n<link rel=\"stylesheet\" href=\"../../css/ista.css\"><META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=UTF-8\">\\r\\n<link rel=\"alternate\" type=\"application/rss+xml\" title=\"RSS\" href=\"http://sacred-texts.com/rss/new.xml\">\\r\\n\\r\\n<META name=\"description\"\\r\\ncontent=\"Sacred Texts: Lang Fairy Books\">\\r\\n<META name=\"keywords\"\\r\\ncontent=\"Colored Fairy Books Fairy Tales Tale Folklore Folk lore Children Literature\">\\r\\n<TITLE>Sacred-Texts: Lang Fairy Books</TITLE></HEAD>\\r\\n<BODY>\\r\\n<table width=\"800\" border=\"0\" align=\"center\" cellpadding=\"0\" cellspacing=\"0\"><tr> \\r\\n<td height=\"131\" width=\"200\" align=\"left\" valign=\"top\"> \\r\\n<div align=\"left\"><a href=\"../../cdshop/index.htm\"><img src=\"../../img/cdad.gif\" width=\"206\" height=\"136\" border=\"0\"></a></div>\\r\\n</td>\\r\\n<td height=\"131\" width=\"600\" colspan=\"3\"><div align=\"left\"><img src=\"../../img/menu.jpg\" width=\"600\" height=\"134\" usemap=\"#Map\" border=\"0\"><map name=\"Map\"><area shape=\"rect\" coords=\"33,5,552,78\" href=\"../../index.htm\" alt=\"sacred-texts.co'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the URL of the page we want to download\n",
    "url = \"https://www.sacred-texts.com/neu/lfb/index.htm\"\n",
    "\n",
    "# And then grab the page\n",
    "html = requests.get(url)\n",
    "\n",
    "# Preview some of the raw web page / HTML text in the page we just downloaded\n",
    "html.text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8705894d",
   "metadata": {},
   "source": [
    "By inspection of the HTML, we see the books are in `span` tag with a `ista-content` class. Digging further, we then notice the links are in `c_t` classed `span` elements. We can extract them using beautiful soup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e2cf431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"c_t\"><a href=\"bl/index.htm\">The Blue Fairy Book</a></span>,\n",
       " <span class=\"c_t\"><a href=\"br/index.htm\">The Brown Fairy Book</a></span>,\n",
       " <span class=\"c_t\"><a href=\"cr/index.htm\">The Crimson Fairy Book</a></span>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The BeautifulSoup package provides a range of tools\n",
    "# that help us work with the downloaded web page,\n",
    "# such as extracting particular elements from it\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# The \"soup\" is a parsed and structured form of the page we downloaded\n",
    "soup = BeautifulSoup(html.content, \"html.parser\")\n",
    "\n",
    "# Find the span elements containing the links\n",
    "items_ = soup.find(\"span\", class_=\"ista-content\").find_all(\"span\", class_=\"c_t\")\n",
    "\n",
    "# Preview the first few extracted <span> elements\n",
    "items_[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd81370",
   "metadata": {},
   "source": [
    "Let's grab just the anchor tags from there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba8ab9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"bl/index.htm\">The Blue Fairy Book</a>,\n",
       " <a href=\"br/index.htm\">The Brown Fairy Book</a>,\n",
       " <a href=\"cr/index.htm\">The Crimson Fairy Book</a>,\n",
       " <a href=\"gn/index.htm\">The Green Fairy Book</a>,\n",
       " <a href=\"gy/index.htm\">The Grey Fairy Book</a>,\n",
       " <a href=\"li/index.htm\">The Lilac Fairy Book</a>,\n",
       " <a href=\"ol/index.htm\">The Olive Fairy Book</a>,\n",
       " <a href=\"or/index.htm\">The Orange Fairy Book</a>,\n",
       " <a href=\"pi/index.htm\">The Pink Fairy Book</a>,\n",
       " <a href=\"re/index.htm\">The Red Fairy Book</a>,\n",
       " <a href=\"vi/index.htm\">The Violet Fairy Book</a>,\n",
       " <a href=\"ye/index.htm\">The Yellow Fairy Book</a>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following construction is known as a \"list comprehension\"\n",
    "# It generates a list of items (items contained in square brackets, [])\n",
    "# from another list of items\n",
    "\n",
    "items_ = [item.find(\"a\") for item in items_]\n",
    "items_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce8dca9",
   "metadata": {},
   "source": [
    "`````{admonition} List Comprehensions\n",
    "List comprehensions provide a concise form for defining one list structure based on the contents of another (or more generally, any iterable).\n",
    "\n",
    "In an expanded form, we might create one list from another using a loop of the form:\n",
    "\n",
    "```python\n",
    "new_list = []\n",
    "for item in items:\n",
    "    new_list.append( process(items) )\n",
    "```\n",
    "\n",
    "In a list comprehension, we might write:\n",
    "\n",
    "```python\n",
    "new_list = []\n",
    "for item in items:\n",
    "    new_list.append( process(items) )\n",
    "```\n",
    "\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8e5238",
   "metadata": {},
   "source": [
    "The links are *relative* links, which means we need to resolve them relative to the path of the current page.\n",
    "\n",
    "Obtain the path to the current page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a34bcbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip the \"index.htm\" element from the URL to give a \"base\" URL\n",
    "base_url = url.replace(\"index.htm\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6a8453",
   "metadata": {},
   "source": [
    "Extract the link text (`link.text`) and relative links (`link.get('href')`) from the `<a>` tags and use a Pyhton f-string to generate full links for each book page (`f\"{base_url}{link.get('href')}\"`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc480f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base URL: https://www.sacred-texts.com/neu/lfb/\n",
      "Example links: [('The Blue Fairy Book', 'https://www.sacred-texts.com/neu/lfb/bl/index.htm'), ('The Brown Fairy Book', 'https://www.sacred-texts.com/neu/lfb/br/index.htm'), ('The Crimson Fairy Book', 'https://www.sacred-texts.com/neu/lfb/cr/index.htm')]\n"
     ]
    }
   ],
   "source": [
    "links = [(link.text, f\"{base_url}{link.get('href')}\") for link in items_]\n",
    "\n",
    "# Display some annotated output to see what's going on\n",
    "print(f\"Base URL: {base_url}\\nExample links: {links[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f751e8",
   "metadata": {},
   "source": [
    "```{admonition} Python f-strings\n",
    "\n",
    "Python's f-strings (*formatted string literals*, [PEP 498](https://docs.python.org/3/whatsnew/3.6.html#whatsnew36-pep498)) are strings prefixed with an `f` character. The strings contain \"replacement fields\" of code contained within curly braces. The contents of the curly braces are evaluated and included in the returned string.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3835cfaa",
   "metadata": {},
   "source": [
    "We can also grab the publication year for each work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b85c2205",
   "metadata": {},
   "outputs": [],
   "source": [
    "years_ = soup.find(\"span\", class_=\"ista-content\").find_all(\"span\", class_=\"c_d\")\n",
    "years = [year.text for year in years_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c16d63",
   "metadata": {},
   "source": [
    "And merge those in to a metadata record collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ced7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('The Blue Fairy Book', 'https://www.sacred-texts.com/neu/lfb/bl/index.htm'),\n",
       "  '1889'),\n",
       " (('The Brown Fairy Book',\n",
       "   'https://www.sacred-texts.com/neu/lfb/br/index.htm'),\n",
       "  '1904'),\n",
       " (('The Crimson Fairy Book',\n",
       "   'https://www.sacred-texts.com/neu/lfb/cr/index.htm'),\n",
       "  '1903')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sacred_metadata = list(zip(links, years))\n",
    "sacred_metadata[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d03c7c",
   "metadata": {},
   "source": [
    "We could now load each of those pages and then scrape the download link. But, we notice that the download links have a regular pattern: `https://www.sacred-texts.com/neu/lfb/bl/blfb.txt.gz` which we can derive from the book pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a12af05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The Blue Fairy Book',\n",
       "  'https://www.sacred-texts.com/neu/lfb/bl/blfb.txt.gz'),\n",
       " ('The Brown Fairy Book',\n",
       "  'https://www.sacred-texts.com/neu/lfb/br/brfb.txt.gz'),\n",
       " ('The Crimson Fairy Book',\n",
       "  'https://www.sacred-texts.com/neu/lfb/cr/crfb.txt.gz')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_links = []\n",
    "\n",
    "for (_title, _url) in links:\n",
    "    # We need to get the \"short\" colour name of the book\n",
    "    # which can be found in the URL path...\n",
    "    book_path = _url.split(\"/\")[-2]\n",
    "    zip_fn =  f\"{book_path}fb.txt.gz\"\n",
    "    zip_url = _url.replace(\"index.htm\", zip_fn)\n",
    "    \n",
    "    download_links.append((_title, zip_url))\n",
    "\n",
    "download_links[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899bcbf6",
   "metadata": {},
   "source": [
    "Now we can download and unzip the files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1153341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "for (_, url) in download_links:\n",
    "    # Create a file name to save file to as the file downloaded from the URL\n",
    "    zip_file = url.split(\"/\")[-1]\n",
    "    urllib.request.urlretrieve(url, zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1da1ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ashliman_folk_texts_scraper.ipynb\r\n",
      "DBPedia_Aarne-Thompson-Uther_Search.ipynb\r\n",
      "Jacobs' Fairy Tales.ipynb\r\n",
      "LICENSE\r\n",
      "Lang_Doc2Vec.ipynb\r\n",
      "MFTD-Multilingual_Folk_Tale_Database.ipynb\r\n",
      "Missouri_Tale_Types.ipynb\r\n",
      "README.md\r\n",
      "Story db search examples.ipynb\r\n",
      "Thompson_Motif_Index.ipynb\r\n",
      "\u001b[34m_build\u001b[m\u001b[m\r\n",
      "_config.yml\r\n",
      "_toc.yml\r\n",
      "ashliman_demo.db\r\n",
      "blfb.txt.gz\r\n",
      "brfb.txt.gz\r\n",
      "crfb.txt.gz\r\n",
      "demo.db\r\n",
      "\u001b[34mdocs\u001b[m\u001b[m\r\n",
      "gnfb.txt.gz\r\n",
      "gyfb.txt.gz\r\n",
      "how-to-read-this-book.ipynb\r\n",
      "\u001b[34mimages\u001b[m\u001b[m\r\n",
      "lang-fairy-books-db.ipynb\r\n",
      "lang-fairy-books-db_PART 1.ipynb\r\n",
      "lang-fairy-books-db_PART 2.ipynb\r\n",
      "lang-fairy-books-db_PART 3.ipynb\r\n",
      "lang-fairy-books-db_PART 4.ipynb\r\n",
      "lang_fairy_tale.db\r\n",
      "lang_model.gensim\r\n",
      "lifb.txt.gz\r\n",
      "motifs_demo.db\r\n",
      "mtdf_demo.db\r\n",
      "olfb.txt.gz\r\n",
      "orfb.txt.gz\r\n",
      "pifb.txt.gz\r\n",
      "preface.md\r\n",
      "refb.txt.gz\r\n",
      "requirements.txt\r\n",
      "tale_types_demo.db\r\n",
      "thompson_motif_index.csv\r\n",
      "vifb.txt.gz\r\n",
      "web_cache.sqlite\r\n",
      "yefb.txt.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17b111",
   "metadata": {},
   "source": [
    "The following function will read in the contents of a local gzip file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78e08924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "def gzip_txt(fn):\n",
    "    \"\"\"Open gzip file and extract text.\"\"\"\n",
    "    with gzip.open(fn,'rb') as f:\n",
    "        txt = f.read().decode('UTF-8').replace(\"\\r\", \"\")\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ac822b",
   "metadata": {},
   "source": [
    "Let's see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0657b9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe Green Fairy Book, by Andrew Lang, [1892], at sacred-texts.com\\n\\nTHE GREEN FAIRY BOOK\\n\\nBy Various\\n\\nEdited by Andrew Lang\\n\\nLondon, New York: Longmans, Green, and Co.\\n\\n[1892]\\n\\nTo\\n\\nStella Margaret Alleyne\\n\\nthe\\n\\nGreen Fairy Book\\n\\nis dedicated\\n\\nThe Green Fairy Book, by Andrew Lang, [1892], at sacred-texts.com\\n\\nContents\\n\\n[*To the Friendly Reader]\\n\\n[*The Blue Bird]\\n\\n[*The Half-Chick]\\n\\n[*The Story of Caliph Stork]\\n\\n[*The Enchanted Watch]\\n\\n[*Rosanella]\\n\\n[*Sylvain and Jocosa]\\n\\n[*Fairy Gifts]\\n\\n[*Prince Narcissus and the Princess Potentilla]\\n\\n[*Prince Featherhead and the Princess Celandine]\\n\\n[*The Three Little Pigs]\\n\\n[*Heart of Ice]\\n\\n[*The Enchanted Ring]\\n\\n[*The Snuff-box]\\n\\n[*The Golden Blackbird]\\n\\n[*The Little Soldier]\\n\\n[*The Magic Swan]\\n\\n[*The Dirty Shepherdess]\\n\\n[*The Enchanted Snake]\\n\\n[*The Biter Bit]\\n\\n[*King Kojata]\\n\\n[*Prince Fickle and Fair Helena]\\n\\n[*Puddocky]\\n\\n[*The Story of Hok Lee and the Dwarfs]\\n\\n[*The Story of the Three Bears]\\n\\n[*Prince Vivien and the Princess Placida]\\n\\n[*Little One'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gzip_txt('gnfb.txt.gz')[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1245a4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ashliman_folk_texts_scraper.ipynb\r\n",
      "DBPedia_Aarne-Thompson-Uther_Search.ipynb\r\n",
      "Jacobs' Fairy Tales.ipynb\r\n",
      "LICENSE\r\n",
      "Lang_Doc2Vec.ipynb\r\n",
      "MFTD-Multilingual_Folk_Tale_Database.ipynb\r\n",
      "Missouri_Tale_Types.ipynb\r\n",
      "README.md\r\n",
      "Story db search examples.ipynb\r\n",
      "Thompson_Motif_Index.ipynb\r\n",
      "\u001b[34m_build\u001b[m\u001b[m\r\n",
      "_config.yml\r\n",
      "_toc.yml\r\n",
      "ashliman_demo.db\r\n",
      "blfb.txt.gz\r\n",
      "brfb.txt.gz\r\n",
      "crfb.txt.gz\r\n",
      "demo.db\r\n",
      "\u001b[34mdocs\u001b[m\u001b[m\r\n",
      "gnfb.txt.gz\r\n",
      "gyfb.txt.gz\r\n",
      "how-to-read-this-book.ipynb\r\n",
      "\u001b[34mimages\u001b[m\u001b[m\r\n",
      "lang-fairy-books-db.ipynb\r\n",
      "lang-fairy-books-db_PART 1.ipynb\r\n",
      "lang-fairy-books-db_PART 2.ipynb\r\n",
      "lang-fairy-books-db_PART 3.ipynb\r\n",
      "lang-fairy-books-db_PART 4.ipynb\r\n",
      "lang_fairy_tale.db\r\n",
      "lang_model.gensim\r\n",
      "lifb.txt.gz\r\n",
      "motifs_demo.db\r\n",
      "mtdf_demo.db\r\n",
      "olfb.txt.gz\r\n",
      "orfb.txt.gz\r\n",
      "pifb.txt.gz\r\n",
      "preface.md\r\n",
      "refb.txt.gz\r\n",
      "requirements.txt\r\n",
      "tale_types_demo.db\r\n",
      "thompson_motif_index.csv\r\n",
      "vifb.txt.gz\r\n",
      "web_cache.sqlite\r\n",
      "yefb.txt.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e0859",
   "metadata": {},
   "source": [
    "Select one of the books and read in the book text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cddeff1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe Blue Fairy Book, by Andrew Lang, [1889], at sacred-texts.com\\n\\nTHE BLUE FAIRY BOOK\\n\\nby Andrew Lang\\n\\nLondon, New York: Longmans, Green\\n\\n[1889]\\n\\nThe Blue Fairy Book, by Andrew Lang, [1889], at sacred-texts.com\\n\\nCONTENTS\\n\\n[*THE BRONZE RING]\\n\\n[*PRINCE HYACINTH AND THE DEAR LITTLE PRINCESS]\\n\\n[*EAST OF THE SUN AND WEST OF THE MOON]\\n\\n[*THE YELLOW DWARF]\\n\\n[*LITTLE RED RIDING-HOOD]\\n\\n[*THE SLEEPING BEAUTY IN THE WOOD]\\n\\n[*CINDERELLA; OR, THE LITTLE GLASS SLIPPER]\\n\\n[*ALADDIN AND THE WONDERFUL LAMP]\\n\\n[*THE TALE OF A YOUTH WHO SET OUT TO LEARN WHAT FEAR WAS]\\n\\n[*RUMPELSTILTZKIN]\\n\\n[*BEAUTY AND THE BEAST]\\n\\n[*THE MASTER-MAID]\\n\\n[*WHY THE SEA IS SALT]\\n\\n[*THE MASTER CAT; OR, PUSS IN BOOTS]\\n\\n[*FELICIA AND THE POT OF PINKS]\\n\\n[*THE WHITE CAT]\\n\\n[*THE WATER-LILY. THE GOLD-SPINNERS]\\n\\n[*THE TERRIBLE HEAD]\\n\\n[*THE STORY OF PRETTY GOLDILOCKS]\\n\\n[*THE HISTORY OF WHITTINGTON]\\n\\n[*THE WONDERFUL SHEEP]\\n\\n[*LITTLE THUMB]\\n\\n[*THE FORTY THIEVES]\\n\\n[*HANSEL AND GRETTEL]\\n\\n[*SNOW-WHITE AND ROSE-RED]\\n\\n[*THE GOOSE-GIRL]\\n\\n[*TOADS AND DIAMONDS]\\n\\n[*PRINCE DARLING]\\n\\n[*BLUE BEARD]\\n\\n[*TRUSTY JOHN]\\n\\n[*THE BRAVE LITTLE TAILOR]\\n\\n[*A VOYAGE TO LILLIPUT]\\n\\n[*THE PRINCESS ON THE GLASS HILL]\\n\\n[*THE STORY OF PRINCE AHMED AND THE FAIRY PARIBANOU]\\n\\n[*THE HISTORY OF JACK THE GIANT-KILLER]\\n\\n[*THE BLACK BULL OF NORROWAY]\\n\\n[*THE RED ETIN]\\n\\nThe Blue Fairy Book, by Andrew Lang, [1889], at sacred-texts.com\\n\\n[f01]\\n\\nTHE BRONZE RING\\n\\nOnce upon a time in a certain country there lived a king whose palace was surrounded by a spacious garden. But, t'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = gzip_txt('blfb.txt.gz')\n",
    "\n",
    "# Preview the first 1500 characters\n",
    "txt[:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc88d781",
   "metadata": {},
   "source": [
    "## Extract Stories\n",
    "\n",
    "Having got the contents, let's now extract all the stories.\n",
    "\n",
    "Within each book, the stories are delimited by a pattern `[fNN]` (for digits `N`). We can use this pattern to split out the stories.\n",
    "\n",
    "To do this, we'll use the `re` regular expression package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07a1a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54296e4",
   "metadata": {},
   "source": [
    "We can now define a pattern against which we can split each file into separate chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee55966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the file into separate chunks delimited by the pattern: [fNN]\n",
    "stories = re.split(\"\\[f\\d{2}\\]\", txt)\n",
    "\n",
    "# Strip whitespace at start and end\n",
    "stories = [s.strip(\"\\n\") for s in stories]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7128ed",
   "metadata": {},
   "source": [
    "## Extract the contents\n",
    "\n",
    "The contents appear in the first \"story chunk\" (index `0`) in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1029a037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Blue Fairy Book, by Andrew Lang, [1889], at sacred-texts.com\\n\\nTHE BLUE FAIRY BOOK\\n\\nby Andrew Lang\\n\\nLondon, New York: Longmans, Green\\n\\n[1889]\\n\\nThe Blue Fairy Book, by Andrew Lang, [1889], at sacred-texts.com\\n\\nCONTENTS\\n\\n[*THE BRONZE RING]\\n\\n[*PRINCE HYACINTH AND THE DEAR LITTLE PRINCESS]\\n\\n[*EAST OF THE SUN AND WEST OF THE MOON]\\n\\n[*THE YELLOW DWARF]\\n\\n[*LITTLE RED RIDING-HOOD]\\n\\n[*THE SLEEPING BEAUTY IN THE WOOD]\\n\\n[*CINDERELLA; OR, THE LITTLE GLASS SLIPPER]\\n\\n[*ALADDIN AND THE WONDERFUL LAMP]\\n\\n[*THE TALE OF A YOUTH WHO SET OUT TO LEARN WHAT FEAR WAS]\\n\\n[*RUMPELSTILTZKIN]\\n\\n[*BEAUTY AND THE BEAST]\\n\\n[*THE MASTER-MAID]\\n\\n[*WHY THE SEA IS SALT]\\n\\n[*THE MASTER CAT; OR, PUSS IN BOOTS]\\n\\n[*FELICIA AND THE POT OF PINKS]\\n\\n[*THE WHITE CAT]\\n\\n[*THE WATER-LILY. THE GOLD-SPINNERS]\\n\\n[*THE TERRIBLE HEAD]\\n\\n[*THE STORY OF PRETTY GOLDILOCKS]\\n\\n[*THE HISTORY OF WHITTINGTON]\\n\\n[*THE WONDERFUL SHEEP]\\n\\n[*LITTLE THUMB]\\n\\n[*THE FORTY THIEVES]\\n\\n[*HANSEL AND GRETTEL]\\n\\n[*SNOW-WHITE AND ROSE-RED]\\n\\n[*THE GOOSE-GIRL]\\n\\n[*TOADS AND DIAMONDS]\\n\\n[*PRINCE DARLING]\\n\\n[*BLUE BEARD]\\n\\n[*TRUSTY JOHN]\\n\\n[*THE BRAVE LITTLE TAILOR]\\n\\n[*A VOYAGE TO LILLIPUT]\\n\\n[*THE PRINCESS ON THE GLASS HILL]\\n\\n[*THE STORY OF PRINCE AHMED AND THE FAIRY PARIBANOU]\\n\\n[*THE HISTORY OF JACK THE GIANT-KILLER]\\n\\n[*THE BLACK BULL OF NORROWAY]\\n\\n[*THE RED ETIN]\\n\\nThe Blue Fairy Book, by Andrew Lang, [1889], at sacred-texts.com'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b4ecda",
   "metadata": {},
   "source": [
    "Let's pull out the book name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35a8ec0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Blue Fairy Book'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The name appears before the first comma\n",
    "book = stories[0].split(\",\")[0]\n",
    "book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e7429",
   "metadata": {},
   "source": [
    "The Python [`parse`](https://github.com/r1chardj0n3s/parse) package provides a simple way of *matching* patterns using syntax that resembles a string formatting template that could be used to create the strings being matched against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29af6f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e88de5f",
   "metadata": {},
   "source": [
    "We can alternatively is this package to extract the title against a template style pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "021a1345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The Blue Fairy Book', '1889')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The Blue Fairy Book, by Andrew Lang, [1889], at sacred-texts.com\n",
    "metadata = parse.parse(\"{title}, by Andrew Lang, [{year}]{}, at sacred-texts.com\", stories[0])\n",
    "\n",
    "metadata[\"title\"], metadata[\"year\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65d36cf",
   "metadata": {},
   "source": [
    "There are plenty of cribs to help us pull out the contents, although it may not be obviously clear with the early content items whether they are stories or not..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86a28338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Blue Fairy Book, by Andrew Lang, [1889], at sacred-texts.com\\n\\nTHE BLUE FAIRY BOOK\\n\\nby Andrew Lang\\n\\nLondon, New York: Longmans, Green\\n\\n[1889]\\n\\nThe Blue Fairy Book, by Andrew Lang, [1889], at sacred-texts.com\\n\\n',\n",
       " 'CONTENTS',\n",
       " '\\n\\n[*THE BRONZE RING]\\n\\n[*PRINCE HYACINTH AND THE DEAR LITTLE PRINCESS]\\n\\n[*EAST OF THE SUN AND WEST OF THE MOON]\\n\\n[*THE YELLOW DWARF]\\n\\n[*LITTLE RED RIDING-HOOD]\\n\\n[*THE SLEEPING BEAUTY IN THE WOOD]\\n\\n[*CINDERELLA; OR, THE LITTLE GLASS SLIPPER]\\n\\n[*ALADDIN AND THE WONDERFUL LAMP]\\n\\n[*THE TALE OF A YOUTH WHO SET OUT TO LEARN WHAT FEAR WAS]\\n\\n[*RUMPELSTILTZKIN]\\n\\n[*BEAUTY AND THE BEAST]\\n\\n[*THE MASTER-MAID]\\n\\n[*WHY THE SEA IS SALT]\\n\\n[*THE MASTER CAT; OR, PUSS IN BOOTS]\\n\\n[*FELICIA AND THE POT OF PINKS]\\n\\n[*THE WHITE CAT]\\n\\n[*THE WATER-LILY. THE GOLD-SPINNERS]\\n\\n[*THE TERRIBLE HEAD]\\n\\n[*THE STORY OF PRETTY GOLDILOCKS]\\n\\n[*THE HISTORY OF WHITTINGTON]\\n\\n[*THE WONDERFUL SHEEP]\\n\\n[*LITTLE THUMB]\\n\\n[*THE FORTY THIEVES]\\n\\n[*HANSEL AND GRETTEL]\\n\\n[*SNOW-WHITE AND ROSE-RED]\\n\\n[*THE GOOSE-GIRL]\\n\\n[*TOADS AND DIAMONDS]\\n\\n[*PRINCE DARLING]\\n\\n[*BLUE BEARD]\\n\\n[*TRUSTY JOHN]\\n\\n[*THE BRAVE LITTLE TAILOR]\\n\\n[*A VOYAGE TO LILLIPUT]\\n\\n[*THE PRINCESS ON THE GLASS HILL]\\n\\n[*THE STORY OF PRINCE AHMED AND THE FAIRY PARIBANOU]\\n\\n[*THE HISTORY OF JACK THE GIANT-KILLER]\\n\\n[*THE BLACK BULL OF NORROWAY]\\n\\n[*THE RED ETIN]\\n\\nThe Blue Fairy Book, by Andrew Lang, [1889], at sacred-texts.com']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is a Contents header, but it may be cased...\n",
    "# So split in a case insensitive way\n",
    "boilerplate = re.split('(Contents|CONTENTS)', stories[0])\n",
    "boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e917c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[*THE BRONZE RING]\\n\\n[*PRINCE HYACINTH AND THE DEAR LITTLE PRINCESS]\\n\\n[*EAST OF THE SUN AND WEST OF THE MOON]\\n\\n[*THE YELLOW DWARF]\\n\\n[*LITTLE RED RIDING-HOOD]\\n\\n[*THE SLEEPING BEAUTY IN THE WOOD]\\n\\n[*CINDERELLA; OR, THE LITTLE GLASS SLIPPER]\\n\\n[*ALADDIN AND THE WONDERFUL LAMP]\\n\\n[*THE TALE OF A YOUTH WHO SET OUT TO LEARN WHAT FEAR WAS]\\n\\n[*RUMPELSTILTZKIN]\\n\\n[*BEAUTY AND THE BEAST]\\n\\n[*THE MASTER-MAID]\\n\\n[*WHY THE SEA IS SALT]\\n\\n[*THE MASTER CAT; OR, PUSS IN BOOTS]\\n\\n[*FELICIA AND THE POT OF PINKS]\\n\\n[*THE WHITE CAT]\\n\\n[*THE WATER-LILY. THE GOLD-SPINNERS]\\n\\n[*THE TERRIBLE HEAD]\\n\\n[*THE STORY OF PRETTY GOLDILOCKS]\\n\\n[*THE HISTORY OF WHITTINGTON]\\n\\n[*THE WONDERFUL SHEEP]\\n\\n[*LITTLE THUMB]\\n\\n[*THE FORTY THIEVES]\\n\\n[*HANSEL AND GRETTEL]\\n\\n[*SNOW-WHITE AND ROSE-RED]\\n\\n[*THE GOOSE-GIRL]\\n\\n[*TOADS AND DIAMONDS]\\n\\n[*PRINCE DARLING]\\n\\n[*BLUE BEARD]\\n\\n[*TRUSTY JOHN]\\n\\n[*THE BRAVE LITTLE TAILOR]\\n\\n[*A VOYAGE TO LILLIPUT]\\n\\n[*THE PRINCESS ON THE GLASS HILL]\\n\\n[*THE STORY OF PRINCE AHMED AND THE FAIRY PARIBANOU]\\n\\n[*THE HISTORY OF JACK THE GIANT-KILLER]\\n\\n[*THE BLACK BULL OF NORROWAY]\\n\\n[*THE RED ETIN]'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The name of the book repeats at the end of the content block\n",
    "# So snip it out... \n",
    "contents_ = boilerplate[-1].split(book)[0].strip(\"\\n\")\n",
    "contents_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d756c580",
   "metadata": {},
   "source": [
    "We note that `contents_` conains a string with repeated end of line elements (`\\n\\n`) separating the titles in the form `[*STORY TITLE]` (for example, `[*LITTLE RED RIDING-HOOD]`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b7167a",
   "metadata": {},
   "source": [
    "We can parse out titles from the contents list based on the pattern delimiter `[*EXTRACT THIS PATTERN]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ca92a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Bronze Ring',\n",
       " 'Prince Hyacinth And The Dear Little Princess',\n",
       " 'East Of The Sun And West Of The Moon',\n",
       " 'The Yellow Dwarf',\n",
       " 'Little Red Riding-Hood',\n",
       " 'The Sleeping Beauty In The Wood',\n",
       " 'Cinderella; Or, The Little Glass Slipper',\n",
       " 'Aladdin And The Wonderful Lamp',\n",
       " 'The Tale Of A Youth Who Set Out To Learn What Fear Was',\n",
       " 'Rumpelstiltzkin',\n",
       " 'Beauty And The Beast',\n",
       " 'The Master-Maid',\n",
       " 'Why The Sea Is Salt',\n",
       " 'The Master Cat; Or, Puss In Boots',\n",
       " 'Felicia And The Pot Of Pinks',\n",
       " 'The White Cat',\n",
       " 'The Water-Lily. The Gold-Spinners',\n",
       " 'The Terrible Head',\n",
       " 'The Story Of Pretty Goldilocks',\n",
       " 'The History Of Whittington',\n",
       " 'The Wonderful Sheep',\n",
       " 'Little Thumb',\n",
       " 'The Forty Thieves',\n",
       " 'Hansel And Grettel',\n",
       " 'Snow-White And Rose-Red',\n",
       " 'The Goose-Girl',\n",
       " 'Toads And Diamonds',\n",
       " 'Prince Darling',\n",
       " 'Blue Beard',\n",
       " 'Trusty John',\n",
       " 'The Brave Little Tailor',\n",
       " 'A Voyage To Lilliput',\n",
       " 'The Princess On The Glass Hill',\n",
       " 'The Story Of Prince Ahmed And The Fairy Paribanou',\n",
       " 'The History Of Jack The Giant-Killer',\n",
       " 'The Black Bull Of Norroway',\n",
       " 'The Red Etin']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match against [* and ] and extract everything in between\n",
    "contents = parse.findall(\"[*{}]\", contents_)\n",
    "\n",
    "# The title text available as item.fixed[0]\n",
    "# Also convert the title to title case\n",
    "titles = [item.fixed[0].title() for item in contents]\n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740cad6b",
   "metadata": {},
   "source": [
    "## Coping With Page Numbers\n",
    "\n",
    "There seems to be work in progress adding page numbers to books using a pattern of the form `[p. ix]`, `[p. 1]`, `[p. 11]` and so on.\n",
    "\n",
    "For now, let's create a regular expression substitution to remove those..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "115004cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[f01]THE YELLOW FAIRY BOOK\\n\\nTHE CAT AND THE MOUSE IN PARTNERSHIP\\n\\nA cat had made acquaintance with a mouse, and had spoken so much of the great love and friendship she felt for her, that at last the Mouse consented to live in the same house with her, and to go shares in the housekeeping.  'But we must provide for the winter or else we shall suffer hunger,' said the Cat.  'You, little Mouse, cannot venture everywhere in case you run at last into a trap.'  This good counsel was followed, and a little pot of fat was bought.  But they did not know where to put it.  At length, after long consultation, the Cat said, 'I know of no place where it could be better put than in the church.  No one will trouble to take it away from there.  We will hide it in a corner, and we won't touch it till we are in want.'  So the little pot was placed in safety; but it was not long before the Cat had a great longing for it, and said to the Mouse, 'I wanted to tell you, little Mouse, that my cousin has a little son, white with brown spots, and she wants me to be godmother to it.  Let me go out to-day, and do you take care of the house alone.''Yes, go certainly,' replied the Mouse, 'and when you eat anything good, think of me; I should very much like a drop of the red christening wine.'\\n\\nBut it was all untrue.  The Cat had no cousin, and had not been asked to be godmother.  She went straight to the church, slunk to the little pot of fat, began to lick it, and licked the top off.  Then she took a walk on the roofs of the town, looked at the view, stretchedherself out in the sun, and licked her lips whenever she thought of the little pot of fat.  As soon as it was evening she went home again.\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"\"\"[f01]\n",
    "[p. ix]\n",
    "\n",
    "THE YELLOW FAIRY BOOK\n",
    "\n",
    "THE CAT AND THE MOUSE IN PARTNERSHIP\n",
    "\n",
    "A cat had made acquaintance with a mouse, and had spoken so much of the great love and friendship she felt for her, that at last the Mouse consented to live in the same house with her, and to go shares in the housekeeping.  'But we must provide for the winter or else we shall suffer hunger,' said the Cat.  'You, little Mouse, cannot venture everywhere in case you run at last into a trap.'  This good counsel was followed, and a little pot of fat was bought.  But they did not know where to put it.  At length, after long consultation, the Cat said, 'I know of no place where it could be better put than in the church.  No one will trouble to take it away from there.  We will hide it in a corner, and we won't touch it till we are in want.'  So the little pot was placed in safety; but it was not long before the Cat had a great longing for it, and said to the Mouse, 'I wanted to tell you, little Mouse, that my cousin has a little son, white with brown spots, and she wants me to be godmother to it.  Let me go out to-day, and do you take care of the house alone.'\n",
    "\n",
    "[p. 1]\n",
    "\n",
    "'Yes, go certainly,' replied the Mouse, 'and when you eat anything good, think of me; I should very much like a drop of the red christening wine.'\n",
    "\n",
    "But it was all untrue.  The Cat had no cousin, and had not been asked to be godmother.  She went straight to the church, slunk to the little pot of fat, began to lick it, and licked the top off.  Then she took a walk on the roofs of the town, looked at the view, stretched\n",
    "\n",
    "[P. 22]\n",
    "\n",
    "herself out in the sun, and licked her lips whenever she thought of the little pot of fat.  As soon as it was evening she went home again.\n",
    "\"\"\"\n",
    "\n",
    "# Example of regex to remove page numbers\n",
    "re.sub(r'\\n*\\[[pP]\\. [^\\]\\s]*\\]\\n\\n', '', example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cc0a0e",
   "metadata": {},
   "source": [
    "## Pulling the Parser Together\n",
    "\n",
    "Let's create a function to parse the book for us by pulling together all the previous fragments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bdab34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_book(txt):\n",
    "    \"\"\"Parse book from text.\"\"\"\n",
    "    \n",
    "    # Get story chunks\n",
    "    stories = re.split(\"\\[f\\d{2}\\]\", txt)\n",
    "    stories = [s.strip(\"\\n\") for s in stories]\n",
    "    \n",
    "    # Get book name\n",
    "    book = stories[0].split(\",\")[0]\n",
    "    \n",
    "    # Process contents\n",
    "    boilerplate = re.split('(Contents|CONTENTS)', stories[0])\n",
    "\n",
    "    # The name of the book repeats at the end of the content block\n",
    "    # So snip it out... \n",
    "    contents_ = boilerplate[-1].split(book)[0].strip(\"\\n\")\n",
    "    \n",
    "    # Match against [* and ] and extract everything in between\n",
    "    contents = parse.findall(\"[*{}]\", contents_)\n",
    "\n",
    "    # Get titles from contents\n",
    "    titles = [item.fixed[0].title() for item in contents]\n",
    "    \n",
    "    # Get metadata\n",
    "    metadata = parse.parse(\"{title}, by Andrew Lang, [{year}]{}, at sacred-texts.com\", stories[0]).named\n",
    "\n",
    "    return book, stories, titles, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b5a11c",
   "metadata": {},
   "source": [
    "## Create Simple Database Structure\n",
    "\n",
    "Let's create a simple database structure and configure it for full text search.\n",
    "\n",
    "We'll use SQLite3 for the database. One of the easiest ways of working with SQLite3 databases is via the [`sqlite_utils`](https://sqlite-utils.datasette.io/en/stable/) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f562ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlite_utils import Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97c4857",
   "metadata": {},
   "source": [
    "Specifiy the database filename (and optionally conntect to the database if it already exists):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bae5ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"demo.db\"\n",
    "\n",
    "# Uncomment the following lines to connect to a pre-existing database\n",
    "#db = Database(db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04bd834",
   "metadata": {},
   "source": [
    "The following will create a new database (or overwrite a pre-existing one of the same name) and define the database tables we require.\n",
    "\n",
    "Note that we also enable full text search on the `book` that creates an extra virtual table that supports full text search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e22d5368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table books (book, title, text, last_para, first_line, provenance, chapter_order)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not run this cell if your database already exists!\n",
    "\n",
    "# While developing the script, recreate database each time...\n",
    "db = Database(db_name, recreate=True)\n",
    "\n",
    "# This schema has been evolved iteratively as I have identified structure\n",
    "# that can be usefully mined...\n",
    "\n",
    "db[\"books\"].create({\n",
    "    \"book\": str,\n",
    "    \"title\": str,\n",
    "    \"text\": str,\n",
    "    \"last_para\": str, # sometimes contains provenance\n",
    "    \"first_line\": str, # maybe we want to review the openings, or create an index...\n",
    "    \"provenance\": str, # attempt at provenance\n",
    "    \"chapter_order\": int, # Sort order of stories in book\n",
    "}, pk=(\"book\", \"title\"))\n",
    "\n",
    "db[\"books_metadata\"].create({\n",
    "    \"title\": str,\n",
    "    \"year\": int\n",
    "})\n",
    "\n",
    "# Enable full text search\n",
    "# This creates an extra virtual table (books_fts) to support the full text search\n",
    "db[\"books\"].enable_fts([\"title\", \"text\"], create_triggers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2129269",
   "metadata": {},
   "source": [
    "## Build Database\n",
    "\n",
    "Let's now create a function that can populate our database based on the contents of one of the books:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfe3773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_book_stories(db_tbl, book, stories, titles=None, quiet=False):\n",
    "    book_items = []\n",
    "\n",
    "    # The titles are from the contents list\n",
    "    # We will actually grab titles from the story\n",
    "    # but the titles grabbed from the contents can be passed in\n",
    "    # if we want to write a check against them.\n",
    "    # Note: there may be punctation differences in the title in the contents\n",
    "    # and the actual title in the text\n",
    "    for i, story in enumerate(stories[1:]):\n",
    "        # Remove the page numbers for now...\n",
    "        story = re.sub(r'\\n*\\[[pP]\\. [^\\]\\s]*\\]\\n\\n', '', story).strip(\"\\n\")\n",
    "        # Other cleaning\n",
    "        story = re.sub(r'\\[\\*\\d+\\s*\\]', '', story)\n",
    "        \n",
    "        # Get the title from the start of the story text\n",
    "        story_ = story.split(\"\\n\\n\")\n",
    "        title_ = story_[0].strip()\n",
    "\n",
    "        # Force the title case variant of the title\n",
    "        title = title_.title().replace(\"'S\", \"'s\")\n",
    "    \n",
    "        # Optionally display the titles and the book\n",
    "        if not quiet:\n",
    "            print(f\"{title} :: {book}\")\n",
    "\n",
    "        # Reassemble the story\n",
    "        text = \"\\n\\n\".join(story_[1:])\n",
    "        \n",
    "        # Clean out the name of the book if it is in the text\n",
    "        #The Green Fairy Book, by Andrew Lang, [1892], at sacred-texts.com\n",
    "        name_ignorecase = re.compile(f\"{book}, by Andrew Lang, \\[\\d*\\], at sacred-texts.com\", re.IGNORECASE)\n",
    "        text = name_ignorecase.sub('', text).strip()\n",
    "        \n",
    "        # Extract the first line then add the full stop back in.\n",
    "        first_line = text.split(\"\\n\")[0].split(\".\")[0] + \".\"\n",
    "        \n",
    "        last_para = text.split(\"\\n\")[-1]\n",
    "        \n",
    "        provenance_1 = parse.parse('[{}] {provenance}', last_para)\n",
    "        provenance_2 = parse.parse('[{provenance}]', last_para)\n",
    "        provenance_3 = parse.parse('({provenance})', last_para)\n",
    "        provenance_4 = {\"provenance\":last_para} if len(last_para.split())<7 else {} # Heuristic\n",
    "        provenance_ = provenance_1 or provenance_2 or provenance_3 or provenance_4\n",
    "        \n",
    "        provenance = provenance_[\"provenance\"] if provenance_ else \"\"\n",
    "        book_items.append({\"book\": book,\n",
    "                           \"title\": title,\n",
    "                           \"text\": text,\n",
    "                           \"last_para\": last_para,\n",
    "                           \"first_line\": first_line,\n",
    "                           \"provenance\": provenance,\n",
    "                           \"chapter_order\":i})\n",
    "    \n",
    "    # The upsert means \"add or replace\"\n",
    "    db_tbl.upsert_all(book_items, pk=(\"book\", \"title\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65263ec",
   "metadata": {},
   "source": [
    "We can add the data for a particular book by passing in the titles and stories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a98cdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bronze Ring :: The Blue Fairy Book\n",
      "Prince Hyacinth And The Dear Little Princess :: The Blue Fairy Book\n",
      "East Of The Sun And West Of The Moon :: The Blue Fairy Book\n",
      "The Yellow Dwarf :: The Blue Fairy Book\n",
      "Little Red Riding Hood :: The Blue Fairy Book\n",
      "The Sleeping Beauty In The Wood :: The Blue Fairy Book\n",
      "Cinderella, Or The Little Glass Slipper :: The Blue Fairy Book\n",
      "Aladdin And The Wonderful Lamp :: The Blue Fairy Book\n",
      "The Tale Of A Youth Who Set Out To Learn What Fear Was :: The Blue Fairy Book\n",
      "Rumpelstiltzkin :: The Blue Fairy Book\n",
      "Beauty And The Beast :: The Blue Fairy Book\n",
      "The Master-Maid :: The Blue Fairy Book\n",
      "Why The Sea Is Salt :: The Blue Fairy Book\n",
      "The Master Cat; Or, Puss In Boots :: The Blue Fairy Book\n",
      "Felicia And The Pot Of Pinks :: The Blue Fairy Book\n",
      "The White Cat :: The Blue Fairy Book\n",
      "The Water-Lily. The Gold-Spinners :: The Blue Fairy Book\n",
      "The Terrible Head :: The Blue Fairy Book\n",
      "The Story Of Pretty Goldilocks :: The Blue Fairy Book\n",
      "The History Of Whittington :: The Blue Fairy Book\n",
      "The Wonderful Sheep :: The Blue Fairy Book\n",
      "Little Thumb :: The Blue Fairy Book\n",
      "The Forty Thieves :: The Blue Fairy Book\n",
      "Hansel And Grettel :: The Blue Fairy Book\n",
      "Snow-White And Rose-Red :: The Blue Fairy Book\n",
      "The Goose-Girl :: The Blue Fairy Book\n",
      "Toads And Diamonds :: The Blue Fairy Book\n",
      "Prince Darling :: The Blue Fairy Book\n",
      "Blue Beard :: The Blue Fairy Book\n",
      "Trusty John :: The Blue Fairy Book\n",
      "The Brave Little Tailor :: The Blue Fairy Book\n",
      "A Voyage To Lilliput :: The Blue Fairy Book\n",
      "The Princess On The Glass Hill :: The Blue Fairy Book\n",
      "The Story Of Prince Ahmed And The Fairy Paribanou :: The Blue Fairy Book\n",
      "The History Of Jack The Giant-Killer :: The Blue Fairy Book\n",
      "The Black Bull Of Norroway :: The Blue Fairy Book\n",
      "The Red Etin :: The Blue Fairy Book\n"
     ]
    }
   ],
   "source": [
    "book, stories, titles, metadata = parse_book(txt)\n",
    "\n",
    "extract_book_stories(db[\"books\"], book, stories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f013c4",
   "metadata": {},
   "source": [
    "We can now run a full text search over the stories. For example, if we are looking for a story with a king and three sons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eaa401a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'The Master Cat; Or, Puss In Boots', 'book': 'The Blue Fairy Book'}\n",
      "{'title': 'The White Cat', 'book': 'The Blue Fairy Book'}\n",
      "{'title': 'The Story Of Prince Ahmed And The Fairy Paribanou', 'book': 'The Blue Fairy Book'}\n"
     ]
    }
   ],
   "source": [
    "q = 'king \"three sons\"'\n",
    "\n",
    "# The `.search()` method knows how to find the full text search table\n",
    "# given the original table name\n",
    "for story in db[\"books\"].search(db.quote_fts(q), columns=[\"title\", \"book\"]):\n",
    "    print(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e1dd45",
   "metadata": {},
   "source": [
    "We can also construct a full text search query over the full text search virtual table explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e5485c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = 'king \"three sons\" goose'\n",
    "\n",
    "_q = f'SELECT title FROM books_fts WHERE books_fts MATCH {db.quote(q2)} ;'\n",
    "\n",
    "for row in db.query(_q):\n",
    "    print(row[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83422a60",
   "metadata": {},
   "source": [
    "The full text search also allows us to select snippets around the search term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f943afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was a miller who left no more estate to the __three sons__ he had than his mill, his ass, and his cat. The partition was soon made. Neither scrivener...\n",
      "---\n",
      "\n",
      "Once upon a time there was a king who had __three sons__, who were all so clever and brave that he began to be afraid that they would want to...\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q3 = '\"three sons\"'\n",
    "\n",
    "_q = f\"\"\"\n",
    "SELECT title, snippet(books_fts, -1, \"__\", \"__\", \"...\", 30) as clip\n",
    "FROM books_fts WHERE books_fts MATCH {db.quote(q3)} LIMIT 2 ;\n",
    "\"\"\"\n",
    "\n",
    "for row in db.query(_q):\n",
    "    print(row[\"clip\"]+'\\n---\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65096e9",
   "metadata": {},
   "source": [
    "We can now create a complete database of Lang's collected fairy stories by churning through all the books and adding them to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "531b97b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for fn in [fn for fn in os.listdir() if fn.endswith(\".gz\")]:\n",
    "    # Read in book from gzip file\n",
    "    txt = gzip_txt(fn)\n",
    "    # Parse book\n",
    "    book, stories, titles, metadata = parse_book(txt)\n",
    "    \n",
    "    #Populate metadata table\n",
    "    db[\"books_metadata\"].upsert(metadata, pk=(\"title\", \"year\"))\n",
    "    \n",
    "    # Extract stories and add them to the database\n",
    "    # The records are upserted (add or replaced) so we won't get duplicate records\n",
    "    # for the book we have already loaded into the database\n",
    "    extract_book_stories(db[\"books\"], book, stories, quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b026af3c",
   "metadata": {},
   "source": [
    "How many books are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93a9d4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'The Pink Fairy Book', 'year': 1889}\n",
      "{'title': 'The Blue Fairy Book', 'year': 1889}\n",
      "{'title': 'The Yellow Fairy Book', 'year': 1889}\n",
      "{'title': 'The Red Fairy Book', 'year': 1890}\n",
      "{'title': 'The Green Fairy Book', 'year': 1892}\n",
      "{'title': 'The Grey Fairy Book', 'year': 1900}\n",
      "{'title': 'The Violet Fairy Book', 'year': 1901}\n",
      "{'title': 'The Crimson Fairy Book', 'year': 1903}\n",
      "{'title': 'The Brown Fairy Book', 'year': 1904}\n",
      "{'title': 'The Orange Fairy Book', 'year': 1906}\n",
      "{'title': 'The Olive Fairy Book', 'year': 1907}\n",
      "{'title': 'The Lilac Fairy Book', 'year': 1910}\n"
     ]
    }
   ],
   "source": [
    "for row in db.query('SELECT * FROM books_metadata ORDER BY year ASC'):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2479217",
   "metadata": {},
   "source": [
    "Okay - the titles are fine but the years look a bit shonky to me...\n",
    "\n",
    "The dates are okay if we use the ones from the sacred texts listing page that we previously grabbed into `sacred_metadata`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "494b0649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'The Blue Fairy Book', 'year': '1889'},\n",
       " {'title': 'The Brown Fairy Book', 'year': '1904'},\n",
       " {'title': 'The Crimson Fairy Book', 'year': '1903'},\n",
       " {'title': 'The Green Fairy Book', 'year': '1892'},\n",
       " {'title': 'The Grey Fairy Book', 'year': '1900'},\n",
       " {'title': 'The Lilac Fairy Book', 'year': '1910'},\n",
       " {'title': 'The Olive Fairy Book', 'year': '1910'},\n",
       " {'title': 'The Orange Fairy Book', 'year': '1906'},\n",
       " {'title': 'The Pink Fairy Book', 'year': '1897'},\n",
       " {'title': 'The Red Fairy Book', 'year': '1890'},\n",
       " {'title': 'The Violet Fairy Book', 'year': '1901'},\n",
       " {'title': 'The Yellow Fairy Book', 'year': '1894'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_metadata = []\n",
    "for m in sacred_metadata:\n",
    "    new_metadata.append({\"title\": m[0][0], \"year\": m[1]})\n",
    "    \n",
    "new_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288af76f",
   "metadata": {},
   "source": [
    "Replace the `books_metadata` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ff6bcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table books_metadata (title, year)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The truncate=True clears the records from the original table\n",
    "db[\"books_metadata\"].insert_all(new_metadata, pk=(\"title\", \"year\"), truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd862ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'The Blue Fairy Book', 'year': 1889}\n",
      "{'title': 'The Red Fairy Book', 'year': 1890}\n",
      "{'title': 'The Green Fairy Book', 'year': 1892}\n",
      "{'title': 'The Yellow Fairy Book', 'year': 1894}\n",
      "{'title': 'The Pink Fairy Book', 'year': 1897}\n",
      "{'title': 'The Grey Fairy Book', 'year': 1900}\n",
      "{'title': 'The Violet Fairy Book', 'year': 1901}\n",
      "{'title': 'The Crimson Fairy Book', 'year': 1903}\n",
      "{'title': 'The Brown Fairy Book', 'year': 1904}\n",
      "{'title': 'The Orange Fairy Book', 'year': 1906}\n",
      "{'title': 'The Lilac Fairy Book', 'year': 1910}\n",
      "{'title': 'The Olive Fairy Book', 'year': 1910}\n"
     ]
    }
   ],
   "source": [
    "for row in db.query('SELECT * FROM books_metadata ORDER BY year ASC'):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285eb481",
   "metadata": {},
   "source": [
    "That looks a bit better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8f43be",
   "metadata": {},
   "source": [
    "How many stories do we now have with a king and three sons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68f98732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search on: king \"three sons\"\n",
      "\n",
      "{'title': 'The Three Brothers', 'book': 'The Pink Fairy Book'}\n",
      "{'title': 'The Princess Who Was Hidden Underground', 'book': 'The Violet Fairy Book'}\n",
      "{'title': 'The Black Thief And Knight Of The Glen.', 'book': 'The Red Fairy Book'}\n",
      "{'title': 'Blockhead-Hans', 'book': 'The Yellow Fairy Book'}\n",
      "{'title': 'The Golden Lion', 'book': 'The Pink Fairy Book'}\n",
      "{'title': 'The Golden Goose', 'book': 'The Red Fairy Book'}\n",
      "{'title': 'The Master Cat; Or, Puss In Boots', 'book': 'The Blue Fairy Book'}\n",
      "{'title': 'The Enchanted Watch', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'The Story Of The Fair Circassians', 'book': 'The Grey Fairy Book'}\n",
      "{'title': 'The Norka', 'book': 'The Red Fairy Book'}\n",
      "{'title': 'Tritill, Litill, And The Birds', 'book': 'The Crimson Fairy Book'}\n",
      "{'title': 'The Seven Foals', 'book': 'The Red Fairy Book'}\n",
      "{'title': 'The Witch And Her Servants', 'book': 'The Yellow Fairy Book'}\n",
      "{'title': 'The Flying Ship', 'book': 'The Yellow Fairy Book'}\n",
      "{'title': \"How The Hermit Helped To Win The King's Daughter\", 'book': 'The Pink Fairy Book'}\n",
      "{'title': 'The Prince And The Dragon', 'book': 'The Crimson Fairy Book'}\n",
      "{'title': 'The Story Of Sigurd', 'book': 'The Red Fairy Book'}\n",
      "{'title': \"The Magician's Horse\", 'book': 'The Grey Fairy Book'}\n",
      "{'title': \"The Bird 'Grip'\", 'book': 'The Pink Fairy Book'}\n",
      "{'title': 'The Three Treasures Of The Giants', 'book': 'The Orange Fairy Book'}\n",
      "{'title': 'The Golden Mermaid', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'Pinkel The Thief', 'book': 'The Orange Fairy Book'}\n",
      "{'title': 'Jesper Who Herded The Hares', 'book': 'The Violet Fairy Book'}\n",
      "{'title': \"Ian, The Soldier's Son\", 'book': 'The Orange Fairy Book'}\n",
      "{'title': 'The Story Of Ciccu', 'book': 'The Pink Fairy Book'}\n",
      "{'title': 'The White Cat', 'book': 'The Blue Fairy Book'}\n",
      "{'title': 'The Story Of Prince Ahmed And The Fairy Paribanou', 'book': 'The Blue Fairy Book'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Search on: {q}\\n\")\n",
    "\n",
    "for story in db[\"books\"].search(db.quote_fts(q), columns=[\"title\", \"book\"]):\n",
    "    print(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dfc253",
   "metadata": {},
   "source": [
    "How about Jack stories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59eaa0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'The History Of Jack The Giant-Killer', 'book': 'The Blue Fairy Book'}\n",
      "{'title': 'Jack And The Beanstalk', 'book': 'The Red Fairy Book'}\n",
      "{'title': 'Jack My Hedgehog', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'The Three Treasures Of The Giants', 'book': 'The Orange Fairy Book'}\n",
      "{'title': 'Farmer Weatherbeard', 'book': 'The Red Fairy Book'}\n",
      "{'title': 'The Shirt-Collar', 'book': 'The Pink Fairy Book'}\n",
      "{'title': 'To The Friendly Reader', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'Preface', 'book': 'The Red Fairy Book'}\n",
      "{'title': 'Preface', 'book': 'The Orange Fairy Book'}\n",
      "{'title': 'The Princess Mayblossom', 'book': 'The Red Fairy Book'}\n",
      "{'title': 'Tale Of A Tortoise And Of A Mischievous Monkey', 'book': 'The Brown Fairy Book'}\n"
     ]
    }
   ],
   "source": [
    "for story in db[\"books\"].search(\"Jack\", columns=[\"title\", \"book\"]):\n",
    "    print(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0f90e9",
   "metadata": {},
   "source": [
    "Ah... so maybe *Preface* is something we could also catch and exclude... And perhaps *To The Friendly Reader* as a special exception."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12cd105",
   "metadata": {},
   "source": [
    "Or Hans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "478374f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': \"Hans, The Mermaid's Son\", 'book': 'The Pink Fairy Book'}\n",
      "{'title': 'The Headless Dwarfs', 'book': 'The Violet Fairy Book'}\n",
      "{'title': 'Blockhead-Hans', 'book': 'The Yellow Fairy Book'}\n",
      "{'title': 'The Underground Workers', 'book': 'The Violet Fairy Book'}\n",
      "{'title': 'The Magic Book', 'book': 'The Orange Fairy Book'}\n",
      "{'title': 'Preface', 'book': 'The Yellow Fairy Book'}\n",
      "{'title': 'The Shirt-Collar', 'book': 'The Pink Fairy Book'}\n",
      "{'title': 'The Goblin And The Grocer', 'book': 'The Pink Fairy Book'}\n",
      "{'title': 'The Flying Trunk', 'book': 'The Pink Fairy Book'}\n",
      "{'title': 'The Snow-Man', 'book': 'The Pink Fairy Book'}\n",
      "{'title': 'The Fir-Tree', 'book': 'The Pink Fairy Book'}\n",
      "{'title': 'The Daughter Of Buk Ettemsuch', 'book': 'The Grey Fairy Book'}\n",
      "{'title': 'The Story Of Halfman', 'book': 'The Violet Fairy Book'}\n",
      "{'title': 'Udea And Her Seven Brothers', 'book': 'The Grey Fairy Book'}\n",
      "{'title': 'The Ugly Duckling', 'book': 'The Orange Fairy Book'}\n",
      "{'title': 'The Snow-Queen', 'book': 'The Pink Fairy Book'}\n"
     ]
    }
   ],
   "source": [
    "for story in db[\"books\"].search(\"Hans\", columns=[\"title\", \"book\"]):\n",
    "    print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9df90cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'The Street Musicians', 'book': 'The Grey Fairy Book'}\n",
      "{'title': 'The Heart Of A Monkey', 'book': 'The Lilac Fairy Book'}\n",
      "{'title': 'The Ogre', 'book': 'The Grey Fairy Book'}\n",
      "{'title': 'The Cunning Shoemaker', 'book': 'The Pink Fairy Book'}\n",
      "{'title': 'Donkey Skin', 'book': 'The Grey Fairy Book'}\n",
      "{'title': 'The Biter Bit', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'The Donkey Cabbage', 'book': 'The Yellow Fairy Book'}\n",
      "{'title': 'The Stones Of Plouhinec', 'book': 'The Lilac Fairy Book'}\n",
      "{'title': 'The Colony Of Cats', 'book': 'The Crimson Fairy Book'}\n",
      "{'title': 'The Prince And The Three Fates', 'book': 'The Brown Fairy Book'}\n",
      "{'title': 'Story Of The King Who Would Be Stronger Than Fate', 'book': 'The Brown Fairy Book'}\n",
      "{'title': 'The Story Of Hassebu', 'book': 'The Violet Fairy Book'}\n",
      "{'title': 'The Nunda, Eater Of People', 'book': 'The Violet Fairy Book'}\n",
      "{'title': 'Preface', 'book': 'The Yellow Fairy Book'}\n",
      "{'title': 'A French Puck', 'book': 'The Lilac Fairy Book'}\n",
      "{'title': 'The Simpleton', 'book': 'The Grey Fairy Book'}\n",
      "{'title': 'The Goat-Faced Girl', 'book': 'The Grey Fairy Book'}\n",
      "{'title': 'The Story Of Dschemil And Dschemila', 'book': 'The Grey Fairy Book'}\n",
      "{'title': 'Hansel And Grettel', 'book': 'The Blue Fairy Book'}\n",
      "{'title': \"Geirlaug The King's Daughter\", 'book': 'The Olive Fairy Book'}\n",
      "{'title': 'The Enchanted Canary', 'book': 'The Red Fairy Book'}\n",
      "{'title': 'The Yellow Dwarf', 'book': 'The Blue Fairy Book'}\n",
      "{'title': 'Heart Of Ice', 'book': 'The Green Fairy Book'}\n"
     ]
    }
   ],
   "source": [
    "for story in db[\"books\"].search(\"donkey\", columns=[\"title\", \"book\"]):\n",
    "    print(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e63311",
   "metadata": {},
   "source": [
    "We can also run explicit SQL queries over the database. For example, how do some of the stories start?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29aa820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a certain country there lived a king whose palace was surrounded by a spacious garden.\n",
      "Once upon a time there lived a king who was deeply in love with a princess, but she could not marry anyone, because she was under an enchantment.\n",
      "Once upon a time there was a poor husbandman who had many children and little to give them in the way either of food or clothing.\n",
      "Once upon a time there lived a queen who had been the mother of a great many children, and of them all only one daughter was left.\n",
      "Once upon a time there lived in a certain village a little country girl, the prettiest creature was ever seen.\n"
     ]
    }
   ],
   "source": [
    "for row in db.query('SELECT first_line FROM books LIMIT 5'):\n",
    "    print(row[\"first_line\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d3420",
   "metadata": {},
   "source": [
    "I seem to recall there may have been some sources at the end of some texts? A quick text for that is to see if there is any mention of `Grimm`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af4f3afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Preface', 'book': 'The Crimson Fairy Book'}\n",
      "{'title': 'The Three Brothers', 'book': 'The Pink Fairy Book'}\n",
      "{'title': 'To The Friendly Reader', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'Jorinde And Joringel', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'Spindle, Shuttle, And Needle', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'The Marvellous Musician', 'book': 'The Red Fairy Book'}\n",
      "{'title': 'Rumpelstiltzkin', 'book': 'The Blue Fairy Book'}\n",
      "{'title': 'The Twelve Huntsmen', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'The Riddle', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'Mother Holle', 'book': 'The Red Fairy Book'}\n",
      "{'title': 'The Story Of A Clever Tailor', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'The Three Snake-Leaves', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'The War Of The Wolf And The Fox', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'Rapunzel', 'book': 'The Red Fairy Book'}\n",
      "{'title': 'The White Snake', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'The House In The Wood', 'book': 'The Pink Fairy Book'}\n",
      "{'title': 'The Golden Goose', 'book': 'The Red Fairy Book'}\n",
      "{'title': 'The Three Dogs', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'The Twelve Brothers', 'book': 'The Red Fairy Book'}\n",
      "{'title': 'The Iron Stove', 'book': 'The Yellow Fairy Book'}\n",
      "{'title': 'The Golden Lads', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'The Three Dwarfs', 'book': 'The Red Fairy Book'}\n",
      "{'title': 'Jack My Hedgehog', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'The Crystal Coffin', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'Allerleirauh; Or, The Many-Furred Creature', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'The Goose-Girl', 'book': 'The Blue Fairy Book'}\n",
      "{'title': 'The Three Musicians', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'Snow-White And Rose-Red', 'book': 'The Blue Fairy Book'}\n",
      "{'title': 'Brother And Sister', 'book': 'The Red Fairy Book'}\n",
      "{'title': 'Little One-Eye, Little Two-Eyes, And Little Three-Eyes', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'Hansel And Grettel', 'book': 'The Blue Fairy Book'}\n",
      "{'title': 'The Story Of The Fisherman And His Wife', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'Trusty John', 'book': 'The Blue Fairy Book'}\n",
      "{'title': 'Snowdrop', 'book': 'The Red Fairy Book'}\n",
      "{'title': 'The Golden Mermaid', 'book': 'The Green Fairy Book'}\n",
      "{'title': 'The Tale Of A Youth Who Set Out To Learn What Fear Was', 'book': 'The Blue Fairy Book'}\n"
     ]
    }
   ],
   "source": [
    "for story in db[\"books\"].search(\"Grimm\", columns=[\"title\", \"book\"]):\n",
    "    print(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bfa896",
   "metadata": {},
   "source": [
    "Okay, so let's check the end of one of those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df95dc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Grimm.\n",
      "[1] Grimm.\n",
      "[1] Grimm.\n",
      "[1] Grimm.\n",
      "[1] Grimm.\n",
      "[1] Grimm.\n",
      "ut them up in the cellar, but in the morning they shall be led forth into the forest and shall serve a charcoal burner until they have improved, and will never again suffer poor animals to go hungry.'\n",
      " ill and died the two others were so deeply grieved that they were also taken ill and died too. And so, because they had all been so clever, and so fond of each other, they were all laid in one grave.\n",
      " and Mrs. Skovgaard-Pedersen has done 'The Green Knight' from the Danish. I must especially thank Monsieur Macler for permitting us to use some of his Contes Armeniens (Paris: Ernest Leroux, Editeur).\n",
      "^32:1 Grimm.\n",
      "ffer in colour; language, religion, and almost everything else; but they all love a nursery tale. The stories have mainly been adapted or translated by Mrs. Lang, a few by Miss Lang and Miss Blackley.\n",
      "ill not be dull. So good-bye, and when you have read a fairy book, lend it to other children who have none, or tell them the stories in your own way, which is a very pleasant mode of passing the time.\n",
      "Grimm.\n",
      "Grimm.\n",
      "Grimm.\n",
      "Grimm.\n",
      "Grimm.\n",
      "Grimm.\n",
      "Grimm.\n",
      "Grimm.\n",
      "Grimm.\n",
      "Grimm.\n",
      "Grimm.\n",
      "Grimm.\n",
      "Grimm.\n",
      "Grimm.\n",
      "Grimm.\n",
      "Grimm.\n",
      "Grimm.\n",
      "[6] Grimm.\n",
      "[19] Grimm.\n",
      "[22] Grimm.\n",
      "[23] Grimm.\n",
      "[26] Grimm.\n",
      "[29] Grimm.\n",
      "[30] Grimm.\n",
      "[32] Grimm.\n"
     ]
    }
   ],
   "source": [
    "for row in db.query('SELECT last_para FROM books WHERE text LIKE \"%Grimm%\"'):\n",
    "    print(row[\"last_para\"][-200:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62508627",
   "metadata": {},
   "source": [
    "How about some stories that don't reference Grimm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2613b895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditions Populaires de l'Asie Mineure. Carnoy et Nicolaides. Paris: Maisonneuve, 1889. :: [1] Traditions Populaires de l'Asie Mineure. Carnoy et Nicolaides. Paris: Maisonneuve, 1889.\n",
      "Le Prince Desir et la Princesse Mignonne. Par Madame Leprince de Beaumont. :: [1] Le Prince Desir et la Princesse Mignonne. Par Madame Leprince de Beaumont.\n",
      "Asbjornsen and Moe. :: [1] Asbjornsen and Moe.\n",
      "Madame d'Aulnoy. :: [1] Madame d'Aulnoy.\n",
      " :: And, saying these words, this wicked wolf fell upon Little Red Riding-Hood, and ate her all up.\n",
      " ::  creatures she had ordered to be thrown into it for others. The King could not but be very sorry, for she was his mother; but he soon comforted himself with his beautiful wife and his pretty children.\n",
      "Charles Perrault. :: [1] Charles Perrault.\n",
      "Arabian Nights. :: [1] Arabian Nights.\n",
      "La Belle et la Bete. Par Madame de Villeneuve. :: [1] La Belle et la Bete. Par Madame de Villeneuve.\n",
      "Asbjornsen and Moe. :: [1] Asbjornsen and Moe.\n"
     ]
    }
   ],
   "source": [
    "# This query was used to help iterate the regular expressions used to extract the provenance\n",
    "for row in db.query('SELECT last_para, provenance FROM books WHERE text NOT LIKE \"%Grimm%\" LIMIT 10'):\n",
    "    print(row[\"provenance\"],\"::\", row[\"last_para\"][-200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb8799fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 \n",
      "31 Grimm.\n",
      "5 Lapplandische Mahrchen.\n",
      "5 Japanische Marchen.\n",
      "5 From 'West Highland Tales.'\n",
      "5 Ehstnische Marchen.\n",
      "5 Charles Perrault.\n",
      "4 Volksmarchen der Serben.\n",
      "4 Madame d'Aulnoy.\n",
      "4 From Ungarische Mahrchen.\n"
     ]
    }
   ],
   "source": [
    "for row in db.query('SELECT DISTINCT provenance, COUNT(*) AS num FROM books GROUP BY provenance ORDER BY num DESC LIMIT 10'):\n",
    "    print(row[\"num\"], row[\"provenance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fc102a",
   "metadata": {},
   "source": [
    "Hmm.. it seemed like there were more mentions of Grimm than that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ee0c5a",
   "metadata": {},
   "source": [
    "## Making *pandas* based Database Queries\n",
    "\n",
    "For convenience, let's set up a database connection so we can easily run *pandas* mediated queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0dad6422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e86bea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--SPLITHERE--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f4245d",
   "metadata": {},
   "source": [
    "## Entity Extraction...\n",
    "\n",
    "So what entities can we find in the stories...?!\n",
    "\n",
    "Let's load in the `spacy` natural language processing toolkit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32231076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "#%pip install --upgrade spacy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0aa1a3",
   "metadata": {},
   "source": [
    "Get a dataframe of data frm the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0370b9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>last_para</th>\n",
       "      <th>first_line</th>\n",
       "      <th>provenance</th>\n",
       "      <th>chapter_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>The Bronze Ring</td>\n",
       "      <td>Once upon a time in a certain country there li...</td>\n",
       "      <td>[1] Traditions Populaires de l'Asie Mineure. C...</td>\n",
       "      <td>Once upon a time in a certain country there li...</td>\n",
       "      <td>Traditions Populaires de l'Asie Mineure. Carno...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>Prince Hyacinth And The Dear Little Princess</td>\n",
       "      <td>Once upon a time there lived a king who was de...</td>\n",
       "      <td>[1] Le Prince Desir et la Princesse Mignonne. ...</td>\n",
       "      <td>Once upon a time there lived a king who was de...</td>\n",
       "      <td>Le Prince Desir et la Princesse Mignonne. Par ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>East Of The Sun And West Of The Moon</td>\n",
       "      <td>Once upon a time there was a poor husbandman w...</td>\n",
       "      <td>[1] Asbjornsen and Moe.</td>\n",
       "      <td>Once upon a time there was a poor husbandman w...</td>\n",
       "      <td>Asbjornsen and Moe.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>The Yellow Dwarf</td>\n",
       "      <td>Once upon a time there lived a queen who had b...</td>\n",
       "      <td>[1] Madame d'Aulnoy.</td>\n",
       "      <td>Once upon a time there lived a queen who had b...</td>\n",
       "      <td>Madame d'Aulnoy.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>Little Red Riding Hood</td>\n",
       "      <td>Once upon a time there lived in a certain vill...</td>\n",
       "      <td>And, saying these words, this wicked wolf fell...</td>\n",
       "      <td>Once upon a time there lived in a certain vill...</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  book                                         title  \\\n",
       "0  The Blue Fairy Book                               The Bronze Ring   \n",
       "1  The Blue Fairy Book  Prince Hyacinth And The Dear Little Princess   \n",
       "2  The Blue Fairy Book          East Of The Sun And West Of The Moon   \n",
       "3  The Blue Fairy Book                              The Yellow Dwarf   \n",
       "4  The Blue Fairy Book                        Little Red Riding Hood   \n",
       "\n",
       "                                                text  \\\n",
       "0  Once upon a time in a certain country there li...   \n",
       "1  Once upon a time there lived a king who was de...   \n",
       "2  Once upon a time there was a poor husbandman w...   \n",
       "3  Once upon a time there lived a queen who had b...   \n",
       "4  Once upon a time there lived in a certain vill...   \n",
       "\n",
       "                                           last_para  \\\n",
       "0  [1] Traditions Populaires de l'Asie Mineure. C...   \n",
       "1  [1] Le Prince Desir et la Princesse Mignonne. ...   \n",
       "2                            [1] Asbjornsen and Moe.   \n",
       "3                               [1] Madame d'Aulnoy.   \n",
       "4  And, saying these words, this wicked wolf fell...   \n",
       "\n",
       "                                          first_line  \\\n",
       "0  Once upon a time in a certain country there li...   \n",
       "1  Once upon a time there lived a king who was de...   \n",
       "2  Once upon a time there was a poor husbandman w...   \n",
       "3  Once upon a time there lived a queen who had b...   \n",
       "4  Once upon a time there lived in a certain vill...   \n",
       "\n",
       "                                          provenance  chapter_order  \n",
       "0  Traditions Populaires de l'Asie Mineure. Carno...              0  \n",
       "1  Le Prince Desir et la Princesse Mignonne. Par ...              1  \n",
       "2                                Asbjornsen and Moe.              2  \n",
       "3                                   Madame d'Aulnoy.              3  \n",
       "4                                                                 4  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"SELECT * FROM books\"\n",
    "df = pd.read_sql(q, conn)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6a2223",
   "metadata": {},
   "source": [
    "Now let's have a go at extracting some entities (this may take some time!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7388d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a set of entities, rather than a list...\n",
    "get_entities = lambda desc: {f\"{entity.label_} :: {entity.text}\" for entity in nlp(desc).ents}\n",
    "\n",
    "# The full run takes some time....\n",
    "df['entities'] = df[\"text\"].apply(get_entities)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f50544",
   "metadata": {},
   "source": [
    "*We should probably just do this once and add an appropriate table of entities to the database...*\n",
    "\n",
    "We can explode these out into a long format dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3865c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "\n",
    "# Explode the entities one per row...\n",
    "df_long = df.explode('entities')\n",
    "df_long.rename(columns={\"entities\":\"entity\"}, inplace=True)\n",
    "\n",
    "# And then separate out entity type and value\n",
    "df_long[[\"entity_typ\", \"entity_value\"]] = df_long[\"entity\"].str.split(\" :: \").apply(Series)\n",
    "df_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db0f38c",
   "metadata": {},
   "source": [
    "And explore..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e49430",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long[\"entity_typ\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22888116",
   "metadata": {},
   "source": [
    "What sort of money has been identified in the stories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1b4973",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long[df_long[\"entity_typ\"]==\"MONEY\"][\"entity_value\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf16f80",
   "metadata": {},
   "source": [
    "Dollars? Really??? What about gold coins?! Do I need to train a new classifier?! Or was the original text really like that... Or has the text been got at? *(Maybe I should do my own digitisation project to extract the text from copies of the original books on the Internet Archive? Hmmm.. that could be interesting for when we go on strike...)*\n",
    "\n",
    "What about other quantities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long[df_long[\"entity_typ\"]==\"QUANTITY\"][\"entity_value\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a8daa1",
   "metadata": {},
   "source": [
    "What people have been identified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d780e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long[df_long[\"entity_typ\"]==\"PERSON\"][\"entity_value\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046a3285",
   "metadata": {},
   "source": [
    "How about geo-political entities (GPEs)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80a44e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long[df_long[\"entity_typ\"]==\"GPE\"][\"entity_value\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c6bea2",
   "metadata": {},
   "source": [
    "When did things happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9af47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long[df_long[\"entity_typ\"]==\"DATE\"][\"entity_value\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea08b95e",
   "metadata": {},
   "source": [
    "And how about time considerations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8491284",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long[df_long[\"entity_typ\"]==\"TIME\"][\"entity_value\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aa37fe",
   "metadata": {},
   "source": [
    "How were things organised?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ad8e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long[df_long[\"entity_typ\"]==\"ORG\"][\"entity_value\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836f52ad",
   "metadata": {},
   "source": [
    "What's a `NORP`? (Ah... *Nationalities Or Religious or Political groups.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370cc6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long[df_long[\"entity_typ\"]==\"NORP\"][\"entity_value\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d52f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--SPLITHERE--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d12361",
   "metadata": {},
   "source": [
    "## Add Wikipedia Links\n",
    "\n",
    "The Wikipedia page [`Lang's_Fairy_Books`](https://en.wikipedia.org/wiki/Lang's_Fairy_Books) lists the contents of Lang's coloured fairy books (as well as several other books), along with links to the Wikipedia page associated with each tale, if available.\n",
    "\n",
    "This means we can have a go at annotating our database with Wikipedia links for each story. From those pages in turn, or associated *DBpedia* pages, we might also be able to extract Aarne-Thompson classification codes for the corresponding stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd69165",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Lang's_Fairy_Books\"\n",
    "\n",
    "html = requests.get(url)\n",
    "\n",
    "wp_soup = BeautifulSoup(html.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8bc440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the span for a particular book\n",
    "wp_book_loc =  wp_soup.find(\"span\", id=\"The_Blue_Fairy_Book_(1889)\")\n",
    "\n",
    "# Then navigate relative to this to get the (linked) story list\n",
    "wp_book_stories = wp_book_loc.find_parent().find_next(\"ul\").find_all('li')\n",
    "wp_book_stories[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3537ca4b",
   "metadata": {},
   "source": [
    "Get the Wikipedia path for stories with a Wikipedia page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f092f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_book_paths = [(li.find(\"a\").get(\"title\"), li.find(\"a\").get(\"href\")) for li in wp_book_stories]\n",
    "\n",
    "wp_book_paths[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91c6ffd",
   "metadata": {},
   "source": [
    "Useful as a list of `dict`s or *pandas* `DataFrame`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wp_book_paths_wide = []\n",
    "\n",
    "for item in wp_book_paths:\n",
    "    wp_book_paths_wide.append( {\"title\":item[0].strip(), \"path\":item[1]} )\n",
    "    \n",
    "wp_book_df = pd.DataFrame(wp_book_paths_wide)\n",
    "wp_book_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4da5fd8",
   "metadata": {},
   "source": [
    "See if we can then cross reference these with stories in the database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de6bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"SELECT book, title, chapter_order FROM books WHERE book='The Blue Fairy Book' ORDER BY chapter_order ASC\"\n",
    "df_blue = pd.read_sql(q, conn)\n",
    "\n",
    "df_blue.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091653c9",
   "metadata": {},
   "source": [
    "Let's see if the chapters align in terms of order as presented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"book\":df_blue[\"title\"], \"wp\":wp_book_df[\"title\"], \"wp_path\":wp_book_df[\"path\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191bbbfc",
   "metadata": {},
   "source": [
    "Yes, they do so we can use that as a basis of a merge. That said, in the genral case it would probably also be useful to generate a fuzzy match score between matched titles with a report on any low scoring matches, just in case the alignment has gone awry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516813e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO  - wp table for links, story and story order?\n",
    "# TO DO fuzzy match score test just to check ingest and allow user to check poor matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee412f",
   "metadata": {},
   "source": [
    "In passing,what if we wanted to try to match on the titles themselves?\n",
    "\n",
    "If we use decased, but otherwise exact, matching, we see it's bit flaky...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac753be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_blue[\"title\"], wp_book_df,\n",
    "         left_on=df_blue[\"title\"].str.lower(),\n",
    "         right_on=wp_book_df[\"title\"].str.lower(),\n",
    "         how =\"left\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08ccf25",
   "metadata": {},
   "source": [
    "A fuzzy match might be able to improve things..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b5dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reused from on https://stackoverflow.com/a/56315491/454773\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def fuzzy_merge(df_1, df_2, key1, key2, threshold=90, limit=2):\n",
    "    \"\"\"\n",
    "    :param df_1: the left table to join\n",
    "    :param df_2: the right table to join\n",
    "    :param key1: key column of the left table\n",
    "    :param key2: key column of the right table\n",
    "    :param threshold: how close the matches should be to return a match, based on Levenshtein distance\n",
    "    :param limit: the amount of matches that will get returned, these are sorted high to low\n",
    "    :return: dataframe with boths keys and matches\n",
    "    \"\"\"\n",
    "    s = df_2[key2].tolist()\n",
    "    \n",
    "    m = df_1[key1].apply(lambda x: process.extract(x, s, limit=limit))  \n",
    "    df_1['matches'] = m\n",
    "    \n",
    "    m2 = df_1['matches'].apply(lambda x: ', '.join([i[0] for i in x if i[1] >= threshold]))\n",
    "    df_1['matches'] = m2\n",
    "    return df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2e0ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_merge(df_blue, wp_book_df, \"title\", \"title\", 88, limit=1)[[\"title\", \"matches\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/jsoma/fuzzy_pandas/\n",
    "\n",
    "# This is probably overkill...\n",
    "#%pip install fuzzy_pandas\n",
    "import fuzzy_pandas as fpd\n",
    "\n",
    "fpd.fuzzy_merge(df_blue[[\"title\"]], wp_book_df,\n",
    "            left_on='title',\n",
    "            right_on='title',\n",
    "            ignore_case=True,\n",
    "            ignore_nonalpha=True,\n",
    "            method='jaro', #bilenko, levenshtein, metaphone, jaro\n",
    "            threshold=0.86, # If we move to 0.86 we get a false positive...\n",
    "            keep_left='all',\n",
    "            keep_right=\"all\"\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a192dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpd.fuzzy_merge(df_blue[[\"title\"]], wp_book_df,\n",
    "            left_on='title',\n",
    "            right_on='title',\n",
    "            ignore_case=True,\n",
    "            ignore_nonalpha=True,\n",
    "            method='metaphone', #levenshtein, metaphone, jaro, bilenko\n",
    "            threshold=0.86,\n",
    "            keep_left='all',\n",
    "            keep_right=\"all\"\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a955dc0f",
   "metadata": {},
   "source": [
    "## Other Things to Link In\n",
    "\n",
    "Have other people generated data sets that can be linked in?\n",
    "\n",
    "- http://www.mythfolklore.net/andrewlang/indexbib.htm /via @OnlineCrsLady"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c55e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--SPLITHERE--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f800e6bb",
   "metadata": {},
   "source": [
    "## Common Refrains / Repeating Phrases\n",
    "\n",
    "Many stories incorporate a repeating phrase or refrain in the story, but you may need to read quite a long way into a story before you can identify that repeating phrase. So are there any tools we might be able to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d0d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#db = Database(db_name)\n",
    "              \n",
    "q2 = '\"pretty hen\"'\n",
    "\n",
    "_q = f'SELECT * FROM books_fts WHERE books_fts MATCH {db.quote(q2)} ;'\n",
    "\n",
    "for row in db.query(_q):\n",
    "    print(row[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d11e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams as nltk_ngrams\n",
    "\n",
    "tokens = nltk.word_tokenize(row[\"text\"])\n",
    "\n",
    "size = 5\n",
    "#for i in nltk_ngrams(tokens, size):\n",
    "#    print(' '.join(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78461b3",
   "metadata": {},
   "source": [
    "We could then look for repeating phrases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d7abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'phrase':[' '.join(i) for i in nltk_ngrams(tokens, size)]})\n",
    "df['phrase'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cae8cc",
   "metadata": {},
   "source": [
    "Really, we need to do a scan down from large token size until we find a match (longest match phrase).\n",
    "\n",
    "But for now, let's see what repeating elements we get from one of those search phrases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baf60fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "_q = 'pretty brindled cow'\n",
    "\n",
    "for m in re.finditer(_q, row[\"text\"]):\n",
    "    # Display the matched terms and the 50 characters\n",
    "    # immediately preceding and following the phrase \n",
    "    print(f'===\\n{q2}: ', m.start(), m.end(), row[\"text\"][max(0, m.start()-50):m.end()+50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3101aea1",
   "metadata": {},
   "source": [
    "Make a function for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contexts(text, phrase, width=50):\n",
    "    \"\"\"Find the context(s) of the phrase.\"\"\"\n",
    "    contexts = []\n",
    "    for m in re.finditer(phrase, text):\n",
    "        # Display the matched terms and the `width` characters\n",
    "        # immediately preceding and following the phrase \n",
    "        contexts.append(text[max(0, m.start()-width):m.end()+width])\n",
    "    return contexts\n",
    "\n",
    "for i in find_contexts(row['text'], 'pretty brindled cow'):\n",
    "    print(i,\"\\n==\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2eca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_contexts(row['text'], 'pretty brindled cow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f0db0b",
   "metadata": {},
   "source": [
    "We can also make this a SQLite lookup function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ec5f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vtfunc import TableFunction\n",
    "\n",
    "def concordances(text, phrase, width=50):\n",
    "    \"\"\"Find the concordances of a phrase in a text.\"\"\"\n",
    "    contexts = []\n",
    "    for m in re.finditer(phrase, text):\n",
    "        # Display the matched terms and the `width` characters\n",
    "        # immediately preceding and following the phrase\n",
    "        context = text[max(0, m.start()-width):m.end()+width]\n",
    "        contexts.append( (context, m.start(), m.end()) )\n",
    "    return contexts\n",
    "\n",
    "\n",
    "class Concordances(TableFunction):\n",
    "    params = ['phrase', 'text']\n",
    "    columns = ['match', 'start', 'end']\n",
    "    name = 'concordance'\n",
    "\n",
    "    def initialize(self, phrase=None, text=None):\n",
    "        self._iter = iter(concordances(text, phrase))\n",
    "\n",
    "    def iterate(self, idx):\n",
    "        (context, start, end) = next(self._iter)\n",
    "        return (context, start, end,)\n",
    "\n",
    "Concordances.register(db.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b68b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "concordances(row['text'], 'pretty brindled cow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b4e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT matched.*\n",
    "  FROM books, concordance(\"pretty brindled cow\", books.text) AS matched\n",
    "  WHERE title=\"The House In The Wood\";\n",
    "\"\"\"\n",
    "for i in db.execute(q):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b076e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow different tokenisers\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def scanner(text, minlen=4, startlen=50, min_repeats = 3, autostop=True):\n",
    "    \"\"\"Search a text for repeated phrases above a minimum length.\"\"\"\n",
    "    # Tokenise the text\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokenizer.tokenize('Eighty-seven miles to go, yet.  Onward!')\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    #nltk_ngrams returns an empty list if we ask for an ngram longer than the sentence\n",
    "    # So set the (long) start length to the lesser of the original provided\n",
    "    # start length or the token length of the original text;\n",
    "    # which is to say, the minimum of the provided start length \n",
    "    # or the length of the text\n",
    "    startlen = min(startlen, len(tokens))\n",
    "    \n",
    "    # Start with a long sequence then iterate down to a minumum length sequence\n",
    "    for size in range(startlen, minlen-1, -1):\n",
    "        # Generate a dataframe containing all the ngrams, one row per ngram\n",
    "        df = pd.DataFrame({'phrase':[' '.join(i) for i in nltk_ngrams(tokens, size)]})\n",
    "        \n",
    "        # Find the occurrence counts of each phrase\n",
    "        value_counts_series = df['phrase'].value_counts()\n",
    "\n",
    "        # If we have at least the specified number of occurrences\n",
    "        # don't bother searching for any more\n",
    "        if max(value_counts_series) >= min_repeats:\n",
    "            if autostop:\n",
    "                break\n",
    "            pass\n",
    "    # Return a pandas series (an indexed list, essentially)\n",
    "    # containing the longest (or phrases) we found\n",
    "    \n",
    "    return value_counts_series[(value_counts_series>=min_repeats) & (value_counts_series==max(value_counts_series))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d375d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "scanner( row[\"text\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bd23da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first (0'th indexed) item\n",
    "# (In this case there is only one item hat repeats this number of times anyway.)\n",
    "scanner( row[\"text\"] ).index[0], scanner( row[\"text\"] ).values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7885eef",
   "metadata": {},
   "source": [
    "If we constrain this function to return a single item, we can create a simple SQLite function that will search through records and return the longest phrase above a certain minimum length (or the first longest phrase, if several long phrases of the same length are found):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee00e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_repeating_phrase(text):\n",
    "    \"\"\"Return the longest repeating phrase found in a text.\n",
    "       If there are more than one of the same length, return the first.\n",
    "    \"\"\"\n",
    "    phrase = scanner(text)\n",
    "    \n",
    "    #If there is at least one response, take the first\n",
    "    if not phrase.empty:\n",
    "        return phrase.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace0ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_repeating_phrase(row['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9c4485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `db` object is a sqlite_utils database object\n",
    "# Pass in:\n",
    "# - the name of the function we want to use in the database\n",
    "# - the number of arguments it takes\n",
    "# - the function we want to invoke\n",
    "db.conn.create_function('find_repeating_phrase', 1,\n",
    "                        find_repeating_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a132b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_q = \"\"\"\n",
    "SELECT book, title, find_repeating_phrase(text) AS phrase \n",
    "FROM books WHERE title=\"The House In The Wood\" ;\n",
    "\"\"\"\n",
    "\n",
    "for row2 in db.query(_q):\n",
    "    print(row2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_q = \"\"\"\n",
    "SELECT title, find_repeating_phrase(text) AS phrase\n",
    "FROM books WHERE book=\"The Pink Fairy Book\" ;\n",
    "\"\"\"\n",
    "\n",
    "for row3 in db.query(_q):\n",
    "    if row3['phrase'] is not None:\n",
    "        print(row3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832d0e20",
   "metadata": {},
   "source": [
    "The punctuation gets in the way somewhat, so it might be useful if removed the punctuation and tried again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allow param and de-punctuate\n",
    "\n",
    "def scanner2(text, minlen=4, startlen=50, min_repeats = 4, autostop=True, tokeniser='word'):\n",
    "    \"\"\"Search a text for repeated phrases above a minimum length.\"\"\"\n",
    "    # Tokenise the text\n",
    "    if tokeniser == 'depunc_word':\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "    elif tokeniser == 'sent':\n",
    "        pass\n",
    "    else:\n",
    "        # eg for default: tokeniser='word'\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        tokenizer.tokenize('Eighty-seven miles to go, yet.  Onward!')\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    #nltk_ngrams returns an empty list if we ask for an ngram longer than the sentence\n",
    "    # So set the (long) start length to the lesser of the original provided\n",
    "    # start length or the token length of the original text;\n",
    "    # which is to say, the minimum of the provided start length \n",
    "    # or the lenth of the text\n",
    "    startlen = min(startlen, len(tokens))\n",
    "    \n",
    "    # Start with a long sequence then iterate down to a minumum length sequence\n",
    "    for size in range(startlen, minlen-1, -1):\n",
    "        \n",
    "        # Generate a dataframe containing all the ngrams, one row per ngram\n",
    "        df = pd.DataFrame({'phrase':[' '.join(i) for i in nltk_ngrams(tokens,size)]})\n",
    "        \n",
    "        # Find the occurrence counts of each phrase\n",
    "        value_counts_series = df['phrase'].value_counts()\n",
    "        \n",
    "        # If we have at least the specified number of occurrences\n",
    "        # don't bother searching for any more\n",
    "        if max(value_counts_series) >= min_repeats:\n",
    "            if autostop:\n",
    "                break\n",
    "            pass\n",
    "    # Return a pandas series (an indexed list, essentially)\n",
    "    # containing the long phrase (or phrases) we found\n",
    "    return value_counts_series[(value_counts_series>=min_repeats) & (value_counts_series==max(value_counts_series))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea926bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_repeating_phrase_depunc(text, minlen):\n",
    "    \"\"\"Return the longest repeating phrase found in a text.\n",
    "       If there are more than one of the same lentgh, return the first.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Accepts a specified minimum phrase length (minlin)\n",
    "    # Reduce the required number of repeats\n",
    "    phrase = scanner2(text, minlen=minlen, min_repeats = 3,\n",
    "                      tokeniser='depunc_word')\n",
    "    \n",
    "    #If there is at least one response, take the first\n",
    "    if not phrase.empty:\n",
    "        return phrase.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac8b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_repeating_phrase_depunc(row['text'], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459bad69",
   "metadata": {},
   "source": [
    "Register the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0597bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note we need to update the number of arguments (max. 2)\n",
    "db.conn.create_function('find_repeating_phrase_depunc', 2,\n",
    "                        find_repeating_phrase_depunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6904275d",
   "metadata": {},
   "source": [
    "Try again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf28447",
   "metadata": {},
   "outputs": [],
   "source": [
    "_q = \"\"\"\n",
    "SELECT book, title, find_repeating_phrase_depunc(text, 7) AS phrase\n",
    "FROM books WHERE book=\"The Pink Fairy Book\" ;\n",
    "\"\"\"\n",
    "\n",
    "for row5 in db.query(_q):\n",
    "    if row5['phrase'] is not None:\n",
    "        print(row5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b134339",
   "metadata": {},
   "source": [
    "Check the context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346baf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "_q = \"\"\"\n",
    "SELECT text, find_repeating_phrase(text) AS phrase\n",
    "FROM books WHERE title=\"Maiden Bright-Eye\" ;\n",
    "\"\"\"\n",
    "\n",
    "for row6 in db.query(_q):\n",
    "    for c in find_contexts(row6['text'], \"Where is my wicked \", 100):\n",
    "        print(c,\"\\n===\")\n",
    "    #print(row6['phrase'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac39935",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row6 in db.query(_q):\n",
    "    for c in find_contexts(row6['text'], \"the king's palace\", 100):\n",
    "        print(c,\"\\n===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1e259",
   "metadata": {},
   "source": [
    "We need to be able to find short sentences down to the minimum that are not in a longer phrase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a05ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scanner_all(text, minlen=4, startlen=50,\n",
    "                min_repeats = 4, autostop=True):\n",
    "    long_phrases = {}\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    for size in range(startlen, minlen-1, -1):\n",
    "        df = pd.DataFrame({'phrase':[' '.join(i) for i in nltk_ngrams(tokens, min(size, len(tokens)))]})\n",
    "        value_counts_series = df['phrase'].value_counts()\n",
    "        \n",
    "        if max(value_counts_series) >= min_repeats:\n",
    "            test_phrases = value_counts_series[value_counts_series==max(value_counts_series)]\n",
    "            for (test_phrase, val) in test_phrases.iteritems():\n",
    "                if (test_phrase not in long_phrases) and not any(test_phrase in long_phrase for long_phrase in long_phrases):\n",
    "                    long_phrases[test_phrase] = val\n",
    "            \n",
    "    return long_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_reps =\"\"\"\n",
    "Nota that There once was a thing that and 5 There once was a thing that and 4 There once was a thing that and 3\n",
    "There once was a thing that and 1 There once was a thing that and  6 There once was a thing that and 7\n",
    "there was another that 1 and there was another that 2 and there was another that 3 and there was another that and\n",
    "there was another that and there was another that 5 and there was another that 9 and there was another that\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c74a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "scanner( txt_reps )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c8867",
   "metadata": {},
   "outputs": [],
   "source": [
    "scanner_all(txt_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31db255",
   "metadata": {},
   "outputs": [],
   "source": [
    "scanner_all( row[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e70f03",
   "metadata": {},
   "source": [
    "## Longest Common Substring\n",
    "\n",
    "Could we use `difflib.SequenceMatcher.find_longest_match()` on first and second half of doc, or various docs samples, to try to find common refrains?\n",
    "\n",
    "Or chunk into paragraphs and compare every paragraph with every other paragraph?\n",
    "\n",
    "Here's how the to call the `SequenceMatcher().find_longest_match()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cb53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "m = SequenceMatcher(None, txt_reps.split('\\n')[1],\n",
    "                    txt_reps.split('\\n')[2]).find_longest_match()\n",
    "m, txt_reps.split('\\n')[1][m.a: m.a + m.size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16859bce",
   "metadata": {},
   "source": [
    "## Doc2Vec Search Engine\n",
    "\n",
    "To explore: a simple `Doc2Vec` powered search engine based on https://www.kaggle.com/hgilles06/a-doc2vec-search-engine-cord19-new-version ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
